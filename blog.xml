<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title type="text">Eric Ma's Blog</title>
  <id>urn:uuid:8e5496e4-8606-3632-a35c-1d9694b4313d</id>
  <updated>2018-07-16T00:00:00Z</updated>
  <link href="http://www.ericmjl.com/blog/" />
  <link href="http://www.ericmjl.com/blog.xml" rel="self" />
  <author>
    <name></name>
  </author>
  <generator uri="https://github.com/ajdavis/lektor-atom" version="0.3">Lektor Atom Plugin</generator>
  <entry xml:base="http://www.ericmjl.com/blog/2018/7/16/bayesian-estimation-group-comparison-and-workflow/">
    <title type="text">Bayesian Estimation, Group Comparison, and Workflow</title>
    <id>urn:uuid:58217c0b-67d0-3380-92be-00cbcab54a50</id>
    <updated>2018-07-16T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/7/16/bayesian-estimation-group-comparison-and-workflow/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Over the past year, having learned about Bayesian inference methods, I finally see how estimation, group comparison, and model checking build upon each other into this really elegant framework for data analysis.&lt;/p&gt;
&lt;h2 id=&quot;parameter-estimation&quot;&gt;Parameter Estimation&lt;/h2&gt;&lt;p&gt;The foundation of this is &quot;estimating a parameter&quot;. In a typical situation, we are most concerned with the parameter of interest. It could be a population mean, or a population variance. If there's a mathematical function that links the input variables to the output (a.k.a. &quot;link function&quot;), then the parameters of the model are that function's parameters. The key point here is that the atomic activity of Bayesian analysis is the estimation of a parameter, and its associated uncertainty.&lt;/p&gt;
&lt;h2 id=&quot;comparison-of-groups&quot;&gt;Comparison of Groups&lt;/h2&gt;&lt;p&gt;Building on that, we can then estimate parameters for more than one group of things. As a first pass, we could assume that each of the groups are unrelated, and thus &quot;independently&quot; (I'm trying to avoid overloading this term) estimate parameters per group under this assumption. Alternatively, we could assume that the groups are related to one another, and thus use a &quot;hierarchical&quot; model to estimate parameters for each group.&lt;/p&gt;
&lt;p&gt;Once we've done that, what's left is the comparison of parameters between the groups. The simplest activity is to compare the posterior distributions' 95% highest posterior densities, and check to see if they overlap. Usually this is done for the mean, or for regression parameters, but the variance might also be important to check as well.&lt;/p&gt;
&lt;h2 id=&quot;model-check&quot;&gt;Model Check&lt;/h2&gt;&lt;p&gt;Rounding off this framework is model checking: how do we test that the model is a good one? The bare minimum that we should do is simulate data from the model - it should generate samples whose distribution looks like the actual data itself. If it doesn't, then we have a problem, and need to go back and rework the model structure until it does.&lt;/p&gt;
&lt;p&gt;Could it be that we have a model that only fits the data on hand (overfitting)? Potentially so - and if this is the case, then our best check is to have an &quot;out-of-sample&quot; group. While a train/test/validation split might be useful, the truest test of a model is new data that has been collected.&lt;/p&gt;
&lt;h2 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h2&gt;&lt;p&gt;These three major steps in Bayesian data analysis workflows did not come together until recently; they each seemed disconnected from the others. Perhaps this was just an artefact of how I was learning them. However, I think I've finally come to a unified realization: Estimation is necessary before we can do comparison, and model checking helps us build confidence in the estimation and comparison procedures that we use.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;&lt;p&gt;When doing Bayesian data analysis, the key steps that we're performing are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Estimation&lt;/li&gt;
&lt;li&gt;Comparison&lt;/li&gt;
&lt;li&gt;Model Checking&lt;/li&gt;
&lt;/ol&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/7/14/ecdfs/">
    <title type="text">ECDFs</title>
    <id>urn:uuid:dcedf06f-59ec-360f-9711-7e4db71e3ef1</id>
    <updated>2018-07-14T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/7/14/ecdfs/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;In my two SciPy 2018 co-taught tutorials, I made the case that ECDFs provide richer information compared to histograms. My main points were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We can more easily identify central tendency measures, in particular, the median, compared to a histogram.&lt;/li&gt;
&lt;li&gt;We can much more easily identify other percentile values, compared to a histogram.&lt;/li&gt;
&lt;li&gt;We become less susceptible to outliers arising from binning issues.&lt;/li&gt;
&lt;li&gt;It is more difficult to hide multiple modes.&lt;/li&gt;
&lt;li&gt;We can easily identify repeat values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What are ECDFs? ECDFs stand for the &quot;empirical cumulative distribution function&quot;, and they map every data point in the dataset to a quantile, which is a number between 0 and 1 that indicates the cumulative fraction of data points smaller than that data point itself.&lt;/p&gt;
&lt;p&gt;To illustrate, let's take a look at the following plots.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate a mixture of two normal distributions, but with&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# very few data points.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mx1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mx2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mx1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mx2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# one outlier&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ecdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax_ecdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax_hist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax_hist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;histogram&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ax_hist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ecdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax_ecdf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax_ecdf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ecdf&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot;
&gt;
&lt;/div&gt;&lt;p&gt;Let's compare the ECDF and the histogram for this data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is the central tendency measure easily discoverable?&lt;/strong&gt; We might say that there's some peak at just below the x-axis at just above zero, but is that the mode, median or mean? And what is its exact value? On the other hand, at least the median is easily discoverable on the ECDF: Draw a horizontal line from 0.5 on the y-axis until it crosses a data point, and then drop a line down to the x-axis to get the median value.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are percentiles easily discoverable?&lt;/strong&gt; It's much clearer that the answer is &quot;yes&quot; for the ECDF, and &quot;no&quot; for the histogram.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is the value of the potential outlier?&lt;/strong&gt; Difficult to tell on the histogram: it could be anywhere from 4 to 5 (high outlier) and maybe -3 to -4 on the low outlier. On the other hand, just drop a line down from the suspected outliers to the x-axis to read off their values.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is this a mixture distribution or is this a single Normal distribution?&lt;/strong&gt; If you looked at the histogram, you might be tempted to think that the data are normally distributed with mean 0.5 and standard deviation about 2. However, if you look at the ECDF, it's clear that there are multiple modes, as shown by two or three sigmoidal-like curves. This should give us pause to see if there's a mixture distribution at play here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are there repeat values?&lt;/strong&gt; You can't tell in a histogram. However, it's evidently clear on the ECDF scatterplot that there's no repeat values -- they would show up on the plot as vertical stacks of dots. (Repeat-values might be important when working with, say, a zero- or X-inflated distribution.)&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;&lt;p&gt;I hope this post showed you why ECDFs contain richer information than histograms. They're taught less commonly than histograms, so people will have a harder time interpreting them at first glance. However, a bit of guidance and orientation will bring out the rich information on the ECDFs.&lt;/p&gt;
&lt;h2 id=&quot;credits&quot;&gt;Credits&lt;/h2&gt;&lt;p&gt;I credit Justin Bois (Caltech) for teaching me about ECDFs, and Hugo Bowne-Anderson (DataCamp) for reinforcing the idea.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/6/17/git-tip-apply-a-patch/">
    <title type="text">Git Tip: Apply a Patch</title>
    <id>urn:uuid:91a163e7-561a-3b01-937e-dd71a96974c3</id>
    <updated>2018-06-17T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/6/17/git-tip-apply-a-patch/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I learned a new thing this weekend: we apparently can apply a patch onto a branch/fork using &lt;code&gt;git apply [patchfile]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There's a few things to unpack here. First off, what's a &lt;code&gt;patchfile&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;The long story cut short is that a &lt;code&gt;patchfile&lt;/code&gt; is nothing more than a plain text file that contains all information about &lt;code&gt;diffs&lt;/code&gt; between one commit and another. If you've ever used the &lt;code&gt;git diff&lt;/code&gt; command, you'll know that it will output a &lt;code&gt;diff&lt;/code&gt; between the current state of a repository, and the last committed state. Let's take a look at an example.&lt;/p&gt;
&lt;p&gt;Say we have a file, called &lt;code&gt;my_file.txt&lt;/code&gt;. In a real world example, this would be parallel to, say, a &lt;code&gt;.py&lt;/code&gt; module that you've written. After a bunch of commits, I have a directory structure that looks like this:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls
total &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;
drwxr-xr-x   &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; ericmjl  staff   128B Jun &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;:26 ./
drwx------@ &lt;span class=&quot;m&quot;&gt;19&lt;/span&gt; ericmjl  staff   608B Jun &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;:26 ../
drwxr-xr-x  &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt; ericmjl  staff   384B Jun &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;:27 .git/
-rw-r--r--   &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; ericmjl  staff    68B Jun &lt;span class=&quot;m&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;:26 my_file.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The contents of &lt;code&gt;my_file.txt&lt;/code&gt; are as follows:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat my_file.txt
Hello! This is a text file.

I have some text written inside here.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, let's say I edit the text file by adding a new line and removing one line.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat my_file.txt
Hello! This is a text file.

I have some text written inside here.

This is a new line!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If I looked at the &quot;diff&quot; between the current state of the file and the previous committed state of the file:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git diff my_file.txt
&lt;span class=&quot;gh&quot;&gt;diff --git a/my_file.txt b/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gh&quot;&gt;index a594a37..d8602e1 100644&lt;/span&gt;
&lt;span class=&quot;gd&quot;&gt;--- a/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gi&quot;&gt;+++ b/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gu&quot;&gt;@@ -1,4 +1,4 @@&lt;/span&gt;
 Hello! This is a text file.

&lt;span class=&quot;gd&quot;&gt;-I have some text written inside here.&lt;/span&gt;
&lt;span class=&quot;gi&quot;&gt;+This is a new line!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this may look intimidating at first, the key thing that one needs to look at is the &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;-&lt;/code&gt;. The &lt;code&gt;+&lt;/code&gt; signals that there is an addition of one line, and the &lt;code&gt;-&lt;/code&gt; signals the removal of one line.&lt;/p&gt;
&lt;p&gt;Turns out, I can export this as a file.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git diff my_file.txt &amp;gt; /tmp/patch1.txt
$ cat /tmp/patch1.txt
diff --git a/my_file.txt b/my_file.txt
index a594a37..d8602e1 &lt;span class=&quot;m&quot;&gt;100644&lt;/span&gt;
--- a/my_file.txt
+++ b/my_file.txt
@@ -1,4 +1,4 @@
 Hello! This is a text file.

-I have some text written inside here.
+This is a new line!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, let's simulate the scenario where I accidentally discarded those changes in the repository. A real-world analogue happened to me while contributing to CuPy: I had a really weird commit history, and couldn't remember how to rebase, so I exported the patch from my GitHub pull request (more on this later) and applied it following the same conceptual steps below.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git checkout -- my_file.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, the repository is in a &quot;cleaned&quot; state -- there are no changes made:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git status
On branch master
nothing to commit, working tree clean
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since I have saved the diff as a file, I can apply it onto my project:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git apply /tmp/patch1.txt
$ git status
On branch master
Changes not staged &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; commit:
  &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot;&lt;/span&gt; to update what will be committed&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&amp;quot;git checkout -- &amp;lt;file&amp;gt;...&amp;quot;&lt;/span&gt; to discard changes in working directory&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

        modified:   my_file.txt

no changes added to commit &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&amp;quot;git add&amp;quot;&lt;/span&gt; and/or &lt;span class=&quot;s2&quot;&gt;&amp;quot;git commit -a&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looking at the diff again, I've recovered the changes that were lost!&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git diff
&lt;span class=&quot;gh&quot;&gt;diff --git a/my_file.txt b/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gh&quot;&gt;index a594a37..d8602e1 100644&lt;/span&gt;
&lt;span class=&quot;gd&quot;&gt;--- a/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gi&quot;&gt;+++ b/my_file.txt&lt;/span&gt;
&lt;span class=&quot;gu&quot;&gt;@@ -1,4 +1,4 @@&lt;/span&gt;
 Hello! This is a text file.

&lt;span class=&quot;gd&quot;&gt;-I have some text written inside here.&lt;/span&gt;
&lt;span class=&quot;gi&quot;&gt;+This is a new line!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Don't forget to commit and push!&lt;/p&gt;
&lt;h2 id=&quot;how-to-export-a-patch-from-github?&quot;&gt;How to export a patch from GitHub?&lt;/h2&gt;&lt;p&gt;I mentioned earlier that I had exported the patch file from GitHub and then applied it on a re-forked repository. How does one do that? It's not as hard as you think.&lt;/p&gt;
&lt;p&gt;Here's the commands below with comments.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Download the patch from the pull request URL.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Replace curly-braced elements with the appropriate names.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Export it to /tmp/patch.txt.&lt;/span&gt;
$ wget https://github.com/&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;repo_owner&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;repo&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/pull/&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;pr_number&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;.patch -O /tmp/patch.txt

&lt;span class=&quot;c1&quot;&gt;# Now, apply the patch to your project&lt;/span&gt;
$ git apply /tmp/patch.txt
&lt;/pre&gt;&lt;/div&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/6/5/my-latent-dissatisfaction-with-modern-ml/">
    <title type="text">My Latent Dissatisfaction with Modern ML</title>
    <id>urn:uuid:2e5732c7-78fb-320e-a57e-6d2164ced345</id>
    <updated>2018-06-05T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/6/5/my-latent-dissatisfaction-with-modern-ml/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;It took reading Judea Pearl's &quot;The Book of Why&quot;, and Jonas Peters' mini-course on causality, for me to finally figure out why I had this lingering dissatisfaction with modern machine learning. It's because modern machine learning (deep learning included) is most commonly used as a tool in the service of finding correlations, and is not concerned with understanding systems.&lt;/p&gt;
&lt;p&gt;Perhaps this is why Pearl writes of modern ML as basically being &quot;curve fitting&quot;. I tend to believe he didn't write those words in a dismissive way, though I might be wrong about it. Regardless, I think there is an element of truth to that statement.&lt;/p&gt;
&lt;p&gt;Linear models seek a linear combination of correlations between input variables and their targets. Tree-based models essentially seek combinations of splits in the data, while deep learning models are just stacked compositions of linear models with nonlinear functions applied to their outputs. As Keras author Francois Chollet wrote, &lt;a href=&quot;https://blog.keras.io/the-limitations-of-deep-learning.html&quot;&gt;deep learning can be thought of as basically geometric transforms of data from one data manifold to another&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(For convenience, I've divided the ML world into linear models, tree-based models, and deep learning models. Ensembles, like Random Forest, are just that: ensembles composed of these basic models.)&lt;/p&gt;
&lt;p&gt;Granted, curve fitting is actually very useful: much of image deep learning has found pragmatic use: image search, digital pathology, self-driving cars, and more. Yet, in none of these models is the notion of causality important. This is where these models are dissatisfying: they do not provide the tools to help us interrogate these questions in a structured fashion. I think it's reasonable to say that these models are essentially concerned with conditional probabilities. As written by Ferenc Huszár, &lt;a href=&quot;http://www.inference.vc/untitled/&quot;&gt;conditional probabilities are different from interventional probabilities&lt;/a&gt; (ok, I mutilated that term).&lt;/p&gt;
&lt;p&gt;Humans are innately wired to recognize and ask questions about causality; consider it part of our innate makeup. That is, of course, unless that has been drilled out of our minds by our life experiences. (I know of a person who insists that causes do not exist. An extreme Hume-ist, I guess? As I'm not a student of philosophy much, I'm happy to be corrected on this point.) As such, I believe that part of being human involves asking the question, &quot;Why?&quot; (and its natural extension, &quot;How?&quot;). Yet, modern ML is still stuck at the question of, &quot;What?&quot;&lt;/p&gt;
&lt;p&gt;To get at why and how, we test our understanding of a system by perturbing it (i.e. intervening in it), or asking about &quot;what if&quot; scenarios (i.e. thinking about counterfactuals). In the real  world of biological research (which I'm embedded in), we call this &quot;experimentation&quot;. Inherent in a causal view of the world is a causal model. In causal inference, these things are structured and expressed mathematically, and we are given formal procedures for describing an intervention and thinking about counterfactual scenarios. From what I've just learned (baby steps at the moment), these are the basic ingredients, and their mathematical mappings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Causal model: a directed, acyclic graph&lt;ul&gt;
&lt;li&gt;Variables: nodes in a graph&lt;/li&gt;
&lt;li&gt;Relationships: structured causal model's equations (math transforms of incoming variables with a noise distribution added on top, embedded in each node)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Interventions: removal of edges in a graph (&quot;do-calculus&quot;)&lt;/li&gt;
&lt;li&gt;Counterfactuals: set causal model based on observation, then perform do-calculus.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having just learned this, I think there's a way out of this latent dissatisfaction that I have with modern ML. A neat thing about ML methods is that we can use them as tools to help us better identify the important latent factors buried inside our (observational) data, which we can use to construct a better model of our data generating process. Better yet, we can express the model in a structured and formal sense, which would expose our assumptions more explicitly for critique and reasoning. Conditioned on that, perhaps we may be able to write better causal models of the world!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/5/26/causal-modelling/">
    <title type="text">Causal Modelling</title>
    <id>urn:uuid:0d2239fc-b359-3a37-abfa-d50e0d2a6f01</id>
    <updated>2018-05-26T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/5/26/causal-modelling/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Finally, I have finished Judea Pearl's latest work &lt;a href=&quot;https://www.amazon.com/Book-Why-Science-Cause-Effect-ebook/dp/B075CR9QBJ/ref=mt_kindle?_encoding=UTF8&amp;amp;me=&quot;&gt;&quot;The Book of Why&quot;&lt;/a&gt;! Having read it, I have come to appreciate how much work had to go on in order to formalize the very intuitions that we have for causal reasoning into essentially a modelling language.&lt;/p&gt;
&lt;p&gt;&quot;The Book of Why&quot; is geared towards the layman reader. Thus, unlike a textbook, it does not contain &quot;simplest complex examples&quot; that a reader can walk through and do calculations by hand (or through simulation). Thankfully, there is a &lt;a href=&quot;https://www.youtube.com/playlist?list=PLW01hpWnEtbTcuY0a0jhZyanHX3GPImAy&quot;&gt;lecture series by Jonas Peters&lt;/a&gt;, organized by the Broad Institute and held at MIT, that are available freely online.&lt;/p&gt;
&lt;p&gt;From just viewing the first of the four lectures, I am thoroughly enjoying Jonas' explanations of the core ideas in causal modelling. Indeed, Jonas is a very talented lecturer! He builds up the ideas from simple examples, finally culminating in a &quot;simple complex example&quot; that we can simulate on a computer. Having just freshly read &quot;The Book of Why&quot; also helps immensely; it's also clear to me that people in the world of causal modelling are very much familiar with the same talking points. For those interested in learning more about causal modelling, I highly recommend both the book and the lecture series!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/5/6/model-baselines-are-important/">
    <title type="text">Model Baselines Are Important</title>
    <id>urn:uuid:f3d55548-fb27-39e0-bc0d-86413913fe59</id>
    <updated>2018-05-06T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/5/6/model-baselines-are-important/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;For any problem that we think is machine learnable, having a sane baseline is really important. It is even more important to establish them early.&lt;/p&gt;
&lt;p&gt;Today at ODSC, I had a chance to meet both Andreas Mueller and Randy Olson. Andreas leads &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;&lt;code&gt;scikit-learn&lt;/code&gt;&lt;/a&gt; development, while Randy was the lead developer of &lt;a href=&quot;https://github.com/EpistasisLab/tpot&quot;&gt;TPOT&lt;/a&gt;, an AutoML tool. To both of them, I told a variation of the following story:&lt;/p&gt;
&lt;p&gt;I had spent about 1.5 months building and testing a graph convolutions neural network model to predict RNA cleavage by an enzyme. I was suffering from a generalization problem - this model class would never generalize beyond the training samples for my problem on hand, even though I saw the same model class perform admirably well for small molecules and proteins.&lt;/p&gt;
&lt;p&gt;Together with an engineer at NIBR, we brainstormed a baseline with some simple features, and threw a random forest model at it. Three minutes later, after implementing everything, we had a model that generalized and outperformed my implementation of graph CNNs. Three days later, we had an AutoML (TPOT) model that beat the random forest. After further discussion, we realize then that the work that we did is sufficiently publishable even without the fancy graph CNNs.&lt;/p&gt;
&lt;p&gt;I think there’s a lesson in establishing baselines and MVPs early on!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/3/30/consolidate-your-scripts-using-click/">
    <title type="text">Consolidate your scripts using click</title>
    <id>urn:uuid:beec04f1-f5b9-3932-9d12-92337ec70fbb</id>
    <updated>2018-03-30T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/3/30/consolidate-your-scripts-using-click/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;&lt;p&gt;&lt;code&gt;click&lt;/code&gt; is amazing! It's a Python package that allows us to add a command-line interface (CLI) to our Python scripts easily. This blog post is a data scientist-oriented post on how we can use &lt;code&gt;click&lt;/code&gt; to build useful tools for ourselves. In this blog post, I want to focus on how we can better organize our scripts.&lt;/p&gt;
&lt;p&gt;I have found myself sometimes writing custom scripts to deal with custom data transforms. Having them refactored out into a library of modular functions can really help with maintenance. However, I still end up with multiple scripts that might not have a naturally logical organization... except for the fact that they are scripts that I run from time to time! Rather than have them scattered in multiple places, why not have them put together into a single &lt;code&gt;.py&lt;/code&gt; file, with options that are callable from the command line instead?&lt;/p&gt;
&lt;h2 id=&quot;template&quot;&gt;Template&lt;/h2&gt;&lt;p&gt;Here's a template for organizing all those messy scripts using  &lt;code&gt;click&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;click&lt;/span&gt;


&lt;span class=&quot;nd&quot;&gt;@click.group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;


&lt;span class=&quot;nd&quot;&gt;@main.command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;script1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Makes stuff happen.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# do stuff that was originally in script 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;click&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;script 1 was run!&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# click.echo is recommended by the click authors.&lt;/span&gt;


&lt;span class=&quot;nd&quot;&gt;@main.command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;script2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Makes more stuff happen.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# do stuff that was originally in script 2.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;script 2 was run!&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# we can run print instead of click.echo as well!&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;vm&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;how-to-use&quot;&gt;How to use&lt;/h2&gt;&lt;p&gt;Let's call this new meta-script &lt;code&gt;jobs.py&lt;/code&gt;, and make it executable.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ chmod +x jobs.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To execute it at the command line, we now a help command for free:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./jobs.py --help
Usage: jobs.py &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;OPTIONS&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; COMMAND &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ARGS&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;...

Options:
  --help  Show this message and exit.

Commands:
  script1  Makes stuff happen.
  script2  Makes more stuff happen.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can also use just one script with varying commands to control the execution of what was originally two different &lt;code&gt;.py&lt;/code&gt; files.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./jobs.py script1
script &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; was run!
$ ./jobs.py script2
script &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; was run!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead of versioning multiple &lt;code&gt;.py&lt;/code&gt; files, we now only have to keep track of one file where all non-standard custom stuff goes!&lt;/p&gt;
&lt;h2 id=&quot;details&quot;&gt;Details&lt;/h2&gt;&lt;p&gt;Here's what's going on under the hood.&lt;/p&gt;
&lt;p&gt;With the decorator &lt;code&gt;@click.group()&lt;/code&gt;, we have exposed the &lt;code&gt;main()&lt;/code&gt; function from the command line as a &quot;group&quot; of commands that are callable from the command line. What this does is then &quot;wrap&quot; the &lt;code&gt;main()&lt;/code&gt; function (somehow), such that now it can be used to decorate another function (in our case, &lt;code&gt;script1&lt;/code&gt; and &lt;code&gt;script2&lt;/code&gt;) using the decorator syntax &lt;code&gt;@main.command()&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Consolidate disparate Python scripts into a single &lt;code&gt;.py&lt;/code&gt;  file, wrapping them inside a callable function.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;click&lt;/code&gt; to expose them to the end-user (yourself, or others) at the command line.&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/28/lessons-learned-and-reinforced-from-writing-my-own-deep-learning-package/">
    <title type="text">Lessons learned and reinforced from writing my own deep learning package</title>
    <id>urn:uuid:390270b7-9d7b-306c-9ead-2617aac7af0a</id>
    <updated>2018-02-28T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/28/lessons-learned-and-reinforced-from-writing-my-own-deep-learning-package/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;At work, I’ve been rolling my own deep learning package to experiment with graph convolutional neural networks. I did this because in graph-centric deep learning, an idea I picked up from this paper, the inputs, convolution kernels, and much more, are being actively developed, and the standard APIs don’t fit with this kind of data.&lt;/p&gt;
&lt;p&gt;Here’s lessons I learned (and reinforced) while doing this.&lt;/p&gt;
&lt;h2 id=&quot;autograd-is-an-amazing-package&quot;&gt;&lt;code&gt;autograd&lt;/code&gt; is an amazing package&lt;/h2&gt;&lt;p&gt;I am using &lt;code&gt;autograd&lt;/code&gt; to write my neural networks. &lt;code&gt;autograd&lt;/code&gt; provides a way to automatically differentiate &lt;code&gt;numpy&lt;/code&gt; code. As long as I write the forward computation up to the loss function, &lt;code&gt;autograd&lt;/code&gt; will be able to differentiate the loss function w.r.t. all of the parameters used, thus providing the direction to move parameters to minimize the loss function.&lt;/p&gt;
&lt;h2 id=&quot;deep-learning-is-nothing-more-than-chaining-elementary-differentiable-functions&quot;&gt;Deep learning is nothing more than chaining elementary differentiable functions&lt;/h2&gt;&lt;p&gt;Linear regression is nothing more than a dot product of features with weights and adding bias terms. Logistic regression just chains the logistic function on top of that. Anything deeper than that is what we might call a neural network.&lt;/p&gt;
&lt;p&gt;One interesting thing that I've begun to ponder is the shape of the loss function, and how it changes when I change model architecture, activation functions, and more. I can't speak intelligently about it right now, but from observing the training performance live (I update a plot of predictions vs. actual values at the end of &lt;code&gt;x&lt;/code&gt; training epochs), different combinations of activation functions seem to cause different behaviours of the outputs, and there's no first-principles reason why that I can think of. All-told, pretty interesting :).&lt;/p&gt;
&lt;h2 id=&quot;defining-a-good-api-is-hard-work&quot;&gt;Defining a good API is hard work&lt;/h2&gt;&lt;p&gt;There are design choices that go into the API design. I first off wanted to build something familiar, so I chose to emulate the functional API of Keras and PyTorch and Chainer. I also wanted composability, in which I can define modules of layers and chain them together, so I opted to use Python objects and to take advantage of their &lt;code&gt;__call__&lt;/code&gt; method to achieve both goals. At the same time, &lt;code&gt;autograd&lt;/code&gt; imposes a constraint in that I need to have functions differentiable with respect to their first argument, an array of parameters. Thus, I had to make sure the weights and biases are made transparently available for &lt;code&gt;autograd&lt;/code&gt; to differentiate. As a positive side effect, it means I can actually inspect the parameters dictionary quite transparently.&lt;/p&gt;
&lt;h2 id=&quot;optimizing-for-speed-is-a-very-hard-thing&quot;&gt;Optimizing for speed is a very hard thing&lt;/h2&gt;&lt;p&gt;Even though I'm doing my best already with matrix math (and hopefully getting better at mastering 3-dimensional and higher matrix algebra), in order to keep my API clean and compatible with &lt;code&gt;autograd&lt;/code&gt; (meaning no sparse arrays), I have opted to use lists of &lt;code&gt;numpy&lt;/code&gt; arrays.&lt;/p&gt;
&lt;h2 id=&quot;graph-convolutions-have-a-connection-to-network-propagation&quot;&gt;Graph convolutions have a connection to network propagation&lt;/h2&gt;&lt;p&gt;I will probably explore this a bit more deeply in another blog post, but yes, as I explore the math involved in doing graph convolutions, I'm noticing that there's a deep connection there. The short story is basically &quot;convolutions propagate information across nodes&quot; in almost exactly the same way as &quot;network propagation methods share information across nodes&quot;, through the use of a kernel defined by the adjacency matrix of a graph.&lt;/p&gt;
&lt;p&gt;Ok, that's a lot of jargon, but I promise I will explore this topic at a later time.&lt;/p&gt;
&lt;h2 id=&quot;open-sourcing&quot;&gt;Open Sourcing&lt;/h2&gt;&lt;p&gt;I'm an avid open source fan. Lots of my work builds on it. However, because this &quot;neural networks on graphs&quot; work is developed on company time and for company use, this will very likely be the first software project that I send to Legal to evaluate whether I can open source/publish it or not -- I'll naturally have to make my strongest case for open sourcing the code base (e.g. ensuring no competitive intelligence is leaked), but eventually will still have to defer to them for a final decision.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/26/joy-from-teaching/">
    <title type="text">Joy from teaching</title>
    <id>urn:uuid:5c9209f0-4531-3b75-b34a-ceb067bc526c</id>
    <updated>2018-02-26T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/26/joy-from-teaching/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;It always brings me joy to see others benefit from what I can offer.&lt;/p&gt;
&lt;p&gt;Thanks for &lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:6373939725656563713&quot;&gt;sharing the fruits of your journey&lt;/a&gt; on LinkedIn, Umar!&lt;/p&gt;
&lt;p&gt;Also a big thanks to the others who have finished the course! I hope you have enjoyed the learning journey, and were able to find problems to apply your newly-gained knowledge!&lt;/p&gt;
&lt;p&gt;With big thanks to &lt;a href=&quot;https://www.datacamp.com/&quot;&gt;DataCamp&lt;/a&gt; as well, for the development of their platform, enabling us to do teaching even outside of the academy! (Special shout-out to Hugo Bowne-Anderson and Yashas Roy, with whom I've personally partnered with to make the content go live.)&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/25/annotating-code-tests-and-selectively-running-tests/">
    <title type="text">Annotating code tests and selectively running tests</title>
    <id>urn:uuid:58ec5548-622e-3171-a4e9-74776a93d076</id>
    <updated>2018-02-25T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/25/annotating-code-tests-and-selectively-running-tests/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I just learned about a neat trick when using &lt;code&gt;pytest&lt;/code&gt; - the ability to &quot;mark&quot; tests with metadata, and the ability to selectively run groups of marked tests.&lt;/p&gt;
&lt;p&gt;Here's an example:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pytest&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;@pytest.mark.slow&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# annotate it as a &amp;quot;slow&amp;quot; test&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_that_runs_slowly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;@pytest.mark.slow&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# annotate test as a &amp;quot;slow&amp;quot; test.&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@pytest.mark.integration&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# annotate test as being an &amp;quot;integration&amp;quot; test&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_that_does_integration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What's really cool here is that I can selectively run slow tests or selectively run integration tests:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ py.test -m &lt;span class=&quot;s2&quot;&gt;&amp;quot;slow&amp;quot;&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# only runs &amp;quot;slow&amp;quot; tests&lt;/span&gt;
$ py.test -m &lt;span class=&quot;s2&quot;&gt;&amp;quot;integration&amp;quot;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# only runs &amp;quot;integration&amp;quot; tests&lt;/span&gt;
$ py.test -m &lt;span class=&quot;s2&quot;&gt;&amp;quot;not integration&amp;quot;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# only runs tests that are not &amp;quot;integration&amp;quot; tests.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/21/nxviz-first-pr-merged/">
    <title type="text">nxviz first PR merged!</title>
    <id>urn:uuid:12691a84-54fb-355f-a79b-2f656232a743</id>
    <updated>2018-02-21T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/21/nxviz-first-pr-merged/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;With thanks to &lt;a href=&quot;https://twitter.com/KassnerNora&quot;&gt;@KassnerNora&lt;/a&gt;, &lt;a href=&quot;https://github.com/ericmjl/nxviz&quot;&gt;&lt;code&gt;nxviz&lt;/code&gt;&lt;/a&gt; has a new feature! Now, it is possible to specify the data to use to colour edges. Previously, this was available in the API but was not working as I had not the time to implement it.&lt;/p&gt;
&lt;p&gt;Now, with &lt;a href=&quot;https://github.com/ericmjl/nxviz/pull/260&quot;&gt;Nora's PR&lt;/a&gt; merged in, users can declare their edges to be coloured by some edge metadata key! In addition to that, Nora included a &lt;code&gt;seaborn&lt;/code&gt; colour palette that may be useful for drawing other edge colours. The API remains a declarative API, giving users an easy way to specify how they want rational graph plots to be made.&lt;/p&gt;
&lt;p&gt;Thank you for the contribution, Nora!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/20/deep-learning-and-the-importance-of-a-good-teacher/">
    <title type="text">Deep Learning and the Importance of a Good Teacher</title>
    <id>urn:uuid:06ad28dc-a618-3792-a8d5-1cc5645cb01b</id>
    <updated>2018-02-20T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/20/deep-learning-and-the-importance-of-a-good-teacher/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I can’t emphasize this enough - someone who teaches well can really open their student’s minds.&lt;/p&gt;
&lt;p&gt;On my journey in to deep learning and now graph convolutions, &lt;a href=&quot;../../../../../blog/2018/2/20/deep-learning-and-the-importance-of-a-good-teacher/www.cs.toronto.edu/~duvenaud/&quot;&gt;David Duvenaud&lt;/a&gt; (currently a professor at the University of Toronto) simultaneously taught me, a newcomer to deep learning, the basics of deep learning and the mechanics behind the graph convolutional neural network he and his colleagues had just published. The key insight he passed on to me was that deep learning was nothing more than chaining differentiable functions together. Many times I’d ask him, “so does this mean I can do that operation?”, and the answer would usually be “yeah, why not?”.&lt;/p&gt;
&lt;p&gt;Knowing this point has made me realize how flexible deep learning really is. Once I got under the hood of what deep learning really was, then I realized that actually, DL is all about chaining together math functions one after another. Best part is, we get to define what those math functions are!&lt;/p&gt;
&lt;p&gt;Knowing this has also helped me when I read new DL papers. It’s now a lot easier to for me to tell when a research group has come up with something very different from the rest of the pack as opposed to advancing existing methods.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/13/data-scientists-need-to-write-good-apis/">
    <title type="text">Data scientists need to write good APIs</title>
    <id>urn:uuid:53402dcb-b8ee-3f08-923d-b30a8e94a285</id>
    <updated>2018-02-13T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/13/data-scientists-need-to-write-good-apis/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I had a breakthrough in my work today. This was not some scientific epiphany, but just breaking through a wall in my progress. Today's breakthrough  was totally enabled by writing my class definitions in a way that made sense, and by writing class methods that enabled me to express my ideas in a literate fashion.&lt;/p&gt;
&lt;p&gt;Logical class definitions and methods, refactored functions... these should be reflexive habits, but unfortunately, this isn't always the case with data science. We get so caught up in writing the code to make that plot that we forget to refactor out so that the block of code isn't brittle. But that brittle code means that my future self will loathe my current self for not writing that code robustly.&lt;/p&gt;
&lt;p&gt;In other words, write good APIs.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/7/bayesian-inference-and-testing-sets/">
    <title type="text">Bayesian Inference &amp; Testing Sets</title>
    <id>urn:uuid:ef48ae04-9b7a-3b04-a221-bf4e0f46d296</id>
    <updated>2018-02-07T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/7/bayesian-inference-and-testing-sets/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;This topic recently came up again on the &lt;a href=&quot;https://discourse.pymc.io/t/do-we-need-a-testing-set/759/5&quot;&gt;PyMC3 discourse&lt;/a&gt;. I had an opportunity to further clarify what I was thinking about when I first uttered the train/test split comment &lt;a href=&quot;https://www.youtube.com/watch?v=s0S6HFdPtlA&quot;&gt;at PyData NYC&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After a little while, my thoughts for a layperson are a bit clearer, and I thought I'd re-iterate them here.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Model specification uncertainty: Did we get the conditional relationships correct? Did we specify enough of the explanatory variables?&lt;/li&gt;
&lt;li&gt;Model parameter uncertainty: Given a model, can we quantify the uncertainty in the parameter values?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These are different uncertainties to deal with. We must be clear: where we are pretty sure about the model spec, Bayesian inference is about quantifying the uncertainty in the parameter values. Under this paradigm, if we use more data, we get narrower posterior distributions, and if we use less data, we get wider posterior distributions. If we split the data, we're just feeding in fewer data points to the model; if we don't, then we're just feeding in more data points.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/2/6/pycon-program-committee-review/">
    <title type="text">PyCon Program Committee Review</title>
    <id>urn:uuid:017a77c3-861d-34cd-82ec-12512e56f66f</id>
    <updated>2018-02-06T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/2/6/pycon-program-committee-review/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;This year, I participated in the PyCon 2018 program committee (ProgCom). Though it was my second time doing it, it nonetheless was an eye-opening experience. This was because in contrast to last year, when I was writing my thesis and thus couldn't follow through on both rounds of review, this year I was. I’d like to write a bit about my thoughts on the process, with three-fold goals:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;To document my experience reviewing this year's PyCon talks.&lt;/li&gt;
&lt;li&gt;To bring a little bit more transparency to the process. (Proposal authors, understandably, might feel like the process is opaque.)&lt;/li&gt;
&lt;li&gt;To indirectly encourage others to participate in the process by demystifying what goes on in the mind of a reviewer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Before I go on, though I do want to make a few points clear on what I will not be doing in this blog post.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I will not be commenting on any particular proposal.&lt;/li&gt;
&lt;li&gt;I will not be mentioning specific reviewers' names and what they commented on specific proposals.&lt;/li&gt;
&lt;li&gt;I will not be offering tips for making your proposal succeed next year - that will depend on what next year’s program committee is looking for.&lt;/li&gt;
&lt;li&gt;I will not be describing the review process in detail, as this will be dealt with by an &quot;official&quot; blog post from the PSF.&lt;/li&gt;
&lt;li&gt;This blog post is definitely not an invitation to review your current round or next round proposal, as with a full-time job, I currently don't have the bandwidth for that.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ready to read on? Let's go!&lt;/p&gt;
&lt;h2 id=&quot;stage-1:-scoring&quot;&gt;Stage 1: Scoring&lt;/h2&gt;&lt;p&gt;The process for selecting talks is a two-stage process. In the first stage, we are rating the talks qualitatively (ordinally) on six criteria (for which I will defer to the official PSF blog post for details when it comes out). &lt;strong&gt;At this stage, we are blinded to a speaker's name and prior experience&lt;/strong&gt;, as we want to review only the content on its merits. I'd like to give my thoughts on a few of the criteria below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On &quot;code of conduct&quot;&lt;/strong&gt;, this criteria ensures that there's no disparaging of sub-communities. I generally ding'ed talks that carried any hints of negativity, as I'd like to see PyCon be a positive force in the community. A few proposals were easily misconstrued as being negative, even though they weren't in substance; we tried our best to communicate this concern to proposal authors. That said, most talks are technical in nature, thus this criteria was not really an issue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On &quot;completeness&quot;&lt;/strong&gt;, it's really as about seeing whether an author demonstrated the meticulousness in making it easy for us to review. Timings were super important to me, to gauge whether I thought the talk proposer had over- or under-proposed content. I also sought detail to evaluate the accuracy of content and connect the sub-points into the author's overall message. The additional detail made it easier for me to champion a talk in the later stages.&lt;/p&gt;
&lt;p&gt;A few authors, while in communication with the ProgCom, flat-out refused to add in details after I had messaged them requesting details, citing other conferences' practices. Unfortunately, each conference is going to be slightly different in how they operate, and that ongoing dialogue can indirectly influence reviewers' perception and therefore the proposal's score. We're all human, and if a talk proposer comes off as uncooperative, especially when we provide an ongoing opportunity to engage in dialogue, it just makes it tougher to justify their elevated presence as a speaker at a conference that emphasizes cooperation and community.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On &quot;coherence&quot;&lt;/strong&gt;, this point somewhat overlaps with &quot;completeness&quot;, in that the accuracy of content can help boost this criteria. A good talk would cover one sufficiently focused topic for 30 minutes (or 45 minutes if request in sufficient depth.&lt;/p&gt;
&lt;p&gt;I think that what constitutes &quot;sufficient&quot; depends on our state of knowledge. For example, in data science, I would view it as not sufficient to speak on &quot;how to do a data analysis&quot;, as it is now quite clear that each analysis is quite different, and the generalizable principles are too vague to be of use for a listener. On the other hand, speaking about solving a particular (data) science problem can be illuminating with solid take-aways for an audience members.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other non-explicit criteria can affect the perception of a proposal&lt;/strong&gt;. At this stage, we're doing an ongoing dialogue with proposal authors, up till the submission deadline. Thus, as mentioned above, an authors' cooperativeness can affect our perception of the proposal, particularly on the &quot;code of conduct&quot; criteria - it'll affect whether we can trust an author's ability to adhere to the code of conduct. Additionally, having good English grammar can affect how readable the proposal is. Finally, there is something qualitatively different about a proposal by an author who is deeply passionate about their topic and believes they have something important to say, in contrast to a proposal author who is merely trying to fulfill PyCon selection criteria. I want to hear from the former, not the latter.&lt;/p&gt;
&lt;h2 id=&quot;stage-2:-selection&quot;&gt;Stage 2: Selection&lt;/h2&gt;&lt;p&gt;At this stage, we looked at the composition of talks, and proposed &quot;buckets&quot; of topics that the talks covered. This means that the &quot;topics&quot; are defined by what the community puts together. In total, there were &amp;gt;60+ groups of talks.&lt;/p&gt;
&lt;p&gt;In this stage, we are basically looking for one talk to emerge from each group. The unfortunate reality is that there will be some groups that are small (3 talks), and some groups that are large (&amp;gt;15 talks), and many groups in between, meaning not every talk has an &quot;equal&quot; chance of making it through. This is entirely dependent on what the community has submitted, though, so there's no easy way to control for this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;At this stage, we are also debating what kind of conference we want.&lt;/strong&gt; This is where it gets super interesting, and the idiosyncracies of each ProgCom member will show through. Here's a sampling of questions that went through my mind.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do we want one in which mature talks are rehashed from the three other conferences it's already been at, or do we want new talks to come to prominence?&lt;/strong&gt; It's not an easy decision - for some topics we favoured new ones, and for others we favoured mature talks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do we want experienced speakers or do we want to encourage new ones to come up?&lt;/strong&gt; This one is relatively easy - we hard-limited speakers to one talk; some speakers proposed 5 or 6 of them, but we only take one, to enable other speakers to be present. This gives more room for newcomers to speak.&lt;/p&gt;
&lt;p&gt;For me, there were some experienced speakers giving new talks, and I knew they'd be able to pull it off given their track record; I favoured them on both merits: experience and topical novelty. On the other hand, there were experienced speakers taking a single talk around the conference circuit - for these talks, if they were publicly available online, I didn't favour them, and communicated that to other members of the ProgCom team.&lt;/p&gt;
&lt;p&gt;Amongst new speakers (and relatively unknown speakers) at PyCon, I was looking for slide decks to evaluate their message, and recordings of other talks that they had done. Knowing that there's a catch-22 problem (new speaker approximately means no recordings), I also tried looking in greater detail at the proposal for hints and clues that the speaker knew in great depth what they were speaking about, and were confident about delivering it. (Generally, good amounts of non-jargony detail highlight a speaker's capacity for mastery and communication skills simultaneously.)&lt;/p&gt;
&lt;p&gt;My advocacy for new speakers and new talks, and advocacy against talks that had been given at other conferences, particularly those which had a public recording available online, stems from my desire to see PyCon be complementary to other conferences. We're programmers, and I thInk Don't Repeat Yourself (DRY) is a good general principle to adhere to. Other ProgCom members were also free to disagree with my advocacy, as are you, the reader.&lt;/p&gt;
&lt;p&gt;In deciding on whether to include some evergreen topics at a beginners level or not, I looked to history to help me decide. For example, we hadn't had a beginner-friendly live talk on testing for the past few years, so I advocated in favour of that, even though one other program committee member disagreed and preferred to have more advanced testing talks in the program.&lt;/p&gt;
&lt;p&gt;One topic that I was super torn by when voting was in the Bayesian Statistics category. Two talks, one extremely topical and beginner friendly, the other deeply technical but extremely useful in a variety of domains, both by speakers whom I've learned from in the past. I couldn't bring myself to pick one, so I voted for both and communicated this guidance to others on the team, and let them cast the deciding vote.&lt;/p&gt;
&lt;p&gt;Finally, as a machine learner, I have been frustrated by new libraries that don't respect existing community idioms, however idiosyncratic those idioms are. One particular pet peeve is libraries that reinvent similar-yet-slightly-different APIs. There are a myriad of DataFrame APIs out there, yet I've only seen Dask do its best to explicitly implement the Pandas API. Likewise, there are a myriad of GPU tensor libraries out there, but I've only seen CuPy explicitly implement the NumPy API, which is idiomatic in the Python community. I thus strongly advocated for talks that described projects that explicitly adhered to and built on top of community idioms.&lt;/p&gt;
&lt;h2 id=&quot;gratitude-towards-the-team&quot;&gt;Gratitude towards the team&lt;/h2&gt;&lt;p&gt;I'm not ProgCom's fearless leader (Jason Myers, whose name will be public anyways, is our fearless leader (and spreadsheet maestro) – and yes, I know I mentioned a second name here), but I nonetheless feel a ton of gratiutde towards the team. We worked asynchronously, distributed around globe in a myriad of time zones. We gave incisive insight into topics, and educated each other on our respective areas of expertise. I learned and got excited about new topics in Python. We debated and advocated for a PyCon that we'd all be proud of presenting back to the community.&lt;/p&gt;
&lt;h2 id=&quot;encouragement-for-speakers-accepted-and-turned-down&quot;&gt;Encouragement for speakers, accepted and turned down&lt;/h2&gt;&lt;p&gt;As part of PyCon's program committee in 2018, I'm proud to congratulate speakers accepted to this year's PyCon talk lineup!&lt;/p&gt;
&lt;p&gt;To those who were turned down (myself included), I would like to offer up a picture of the reality we faced: some talks were decided by a single vote; at other times, we had to decide between two proposals submitted independently that paralleled each other; yet at other times, we saw such a big cluster of talks that we knew we wanted to hear, yet could only pick a handful because we didn't have an Education Summit-like dedicated track to accommodate all of them. Tough choices left and right. Don't be discouraged, you have important things to say, and there are many awesome Python-related venues (SciPy &amp;amp; PyData) to present at.&lt;/p&gt;
&lt;p&gt;For those whose data science talks were turned down, ping me on Twitter @ericmjl: I'd love to organize a Data Science Summit with you at PyCon 2019!&lt;/p&gt;
&lt;h2 id=&quot;addressing-potential-lingering-questions&quot;&gt;Addressing potential lingering questions&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Does everybody on the ProgCom have the qualifications to review every talk proposal submitted?&lt;/strong&gt; Definitely not. I have a knowledge bias towards the data science talks, and could handle some of the web talks, but I was completely unqualified to review talks on security and Python internals. Thus, for the data science talks, I offered my guidance to the rest of the ProgCom on what would be useful to speak about, but deferred to the expertise of others for talks I could not intelligently comment on. More than once I found myself re-voting based on other expert opinions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Without a fixed criteria on hand, how can talk proposers maximize their chances of getting their talk accepted?&lt;/strong&gt; This “criteria” (if you want to call it that) develops organically over time. This is intentional, as PyCon is a community conference, not a topical conference. By not setting explicit topical criteria, we can solicit talks from the community that range from timely to evergreen, from specialized to broad, and beyond, allowing the community to speak for itself (pun, ahem, not intended).&lt;/p&gt;
&lt;p&gt;This is not to say that PyCon couldn't become a topical conference, in which the ProgCom solitics proposals in particular pre-defined categories. If this changes, I'd love for next year's ProgCom to be explicit about this change, so that proposal authors have enough time to prepare for it.&lt;/p&gt;
&lt;p&gt;Moreover, new topical areas can be proposed: if I am remembering history correctly, this is how the Education Summit came into being (though I'm happy to be corrected if I'm wrong). If anybody's up for it, I'd love for a topical &quot;Data Science Summit&quot; at PyCon to come to life as well! Let's propose it together next year through the Hatchery Program.&lt;/p&gt;
&lt;p&gt;Back to the question, though: if you're thinking of this question, your proposal is probably not the one I would vote in favour of. I personally would like to hear from speakers who are deeply technical and can inject passion into a room through their technical talk, rather than from someone who was trying to tick checkboxes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you're on the ProgCom, does this mean you can't propose a talk?&lt;/strong&gt; Of course you can propose a talk! :) Our previous fearless leader, Ned Jackson Lovely, wrote an open source app that hides our own talks from our own review, thus enabling us to remain impartial. For what it's worth, my own talk was not accepted by the ProgCom, but I have no hard feelings about it - it was placed in a category with (I think) 21 talks, making that category super competitive.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/1/29/refactor-notebook-code/">
    <title type="text">Refactor Notebook Code</title>
    <id>urn:uuid:d502b49d-f207-3319-a533-01b3b17c9330</id>
    <updated>2018-01-29T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/1/29/refactor-notebook-code/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Jupyter notebooks that are filled with complex analyses can get unwieldy. Refactoring repeated code out into functions placed in modules should be standard practice, but from the sampling of Jupyter notebooks I've seen, I don't think this is standard practice.&lt;/p&gt;
&lt;p&gt;When should code be refactored? As soon as we start copying/pasting it! Making sure I have self-contained functions ensures that lingering state in my notebook doesn't cause unexpected behaviour. (Side note: learning the &quot;functional&quot; programming mindset can be very useful here!)&lt;/p&gt;
&lt;p&gt;But won't this slow down my pace? Isn't it faster to just copy and paste the code, and tweak what I need? Yes, but a small speed hit is going to be traded for a massive bump in rigour. Just today, I saw the effects of &quot;lingering state&quot; in my notebooks causing my plots to display different things before and after refactoring. It's not a good sign for any analysis if this happens.&lt;/p&gt;
&lt;p&gt;In short, refactor your code.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/1/18/pymc3-docs-weibull-patches-merged/">
    <title type="text">PyMC3 docs + Weibull patches merged!</title>
    <id>urn:uuid:337ce668-8116-366a-b9dc-903308b761a6</id>
    <updated>2018-01-18T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/1/18/pymc3-docs-weibull-patches-merged/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I recently had a few PRs merged into the PyMC3 codebase. Really happy about it, and just like my previous bug fix, I thought I'd share a bit about how those PRs came about.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/pymc-devs/pymc3/pull/2789&quot;&gt;first PR&lt;/a&gt; was an update to the docs on when to specify precision and when to specify standard deviation. They're related, so only one has to be specified, but I sometimes am sloppy when reading the docs and didn't pick up on that. Thus, I added a few lines to make sure this was crystal clear to sloppy readers like me.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/pymc-devs/pymc3/pull/2799&quot;&gt;next PR&lt;/a&gt; was an update to the Mixture model docs, in which I added an example of the new API for specifying components of mixture models. It previously wasn't clear how to do this, as there were no examples provided, so I put in a documentation PR specifying examples.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/pymc-devs/pymc3/pull/2804&quot;&gt;final PR&lt;/a&gt; was a patch to the Weibull distribution. I wanted to play around with trying mixture Weibulls at work, but mixture Weibulls wouldn't work because it didn't have a mode specified. I checked on Wikipedia, and found that Weibull's mode is conditional on the value of its parameters, and thus put in a PR to make this happen. &lt;a href=&quot;https://github.com/ericmjl/bayesian-analysis-recipes/blob/master/notebooks/mixture-model.ipynb&quot;&gt;Trying it out on some simulated/toy data&lt;/a&gt;, it worked! Thus, the devs allowed it to be merged.&lt;/p&gt;
&lt;p&gt;A few lessons I've learned along the way:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) Docs are an awesome place to start.&lt;/strong&gt; In fact, I made a few formatting mistakes in my first and second PRs that gave an opportunity for another guy to fix! Nothing is too small to be made as a contribution. FWIW, my first contribution to open source software were documentation fixes for &lt;code&gt;matplotlib&lt;/code&gt;, and that was a superb learning journey!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) Friendly maintainers are crucial.&lt;/strong&gt; The PyMC dev team can basically be described as, &quot;generally super nice!&quot; From the online and in-person interactions I've had with them, there's little in the way of egos, they're always learning, always being generally helpful. If they weren't that way, I very likely would have second thoughts trying putting in a PR there.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3) Open source lets me fix bugs I find.&lt;/strong&gt; This lets me work at the pace that I need to, without having to wait for commercial vendors to provide update patches. If the patch that I find turns out to be useful for others, then the work I did can possibly save a ton of people's time as well. Win-win scenario!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/1/10/offline-time/">
    <title type="text">Offline Time</title>
    <id>urn:uuid:9c643c98-4cfc-3fe2-ac9a-d2ee9f8ad34f</id>
    <updated>2018-01-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/1/10/offline-time/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I was locked out of my work computer due to password reasons. (It's not human error - something about corporate management tools locked me out. Okay, well, that's human error too.) That said, I inadvertently gained a full two hours of offline time on Monday.&lt;/p&gt;
&lt;p&gt;Those two hours turned out to be pretty productive. I spent some time sketching out my work projects, trying to make better sense of how the project could fit in a disease area researcher's workflow, and figuring out derivative analyses that could enhance the value to them. This was something I probably wouldn't be able to accomplish if I had the regular distractions of my computer nearby.&lt;/p&gt;
&lt;p&gt;Seems like Cal Newport's &quot;digital distraction de-cluttering&quot; is a good thing to do. I must do more of it.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2018/1/8/bayesian-uncertainty-a-more-nuanced-view/">
    <title type="text">Bayesian Uncertainty: A More Nuanced View</title>
    <id>urn:uuid:c8e9b5e3-9f3c-38d6-9605-cd46842f22ae</id>
    <updated>2018-01-08T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2018/1/8/bayesian-uncertainty-a-more-nuanced-view/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;The following thought hit my mind just last night.&lt;/p&gt;
&lt;p&gt;Bayesian inference requires the computation of uncertainty. Computing that uncertainty is computationally expensive compared to simply computing point estimates/summary statistics. But when exactly is uncertainty useful, and more importantly, actionable? That's something I've not really appreciated in the past. It's probably not productive to be dogmatic about always computing uncertainty if that uncertainty is not actionable.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/12/13/visual-studio-code-a-new-microsoft/">
    <title type="text">Visual Studio Code: A New Microsoft?</title>
    <id>urn:uuid:06b625f2-4e15-3653-91b0-2f759200dd68</id>
    <updated>2017-12-13T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/12/13/visual-studio-code-a-new-microsoft/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;During my week attending PyData NYC 2017, which was effectively a mini-mini-sabbatical from work, I got a chance to try out Visual Studio Code. Part of it was curiosity, having seen so many PyData participants using it; part of it was because of Steve Dowell, a core CPython contributor who works at Microsoft, who mentioned about the Python-friendly tools they added into VSCode.&lt;/p&gt;
&lt;p&gt;I think VSCode is representative of a new Microsoft.&lt;/p&gt;
&lt;p&gt;But first, let me describe what using it is like.&lt;/p&gt;
&lt;h2 id=&quot;user-interface&quot;&gt;User Interface&lt;/h2&gt;&lt;p&gt;First off, the UI is beautiful. It's impossible to repeat enough how important the UI is. With minimal configuration, I made it basically match Atom's UI, which I had grown used to. It has an integrated terminal, and the colours are... wow. That shade of green, blue and red are amazing, ever just so slightly muted compared to the Terminal or iTerm. The background shade of black matches well with the rest of VSCode, and the colour scheme is changeable to match that of Atom's. The design feels... just right. Wow!&lt;/p&gt;
&lt;h2 id=&quot;git-integration&quot;&gt;Git Integration&lt;/h2&gt;&lt;p&gt;Secondly, the integration with Git rivals Atom; in fact, there's a one-click &quot;sync&quot; button! It also has nice &lt;code&gt;git commit -am&lt;/code&gt; analog where I can add and commit all of the files simultaneously.&lt;/p&gt;
&lt;h2 id=&quot;intellisense&quot;&gt;Intellisense&lt;/h2&gt;&lt;p&gt;Thirdly, IntelliSense is just amazing! I like how I can use it to look up a function signature just by mousing over the function name.&lt;/p&gt;
&lt;h2 id=&quot;open-source&quot;&gt;Open Source&lt;/h2&gt;&lt;p&gt;Finally, it’s fully open source and back able, in the same vein as Atom, minus the bloat that comes from building on top of electron. Impressive stuff!&lt;/p&gt;
&lt;h2 id=&quot;other-thoughts&quot;&gt;Other Thoughts&lt;/h2&gt;&lt;p&gt;Now, on the new Microsoft.&lt;/p&gt;
&lt;p&gt;Only at the recent PyData NYC did I learn that Microsoft has hired almost half of the core CPython developers! Not only that, they are encouraged to continue their contributions into the CPython code base. In my view, that’s a pretty awesome development! It means the Python programming language will continue to have a strong corporate backing while also enjoying community support. Its a sign of a healthy ecosystem, IMO, and also a sign of Microsoft’s support for Open Source Software!&lt;/p&gt;
&lt;p&gt;I’m more and more impressed by what Microsoft is doing for the Open Source community. I’m hoping they’ll continue up with this!!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/11/30/pydata-nyc-2017-recap/">
    <title type="text">PyData NYC 2017 Recap</title>
    <id>urn:uuid:69d8bdba-18aa-34f8-961d-a08fcc38cc72</id>
    <updated>2017-11-30T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/11/30/pydata-nyc-2017-recap/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;With that, we’ve finished PyData NYC! Here's some of my highlights of the conference.&lt;/p&gt;
&lt;h2 id=&quot;keynotes&quot;&gt;Keynotes&lt;/h2&gt;&lt;p&gt;There were three keynotes, one each by Kerstin Kleese van Dam, Thomas Sargent, and Andrew Gelman. Interestingly enough, they didn't do what I would expect most academics to do -- give talks highlighting the accomplishments of their research groups. Rather, Kerstin gave a talk that highlighted the use of PyData tools at Brookhaven National Labs. Thomas Sargent gave a philosophical talk on what economic models really are (they're &quot;games&quot;, in a mathematical sense), and I took back the importance of being able to implement models, otherwise, &quot;you're just bull*****ing&quot;.&lt;/p&gt;
&lt;p&gt;Andrew Gelman surprised me the most - he gave a wide-ranging talk about the problems we have in statistical analysis workflows. He emphasized that &quot;robustness checks&quot; are basically scams, because they're basically methods whose purpose is reassurance. He had a really cool example that highlighted that we need to understand our models by modifying our models, perhaps even using a graph of models to identify perturbations to our model that will help us understand our model. He also peppered his talk with anecdotes about how he made mistakes in his analysis workflows. I took home a different philosophy of data analysis: when we evaluate how &quot;good&quot; a model is, the operative question is, &quot;compared against what?&quot;&lt;/p&gt;
&lt;h2 id=&quot;talks&quot;&gt;Talks&lt;/h2&gt;&lt;p&gt;The talks were, for me, the highlight of the conference. A lot of good learning material around. Here's the talks from which I learned actionable new material.&lt;/p&gt;
&lt;h3 id=&quot;analyzing-nba-foul-calls-using-python&quot;&gt;Analyzing NBA Foul Calls using Python&lt;/h3&gt;&lt;p&gt;This talk by the prolific PyMC blogger Austin Rochford is one that I really enjoyed. The take-home that I got from him was towards the end of his talk, in which I picked up three ways to diagnose probabilistic programming models.&lt;/p&gt;
&lt;p&gt;The first was the use of residuals - which I now know can be used for classification problems as well as regression problems.&lt;/p&gt;
&lt;p&gt;The second was the use of the energy plots in PyMC3, where if the &quot;energy transition&quot; and &quot;marginal energy distribution&quot; plots match up (especially in the tails), then we know that the NUTS sampler did a great job.&lt;/p&gt;
&lt;p&gt;The third was the use of the Gelman-Rubin statistic to measure the in-chain vs. between-chain variation; measures close to 1 are generally considered good.&lt;/p&gt;
&lt;p&gt;Check out the talk slides &lt;a href=&quot;http://austinrochford.com/resources/talks/nba-fouls-pydata-nyc-2017.slides.html#/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;scikit-learn-compatible-model-stacking&quot;&gt;&lt;code&gt;scikit-learn&lt;/code&gt;-compatible model stacking&lt;/h3&gt;&lt;p&gt;This talk was a great one because it shows how to use model stacking (also known as &quot;ensembling&quot;, a technique commonly used in Kaggle competitions) to enable better predictions.&lt;/p&gt;
&lt;p&gt;Conceptually, model stacking works like this: I train a set of model individually on a problem, and use the predictions from those models as features for a meta-model. The meta-model should perform, at worst, on par with the best model inside the ensemble, but may also perform better. This idea was first explored in Polley and van der Laan's work, available &lt;a href=&quot;http://biostats.bepress.com/ucbbiostat/paper266&quot;&gt;online&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Civis Analytics has released their implementation of model stacking in their &lt;a href=&quot;https://github.com/civisanalytics/civisml-extensions&quot;&gt;GitHub repository&lt;/a&gt;, and it's available on PyPI. The best part of it? They didn't try inventing a new API, they kept a &lt;code&gt;scikit-learn&lt;/code&gt;-compatible API. Kudos to them!&lt;/p&gt;
&lt;p&gt;Check out the repository &lt;a href=&quot;https://github.com/civisanalytics/civisml-extensions&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;stream-processing-with-dask&quot;&gt;Stream Processing with Dask&lt;/h3&gt;&lt;p&gt;Matthew Rocklin, as usual, gave an entertaining and informative talk on the use of Streamz, a lightweight library he built, to explore the use of Dask for streaming applications. The examples he gave were amazing showcases of the library's capabilities. Given the right project, I'd love to try this out!&lt;/p&gt;
&lt;p&gt;Check out his slides &lt;a href=&quot;http://matthewrocklin.com/slides/pydata-nyc-2017.html#/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;asynchronous-python:-a-gentle-introduction&quot;&gt;Asynchronous Python: A Gentle Introduction&lt;/h3&gt;&lt;p&gt;This talk, delivered by James Cropcho, defined what asynchronous programming was all about. For me, things finally clicked at the end when I asked him for an example of how asynchronous programming would be done in data analytics workflows -- to which he responded, &quot;If you're querying for data and then performing a calculation, then async is a good idea.&quot;&lt;/p&gt;
&lt;p&gt;The idea behind this is as such: web queries written serially are often &quot;blocking&quot;, meaning we can't do anything while we wait for the web query to return. If we want to do a calculation on the returned data point, we have to wait for it to return first. On the other hand, if written asynchronously, we could potentially do a calculation on the previous data point while waiting for the current result to return, shaving the total time off potentially by some considerable fraction.&lt;/p&gt;
&lt;h3 id=&quot;turning-pymc3-into-scikit-learn&quot;&gt;Turning PyMC3 into &lt;code&gt;scikit-learn&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;This talk was by Nicole Carlson, and she did a tremendously great job delivering this talk. In it, she walked through how to wrap a PyMC3 model inside a &lt;code&gt;scikit-learn&lt;/code&gt; estimator, including details on how to implement the &lt;code&gt;.fit()&lt;/code&gt;, &lt;code&gt;.predict()&lt;/code&gt;, and &lt;code&gt;.predict_proba()&lt;/code&gt; methods. The code in &lt;a href=&quot;https://github.com/parsing-science/ps-toolkit/blob/master/ps_toolkit/pymc3_models/HLR.py&quot;&gt;her repository&lt;/a&gt; provides a great base example to copy from.&lt;/p&gt;
&lt;p&gt;One thing I can't emphasize enough is that from a user experience standpoint, it's super important to follow idioms that people are used to. What Nicole did in this talk is to show how we can provide such idioms to end-users, rather than inventing a slightly modified wheel. Props to her for that!&lt;/p&gt;
&lt;p&gt;Her slides are online &lt;a href=&quot;../../../../../blog/2017/11/30/pydata-nyc-2017-recap/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;an-attempt-at-demystifying-bayesian-deep-learning&quot;&gt;An Attempt at Demystifying Bayesian Deep Learning&lt;/h3&gt;&lt;p&gt;This talk was my own, put at the end of the 2nd day. The title definitely contributed to the hype. I popped into the room early, but then left for the restroom. When I got back, there was a lineup in the front door and in the back door. Totally unexpected. That said, big credit to the Boston Bayesians organizers Jordi and Colin, who let me do the talk as a rehearsal for PyData, so I felt very grounded.&lt;/p&gt;
&lt;p&gt;The talk went mostly smoothly. I think I was channeling my colleague, Brant Peterson, with his sense of humour during that time. There was one really hilarious hiccup - right after mentioning that I wouldn't overdo the &quot;math&quot; and &quot;equations&quot;, I accidentally opened an adjacent tab with an alternate version of the slides... with, surprise surprise, a math equation on it! During the Q&amp;amp;A, when I shared the point of not needing to do train/test splits in Bayesian analysis, I could sense the jaws dropping and eyes widening in disbelief; more than just a handful of people came up and asked for the reference later on.&lt;/p&gt;
&lt;p&gt;Having done the talk, I now realize how much people will appreciate a lighthearted and lightweight introduction to a topic that's very dense and filled with jargon. Conference speakers, we need to do more of this!&lt;/p&gt;
&lt;p&gt;From an emotional standpoint, many people brought me joy with their positive comments on the visuals and structure of the talk. Others put out positive comments on Twitter, which I collected together in a &lt;a href=&quot;https://twitter.com/i/moments/924970479869448193?ref_src=twsrc%5Etfw&quot;&gt;Twitter Moment&lt;/a&gt;. It was very encouraging, especially on this deep learning journey that I'm on right now.&lt;/p&gt;
&lt;h2 id=&quot;tutorials&quot;&gt;Tutorials&lt;/h2&gt;&lt;h3 id=&quot;interactive-matplotlib-figures&quot;&gt;Interactive &lt;code&gt;matplotlib&lt;/code&gt; Figures&lt;/h3&gt;&lt;p&gt;This was something I totally didn't realize was possible before - we can create interactive &lt;code&gt;matplotlib&lt;/code&gt; figures very easily! I have cloned the repository, and I think it'll be neat to hack on some projects at work to use this.&lt;/p&gt;
&lt;p&gt;The tutorial repository can be found &lt;a href=&quot;https://github.com/tacaswell/interactive_mpl_tutorial&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;linear-regression-three-ways&quot;&gt;Linear Regression Three Ways&lt;/h3&gt;&lt;p&gt;This one was by Colin Carroll, a software engineer at the MIT Media Lab (previously at Kensho). I sat in and learned a good deal of math from him. One thing new I learned was how we can specify a model without requiring the use of observed variables. Any sampling we do will take into account the hierarchical and mathematical relationships we've done. This makes it neat to implement Bayesian nets to test how things will look under different scenarios!&lt;/p&gt;
&lt;p&gt;His tutorial repository can be found &lt;a href=&quot;https://github.com/ColCarroll/pydata_nyc2017&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;top-to-bottom-line-by-line&quot;&gt;Top-To-Bottom, Line-By-Line&lt;/h3&gt;&lt;p&gt;This one was led by the ever-entertaining, ever-surprising James Powell. I wish the tutorial was recorded, because even though this is a &quot;novice&quot; tutorial, it nonetheless was still an eye-opening talk. Anybody who thinks they know Python should go listen to James' talks, whenever he gives them live - it's bound to be entertaining and eye-opening!&lt;/p&gt;
&lt;h2 id=&quot;overall-thoughts&quot;&gt;Overall Thoughts&lt;/h2&gt;&lt;p&gt;I'm glad I made it to PyData NYC 2017 this year. Made many new friends and connections, and caught up with old friends in the PyData community. As always, learned a ton as well!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/11/16/bayesian-learning-and-overfitting/">
    <title type="text">Bayesian Learning and Overfitting</title>
    <id>urn:uuid:8ac4ab4c-3233-3ebe-8191-80fadf3a82c5</id>
    <updated>2017-11-16T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/11/16/bayesian-learning-and-overfitting/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Yesterday, after I did my Boston Bayesians dry run talk, there was a point raised that I had only heard of once before: Bayesian learning methods don't overfit. Which means we're allowed to use all the data on hand. The point holds for simple Bayesian networks, and for more complicated deep neural nets.&lt;/p&gt;
&lt;p&gt;Though I believe it, I wasn't 100% convinced of this myself, so I decided to check it up. I managed to get my hands on Radford Neal's book, Bayesian Learning for Neural Networks, and found the following quotable paragraphs:&lt;/p&gt;
&lt;blockquote class=&quot;blockquote blockquote-success&quot;&gt;
&lt;p&gt;It is a common belief, however, that restricting the complexity of the models used for such tasks is a good thing, not just because of the obvious computational savings from using a simple model, but also because it is felt that too complex a model will overfit the training data, and perform poorly when applied to new cases. This belief is certainly justified if the model parameters are estimated by maximum likelihood. I will argue here that concern about overfitting is not a good reason to limit complexity in a Bayesian context.&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;A few paragraphs later, after explaining the frequentist procedure:&lt;/p&gt;
&lt;blockquote class=&quot;blockquote&quot;&gt;
&lt;p&gt;From a Bayesian perspective, adjusting the complexity of the model based on the amount of training data makes no sense. A Bayesian defines a model, selects a prior, collects data, computes the posterior, and then makes predictions. There is no provision in the Bayesian framework for changing the model or the prior depending on how much data was collected. If the model and prior are correct for a thousand observations, they are correct for ten observations as well (though the impact of using an incorrect prior might be more serious with fewer observations). In practice, we might sometimes switch to a simpler model if it turns out that we have little data, and we feel that we will consequently derive little benefit from using a complex, computationally expensive model, but this would be a concession to practicality, rather than a theoretically desirable procedure.&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;Finally, in the following section after describing how neural networks are built:&lt;/p&gt;
&lt;blockquote class=&quot;blockquote&quot;&gt;
&lt;p&gt;In a Bayesian model of this type, the role of the hyperparameters controlling the priors for weights is roughly analogous to the role of a weight decay constant in conventional training. With Bayesian training, values for these hyperparameters (more precisely, a distribution of values) can be found without the need for a validation set.&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;This seems to dovetail well with the following convoluted intuition that I've had: &lt;strong&gt;if I fit a Bayesian model on the &quot;training&quot; set of the data, then update it with the &quot;test&quot; set, it's equivalent to just training with the whole dataset. With wide priors, if I fit with a smaller dataset, my posterior distribution will be wider than if I fit with the entire dataset. So... where possible, just train with the entire dataset.&lt;/strong&gt; That said, I've not had sufficient grounding in Bayesian stats (after all, still a newcomer) to justify this.&lt;/p&gt;
&lt;p&gt;I certainly have more reading/learning to do here. Looks like something neat to explore in the short-term.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/11/14/the-value-of-thinking-simply/">
    <title type="text">The Value of Thinking Simply</title>
    <id>urn:uuid:fd45d251-9956-3192-839f-cf23a0455b66</id>
    <updated>2017-11-14T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/11/14/the-value-of-thinking-simply/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Einstein has a famous quote that most people don't hear about.&lt;/p&gt;
&lt;blockquote class=&quot;blockquote&quot;&gt;
&lt;p class=&quot;mb-0&quot;&gt;It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.&lt;/p&gt;
&lt;footer class=&quot;blockquote-footer&quot;&gt;Albert Einstein&lt;/footer&gt;
&lt;/blockquote&gt;&lt;p&gt;It instead, most people hear the misquote:&lt;/p&gt;
&lt;blockquote class=&quot;blockquote text&quot;&gt;
&lt;p&gt;Everything should be made as simple as possible, but no simpler. &lt;/p&gt;
&lt;footer class=&quot;blockquote-footer&quot;&gt;Misquoted version&lt;/footer&gt;
&lt;/blockquote&gt;&lt;p&gt;Though a misquote, it's still a fair (though lopsided -- missing a sufficient translation of the latter half) simplification of the original.&lt;/p&gt;
&lt;p&gt;In my work, I'm reminded of this point. I can choose to go for the complex fancy thing, but if I don't start from first principles, or start with simplistic approximations, I will struggle to have a sufficiently firm grasp on a problem to start tackling it. And therein lies the key, I think, in making progress on creative, intellectual work.&lt;/p&gt;
&lt;p&gt;The past week, I've noticed myself not wasting time on mindless coding (which usually amounts to re-running code with tweaks), and instead devoting more time to strategic thinking. As an activity, strategic thinking isn't just sitting there and thinking. For me, it involves writing and re-writing what I'm thinking, drawing and re-drawing what I'm seeing, and arranging and composing the pieces that are floating in my mind. During that time of writing, drawing, arranging and composing, I'm questioning myself, &quot;What if I didn't have this piece?&quot;. Soon enough, the &quot;simplest complex version&quot; (SCV) of whatever I'm working on begins to emerge -- but it never really is the final version! I go back and prototype it in code, and then get stuck on something, and realize I left something out in that SCV, and re-draw the entire SCV from scratch.&lt;/p&gt;
&lt;p&gt;Here's my misquote, then, offered up:&lt;/p&gt;
&lt;blockquote class=&quot;blockquote&quot;&gt;
&lt;p&gt;Sufficiently simple, and only necessarily complex.&lt;/p&gt;
&lt;footer class=&quot;blockquote-footer&quot;&gt;A further mutated version.&lt;/footer&gt;
&lt;/blockquote&gt;</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/11/3/boston-bayesians-talk-an-attempt-at-demystifying-bayesian-deep-learning/">
    <title type="text">Boston Bayesians Talk: An Attempt at Demystifying Bayesian Deep Learning</title>
    <id>urn:uuid:16575827-ed23-3dba-8acf-172b01b148f7</id>
    <updated>2017-11-03T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/11/3/boston-bayesians-talk-an-attempt-at-demystifying-bayesian-deep-learning/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;It's confirmed! I will be rehearsing my PyData NYC talk &lt;a href=&quot;https://www.meetup.com/Boston-Bayesians/events/244731222&quot;&gt;at Boston Bayesians&lt;/a&gt;, held at McKinsey's office.&lt;/p&gt;
&lt;p&gt;This time round, I've challenged myself with making the slides without using PowerPoint or Keynote, and I think I've successfully done it! Check them out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ericmjl/bayesian-deep-learning-demystified&quot;&gt;GitHub repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ericmjl.github.io/bayesian-deep-learning-demystified&quot;&gt;Online slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Side note, I'm starting to really love what we can do with the web!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/31/always-check-your-data/">
    <title type="text">Always Check Your Data</title>
    <id>urn:uuid:5aa6b7fd-5346-3f68-a35b-83bb0dc0b0b6</id>
    <updated>2017-10-31T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/31/always-check-your-data/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;True story, just happened today. I was trying to fit a Poisson likelihood to estimate event cycle times (in discreet weeks). For certain columns, everything went perfectly fine. Yet for other columns, I was getting negative infinity’s likelihoods, and was banging my head over this problem for over an hour and a half.&lt;/p&gt;
&lt;p&gt;As things turned out, those columns that gave me negative infinity likelihood initializations were doing so because of negative values in the data. Try fitting a Poisson likelihood, which only has positive support, on that!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgflip.com/1yl6ki.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;This lost hour and a half was a good lesson in data checking/testing: &lt;strong&gt;always be sure to sanity check basic stats associated with the data - bounds (min/max), central tendency (mean/median/mode) and spread (variance, quartile range) - always check!&lt;/strong&gt;&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/27/random-forests-a-good-default-model/">
    <title type="text">Random Forests: A Good Default Model?</title>
    <id>urn:uuid:2570438e-960b-3197-8bf0-6a690f53f864</id>
    <updated>2017-10-27T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/27/random-forests-a-good-default-model/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I've been giving this some thought, and wanted to go out on a limb to put forth this idea:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I think Random Forests (RF) are a good &quot;baseline&quot; model to try, after establishing a &quot;random&quot; baseline case.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(Clarification: I'm using RF as a shorthand for &quot;forest-based ML algorithms&quot;, including XGBoost etc.)&lt;/p&gt;
&lt;p&gt;Before I go on, let me first provide some setup.&lt;/p&gt;
&lt;p&gt;Let's say we have a two-class classification problem. Assume everything is balanced. One &quot;dumb baseline&quot;&quot; case is a coin flip. The other &quot;dumb baseline&quot; is predicting everything to be one class. Once we have these established, we can go to a &quot;baseline&quot; machine learning model.&lt;/p&gt;
&lt;p&gt;Usually, people might say, &quot;go do logistic regression (LR)&quot; as your first baseline model for classification problems. It sure is a principled choice! Logistic regression is geared towards classification problems, makes only linear assumptions about the data, and identifies directional effects as well. From a practical perspective, it's also very fast to train.&lt;/p&gt;
&lt;p&gt;But I've found myself more and more being oriented towards using RFs as my baseline model instead of logistic regression. Here are my reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Practically speaking, any modern computer can train a RF model with ~1000+ trees in not much more time than it would need for an LR model.&lt;/li&gt;
&lt;li&gt;By using RFs, we do not make linearity assumptions about the data.&lt;/li&gt;
&lt;li&gt;Additionally, we don't have to scale the data (one less thing to do).&lt;/li&gt;
&lt;li&gt;RFs will automatically learn non-linear interaction terms in the data, which is not possible without further feature engineering in LR.&lt;/li&gt;
&lt;li&gt;As such, the out-of-the-box performance using large RFs with default settings is often very good, making for a much more intellectually interesting challenge in trying to beat that classifier.&lt;/li&gt;
&lt;li&gt;With &lt;code&gt;scikit-learn&lt;/code&gt;, it's a one-liner change to swap out LR for RF. The API is what matters, and as such, drop-in replacements are easily implemented!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Just to be clear, I'm not advocating for throwing away logistic regression altogether. There are moments where interpretability is needed, and is more easily done by using LR. In those cases, LR can be the &quot;baseline model&quot;, or even just back-filled in after training the baseline RF model for comparison.&lt;/p&gt;
&lt;p&gt;Random Forests were the darling of the machine learning world before neural networks came along, and even now, remain the tool-of-choice for colleagues in the cheminformatics world. Given how easy they are to use now, why not just start with them?&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/11/pypy-impressive/">
    <title type="text">PyPy: Impressive!</title>
    <id>urn:uuid:d33ee57d-b161-39f0-9b6d-9821ba7c6a11</id>
    <updated>2017-10-11T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/11/pypy-impressive/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;A few years on after trying out PyPy for the first time and wrestling with it, I still find it to be pretty awesome.&lt;/p&gt;
&lt;p&gt;Now that PyPy officially supports &lt;code&gt;numpy&lt;/code&gt;, I'm going to profile a few simple statistical simulation tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computing the mean of a number of random number draws.&lt;/li&gt;
&lt;li&gt;Simulating many coin flips&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'll profile each of the tasks four ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pure Python implementation running from the CPython and PyPy interpreters&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy&lt;/code&gt; implementation running from the CPython and PyPy interpreters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, how do PyPy and CPython fare? Let's show the results up front first.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;../../../../../blog/2017/10/11/pypy-impressive/profile.png&quot;&gt;&lt;img src=&quot;../../../../../blog/2017/10/11/pypy-impressive/profile-sm.png&quot; alt=&quot;Profiling results.&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Click on the image to view a higher resolution chart. The raw recorded measurements can be found &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1QB1hF7Z8SGYjvll8sYCjVYEYAgzL4pjqGt1dbO6B2Co/edit?usp=sharing&quot;&gt;on Google Sheets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's a description of what's happening:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(top-left): PyPy is approx. 10X faster than CPython at computing the mean of 10 million random numbers.&lt;/li&gt;
&lt;li&gt;(top-right): When both are running &lt;code&gt;numpy&lt;/code&gt;, the speed is identical.&lt;/li&gt;
&lt;li&gt;(bottom-left): When simulating coin flips, PyPy with a custom &lt;code&gt;binomial()&lt;/code&gt; function is about 3X faster than CPython.&lt;/li&gt;
&lt;li&gt;(bottom-right): When using &lt;code&gt;numpy&lt;/code&gt; instead, there is a bottleneck, and PyPy fails badly compared to CPython.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's pretty clear that when PyPy is dealing with &quot;pure&quot; data (i.e. not having to pass data between Python and C), PyPy runs very, very fast, and, at least in the scenarios tested here, it performs faster than the CPython interpreter. This is consistent with my previous observations, and probably explains why PyPy is very good for code that is very repetitive; the JIT tracer really speeds things up.&lt;/p&gt;
&lt;p&gt;That last plot (bottom-right) is a big curiosity. Using the code below, I measured the random number generation is actually just as fast as it should be using CPython, but that PyPy failed badly when I was passing in a &lt;code&gt;numpy&lt;/code&gt; array to the &lt;code&gt;Counter()&lt;/code&gt; object (from the standard library). I'm not sure what is happening behind-the-scenes, but I have reached out to the PyPy developers to ask what's going on, and will update this post at a later date.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; I heard back from the PyPy devs &lt;a href=&quot;https://bitbucket.org/pypy/pypy/issues/2680/slow-speed-going-from-numpy-data-structure&quot;&gt;on BitBucket&lt;/a&gt;, and this is indeed explainable by data transfer between the C-to-PyPy interface. It's probably parallel to the latency that arises from transferring data between the CPU and GPU, or between compute nodes.&lt;/p&gt;
&lt;p&gt;So, what does this mean? It means that for pure Python code, PyPy can be a very powerful way to accelerate your code. One example I can imagine is agent-based simulations using Python objects. Another example that comes to mind is running a web server that only ever deals with strings, floats and JSONs (in contrast to matrix-heavy scientific computing).&lt;/p&gt;
&lt;p&gt;Now, for those who are curious, here's the source code for the &lt;strong&gt;pure Python implementation of the mean of random numbers&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Mean of 10 million random number draws.&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1E7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rnds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rnds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;{} seconds&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here's the source code for the &lt;strong&gt;&lt;code&gt;numpy&lt;/code&gt; implementation of the mean of random numbers&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1E7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;{} seconds&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, here's the source code for &lt;strong&gt;coin flips in pure Python&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Simulate 10 million biased coin flips with p = 0.3&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rnd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1E7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;{} seconds&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And finally, source code for &lt;strong&gt;coin flips using &lt;code&gt;numpy&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy.random&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binomial&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coinflips&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1E7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Time for numpy coinflips: {} seconds&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coinflips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;{} seconds&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/10/pydata-nyc-2017/">
    <title type="text">PyData NYC 2017</title>
    <id>urn:uuid:e720c68f-51c8-3391-9f3c-97ce2ba8267c</id>
    <updated>2017-10-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/10/pydata-nyc-2017/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I'm seriously looking forward to PyData NYC this year -- there's a great lineup of talks that I'm particularly looking forward to hearing! The theme for my set of must-see talks this year is &quot;Bayesian machine learning&quot; - there's much for me to learn!&lt;/p&gt;
&lt;p&gt;The first is by my fellow Boston Bayesian &lt;strong&gt;&lt;a href=&quot;https://colindcarroll.com/&quot;&gt;Colin Caroll&lt;/a&gt;&lt;/strong&gt; with his talk titled &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/12/&quot;&gt;Two views on regression with PyMC3 and scikit-learn&lt;/a&gt;. Colin is a mathematician at heart, even though he does software engineering for living now, and I can't wait to hear about regularization strategies!&lt;/p&gt;
&lt;p&gt;The second is by &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/speaker/profile/6/&quot;&gt;Nicole Carlson&lt;/a&gt;&lt;/strong&gt;, with her talk titled &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/24/&quot;&gt;Turning PyMC3 into scikit-learn&lt;/a&gt;. Nicole's talk is of interest to me because I've implemented models in PyMC3 before, and now would like to know how to make them reusable!&lt;/p&gt;
&lt;p&gt;The third talk is by &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/speaker/profile/118/&quot;&gt;Chaya Stern&lt;/a&gt;&lt;/strong&gt;, with her talk titled &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/53/&quot;&gt;Bayesian inference in computational chemistry&lt;/a&gt;. Super relevant to my work at Novartis!&lt;/p&gt;
&lt;p&gt;The fourth is by my fellow Boston Pythonista &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/speaker/profile/34/&quot;&gt;Joe Jevnik&lt;/a&gt;&lt;/strong&gt;, who will be speaking on the first day about his journey into deep learning on some really cool time-series data. He works at Quantopian, BUT the spoiler here is that his talk is NOT about financial data! (I've heard his talk outline already.)&lt;/p&gt;
&lt;p&gt;The fifth is a tutorial by &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/speaker/profile/29/&quot;&gt;Jacob Schrieber&lt;/a&gt;&lt;/strong&gt;, with his talk titled &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/30/&quot;&gt;pomegranate: fast and flexible probabilistic modeling in python&lt;/a&gt;. &lt;code&gt;pomegranate&lt;/code&gt;'s API models after the &lt;code&gt;scikit-learn&lt;/code&gt;'s API; with the API being the user-facing interface, and &lt;code&gt;scikit-learn&lt;/code&gt; being the &lt;em&gt;de facto&lt;/em&gt; go-to library for machine learning, I'd be interested to see how much more &lt;code&gt;pomegranate&lt;/code&gt; adds to the ecosystem, particularly w.r.t. Bayesian models.&lt;/p&gt;
&lt;p&gt;There are a swathe of other good talks that I'm expecting to be able to catch online later on. &lt;strong&gt;&lt;a href=&quot;https://matthewrocklin.com/&quot;&gt;Matt Rocklin&lt;/a&gt;&lt;/strong&gt;, who is the lead developer of Dask, has done a ton of work on speeding Python up through parallelism. His talk will be on &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/22/&quot;&gt;the use of Cython &amp;amp; Dask to speed up GeoPandas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/speaker/profile/80/&quot;&gt;Thomas Caswell&lt;/a&gt;&lt;/strong&gt;, one of the &lt;a href=&quot;http://matplotlib.org/&quot;&gt;&lt;code&gt;matplotlib&lt;/code&gt;&lt;/a&gt; lead devs who helped guide my first foray into open source contributions, is giving a tutorial on &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/3/&quot;&gt;developing interactive figures in matplotlib&lt;/a&gt;. Highly recommended if you're into the visualization world!&lt;/p&gt;
&lt;p&gt;Finally, the always-interesting, always entertaining &lt;strong&gt;&lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/25/&quot;&gt;en zyme&lt;/a&gt;&lt;/strong&gt; will be speaking on an &lt;a href=&quot;https://pydata.org/nyc2017/schedule/presentation/25/&quot;&gt;interesting topic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Looking forward to being at the conference, and meeting old and new friends there!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/10/recursive-programming-and-dags/">
    <title type="text">Recursive Programming and DAGs</title>
    <id>urn:uuid:5b939f02-8808-3e54-938f-21843ac5e60b</id>
    <updated>2017-10-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/10/recursive-programming-and-dags/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Over the past few days, I've found myself using recursive programming to implement a &quot;model specification&quot; system with inheritance for deep learning. The goal here is to enable reproducible computational experiments for particular deep learning hyperparameter sets. Reproducibility is something I learned from the Software/Data Carpentry initiative, thus I wanted to ensure that my own work was reproducible, even if it's not (because of corporate reasons) open-able, because it's the right thing to do.&lt;/p&gt;
&lt;p&gt;So, how do these &quot;model spec&quot; files work? I call them &quot;experiment profiles&quot;, and they specify a bunch of things: &lt;strong&gt;model architecture&lt;/strong&gt;, &lt;strong&gt;training parameters&lt;/strong&gt;, and &lt;strong&gt;data tasks&lt;/strong&gt;. These experiment profiles are stored in YAML files on disk. A profile essentially looks like the following (dummy examples provided, naturally):&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Name: default.yaml&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;data_tasks&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p p-Indicator&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;task1&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;task2&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;task3&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;model_architecture&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;hidden_layers&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p p-Indicator&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;hidden_dropouts&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p p-Indicator&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;training_parameters&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;sgd&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;optimizer_options&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;20&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this YAML file, the key-value pairs essentially match the API of the tooling I've built on top of Keras' API to make myself more productive. (From the example, it should be clear that we're dealing with only feed-forward neural networks and nothing else more complicated.) The key here (pun unintended) is that I have a &lt;code&gt;parent&lt;/code&gt; key-value pair that specifies another experiment profile that I can inherit from.&lt;/p&gt;
&lt;p&gt;Let's call the above example &lt;code&gt;default.yaml&lt;/code&gt;. Let's say I want to run another computational experiment that uses the &lt;code&gt;adam&lt;/code&gt; optimizer instead of plain vanilla &lt;code&gt;sgd&lt;/code&gt;. Instead of re-specifying the entire YAML file, by implementing an inheritance scheme, I can re-specify only the optimizer and optimizer_options.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Name: adam.yaml&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;default.yaml&amp;quot;&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;training_parameters&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;adam&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, let's say I find out that 20 epochs (inherited from &lt;code&gt;default.yaml&lt;/code&gt;) is too much for Adam - after all, Adam is one of the most efficient gradient descent algorithms out there - and I want to change it to 3 epochs instead. I can do the following:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Name: adam-3.yaml&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;adam.yaml&amp;quot;&lt;/span&gt;
&lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;training_parameters&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;optimizer_options&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Okay, so specifying YAML files with inheritance is all good, but how do I ensure that I get the entire parameter set out correctly, without writing verbose code? This is where the power of recursive programming comes in. Using recursion, I can solve this problem with &lt;strong&gt;a single function that calls itself on one condition, and returns a result on another condition&lt;/strong&gt;. That's a recursive function in its essence.&lt;/p&gt;
&lt;p&gt;The core of this problem is traversing the inheritance path, from &lt;code&gt;adam-3.yaml&lt;/code&gt; to &lt;code&gt;adam.yaml&lt;/code&gt; to &lt;code&gt;default.yaml&lt;/code&gt;. Once I have the inheritance path specified, loading the YAML files as a dictionary becomes the easy part.&lt;/p&gt;
&lt;p&gt;How would this look like in code? Let's take a look at an implementation.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;yaml&lt;/span&gt; 

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inheritance_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    :param str yaml_file: The path to the yaml file of interest.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    :param list path: A list specifying the existing inheritance path. First&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        entry is the file of interest, and parents are recursively appended to&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        the end of the list.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;parent&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;parent&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inheritance_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;parent&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most important part of the function is in the &lt;code&gt;if&lt;/code&gt;/&lt;code&gt;else&lt;/code&gt; block. If I have reached the &quot;root&quot; of the inheritance path, (that is, I have hit &lt;code&gt;default.yaml&lt;/code&gt; which has no parent), then I return the &lt;code&gt;path&lt;/code&gt; traversed. Otherwise, I return into the &lt;code&gt;inheritance_path&lt;/code&gt; function call again, but with an updated &lt;code&gt;path&lt;/code&gt; list, and a different &lt;code&gt;yaml_file&lt;/code&gt; to read. It's a bit like doing a &lt;code&gt;while&lt;/code&gt; loop, but in my opinion, a bit more elegant aesthetically.&lt;/p&gt;
&lt;p&gt;Once I've gotten the path list, I can finally load the parameters using a single function that calls on &lt;code&gt;inheritance_path&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inheritance_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tasks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
             &lt;span class=&quot;n&quot;&gt;model_architecture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
             &lt;span class=&quot;n&quot;&gt;training_parameters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# go in reverse!&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the equivalent of traversing a Directed Acyclic Graph (DAG), or in some special cases, a tree data structure, but in a way where we don't have to know the entire tree structure ahead of time. The goal is to reach the root from any node:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root
    |- A
        |- B
        |- C
            |- D
            |- E
    |- F
        |- G
        |- H
        |- I 
            |- J
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, because we only have one pointer in each YAML file to its parent, we have effectively created a &quot;Linked List&quot; that we can use to trace a path back to the &quot;root&quot; node, along the way collecting the information that we need together. By using this method of traversal, we only need to know the neighbors, and at some point (however long it takes), we will reach the root.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D -&amp;gt; C -&amp;gt; A -&amp;gt; root
E -&amp;gt; C -&amp;gt; A -&amp;gt; root
J -&amp;gt; I -&amp;gt; F -&amp;gt; root
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were wondering why linked lists, trees and other data structures might be useful as a data scientist, I hope this illustrates on productive example!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/7/a-data-scientists-guide-to-environment-variables/">
    <title type="text">A Data Scientist's Guide to Environment Variables</title>
    <id>urn:uuid:0005f631-a0b5-3be2-8e59-9c6c40922a33</id>
    <updated>2017-10-07T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/7/a-data-scientists-guide-to-environment-variables/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;You might have encountered a piece of software asking you for permission to modify your &lt;code&gt;PATH&lt;/code&gt; variable, or another program's installation instructions cryptically telling you that you have to &quot;set your &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; variable correctly&quot;.&lt;/p&gt;
&lt;p&gt;As a data scientist, you might encounter other environment variable issues when interacting with your compute stack (particularly if you don't have full control over it, like I do). This post is meant to demystify what an environment variable is, and how it gets used in a data science context.&lt;/p&gt;
&lt;h2 id=&quot;what-is-an-environment-variable?&quot;&gt;What Is An Environment Variable?&lt;/h2&gt;&lt;p&gt;First off, let me explain what an environment variable is, by going in-depth into the &lt;code&gt;PATH&lt;/code&gt; environment variable. I'd encourage you to execute the commands here inside your bash terminal (with appropriate modifications -- read the text to figure out what I'm doing!).&lt;/p&gt;
&lt;p&gt;When you log into your computer system, say, your local computer’s terminal or your remote server via SSH, your bash interpreter needs to know where to look for particular programs, such as &lt;code&gt;nano&lt;/code&gt; (the text editor), or &lt;code&gt;git&lt;/code&gt; (your version control software), or your Python executable. This is controlled by your PATH variable. It specifies the paths to folders where your executable programs are found.&lt;/p&gt;
&lt;p&gt;By historical convention, command line programs, such as &lt;code&gt;nano&lt;/code&gt;, &lt;code&gt;which&lt;/code&gt;, and &lt;code&gt;top&lt;/code&gt;, are found in the directory &lt;code&gt;/usr/bin&lt;/code&gt;. (By historical convention, the &lt;code&gt;/bin&lt;/code&gt; folder is for software binaries, which is why they are named &lt;code&gt;/bin&lt;/code&gt;.) These are the ones that are bundled with your operating system, and as such, need special permissions to upgrade.&lt;/p&gt;
&lt;p&gt;Try it out in your terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ which which
/usr/bin/which
$ which top
/usr/bin/top
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other programs are installed (for whatever reason) into &lt;code&gt;/bin&lt;/code&gt; instead. &lt;code&gt;ls&lt;/code&gt; is one example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ which ls
/bin/ls
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yet other programs might be installed in other special directories:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ which nano
/usr/local/bin/nano
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How does your Bash terminal figure out where to go to look for stuff? It uses the &lt;code&gt;PATH&lt;/code&gt; environment variable. It looks something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo $PATH
/usr/bin:/bin:/usr/local/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The most important thing to remember about the &lt;code&gt;PATH&lt;/code&gt; variable is that it is &quot;colon-delimited&quot;. That is, each directory path is separated by the next using a &quot;colon&quot; (&lt;code&gt;:&lt;/code&gt;) character. The order in which your bash terminal is looking for programs goes from left to right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/usr/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/usr/local/bin&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On my particular computer, when I type in &lt;code&gt;ls&lt;/code&gt;, my bash interpreter will look inside the &lt;code&gt;/usr/bin&lt;/code&gt; directory first. It'll find that &lt;code&gt;ls&lt;/code&gt; doesn't exist in &lt;code&gt;/usr/bin&lt;/code&gt;, and so it'll move to the next directory, &lt;code&gt;/bin&lt;/code&gt;. Since my &lt;code&gt;ls&lt;/code&gt; exists under &lt;code&gt;/bin&lt;/code&gt;, it'll execute the &lt;code&gt;ls&lt;/code&gt; program from there.&lt;/p&gt;
&lt;p&gt;You can see, then, that this is simultaneously super flexible for customizing your compute environment, yet also potentially super frustrating if a program modified your &lt;code&gt;PATH&lt;/code&gt; variable without you knowing.&lt;/p&gt;
&lt;p&gt;Wait, you can actually modify your &lt;code&gt;PATH&lt;/code&gt; variable? Yep, and there's a few ways to do this.&lt;/p&gt;
&lt;h2 id=&quot;how-to-modify-the-path-variable&quot;&gt;How To Modify the &lt;code&gt;PATH&lt;/code&gt; variable&lt;/h2&gt;&lt;h3 id=&quot;using-a-bash-session&quot;&gt;Using a Bash Session&lt;/h3&gt;&lt;p&gt;The first way is transient, or temporary, and only occurs for your particular bash session. You can make a folder have higher priority than the existing paths by &quot;pre-pending&quot; it to the &lt;code&gt;PATH&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export PATH=/path/to/my/folder:$PATH
$ echo $PATH
/path/to/my/folder:/usr/bin:/bin:/usr/local/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or I can make it have a lower priority than existing paths by &quot;appending&quot; it to the &lt;code&gt;PATH&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export PATH=$PATH:/path/to/my/folder
$ echo $PATH
/usr/bin:/bin:/usr/local/bin:/path/to/my/folder
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason this is temporary is because I only export it during my current bash session.&lt;/p&gt;
&lt;h3 id=&quot;bashrc-or-.bash_profile-file&quot;&gt;&lt;code&gt;bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt; File&lt;/h3&gt;&lt;p&gt;If I wanted to make my changes somewhat more permanent, then I would include inside my &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt; file. (I recommend using the &lt;code&gt;.bashrc&lt;/code&gt; file.) The &lt;code&gt;.bashrc&lt;/code&gt;/&lt;code&gt;.bash_profile&lt;/code&gt; file lives inside your home directory (your &lt;code&gt;$HOME&lt;/code&gt; environment variable specifies this), and is a file that your bash interpreter will execute first load. It will execute all of the commands inside there. This means, you can change your PATH variable by simply putting inside your &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...other stuff above...
# Make /path/to/folder have higher priority
export PATH=/path/to/folder:$PATH

# Make /path/to/other/folder have lower priority
export PATH=$PATH:/path/to/folder
...other stuff below...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;data-science-and-the-path-environment-variable&quot;&gt;Data Science and the &lt;code&gt;PATH&lt;/code&gt; environment variable&lt;/h2&gt;&lt;p&gt;Now, &lt;strong&gt;how is this relevant to data scientists?&lt;/strong&gt; Well, if you're a data scientist, chances are that you use Python, and that your Python interpreter comes from the Anaconda Python distribution (a seriously awesome thing, go get it!). What the Anaconda Python installer does is prioritize the &lt;code&gt;/path/to/anaconda/bin&lt;/code&gt; folder in the &lt;code&gt;PATH&lt;/code&gt; environment variable. You might have other Python interpreters installed on your system (that is, Apple ships its own). However, this &lt;code&gt;PATH&lt;/code&gt; modification ensures that each time you type &lt;code&gt;python&lt;/code&gt; into your Bash terminal, you execute the Python interpreter shipped with the Anaconda Python distribution. In my case, after installing the Anaconda Python distribution, my &lt;code&gt;PATH&lt;/code&gt; looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo $PATH
/Users/ericmjl/anaconda/bin:/usr/bin:/bin:/usr/local/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even better, what conda environments do is prepend the path to the conda environment binaries folder while the environment is activated. For example, with my blog, I keep it in an environment named &lt;code&gt;lektor&lt;/code&gt;. Thus...&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo $PATH
/Users/ericmjl/anaconda/bin:/usr/bin:/bin:/usr/local/bin
$ which python
/Users/ericmjl/anaconda/bin/python
$ source activate lektor
$ echo $PATH
/Users/ericmjl/anaconda/envs/lektor/bin:/Users/ericmjl/anaconda/bin:/usr/bin:/bin:/usr/local/bin
$ which python
/Users/ericmjl/anaconda/envs/lektor/bin/python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how the bash terminal now preferentially picks the Python inside the higher-priority &lt;code&gt;lektor&lt;/code&gt; environment.&lt;/p&gt;
&lt;p&gt;If you've gotten to this point, then you'll hopefully realize there's a few important concepts listed here. Let's recap them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt; is an environment variable stored as a plain text string used by the bash interpreter to figure out where to find executable programs.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt; is colon-delimited; higher priority directories are to the left of the string, while lower priority directories are to the right of the string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt; can be modified by prepending or appending directories to the environment variable. It can be done transiently inside a bash session by running the &lt;code&gt;export&lt;/code&gt; command at the command prompt, or it can be done permanently across bash sessions by adding an &lt;code&gt;export&lt;/code&gt; line inside your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;other-environment-variables-of-interest&quot;&gt;Other Environment Variables of Interest&lt;/h2&gt;&lt;p&gt;Now, what other environment variables might a data scientist encounter? These are a sampling of them that you might see, and might have to fix, especially in contexts where your system administrators are off on vacation (or taking too long to respond).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For general use&lt;/strong&gt;, you'll definitely want to know where your &lt;code&gt;HOME&lt;/code&gt; folder is -- on Linux systems, it's often &lt;code&gt;/home/username&lt;/code&gt;, while on macOS systems, it's often &lt;code&gt;/Users/username&lt;/code&gt;.  You can figure out what &lt;code&gt;HOME&lt;/code&gt; is by doing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo $HOME
/Users/ericmjl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;If you're a Python user&lt;/strong&gt;, then the &lt;code&gt;PYTHONPATH&lt;/code&gt; is one variable that might be useful. It is used by the Python interpreter, and specifies where to find Python modules/packages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you have to deal with C++ libraries&lt;/strong&gt;, then knowing your &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; environment variable is going to be very important. I'm not well-versed enough in this to espouse on it intelligently, so I would defer to &lt;a href=&quot;http://xahlee.info/UnixResource_dir/_/ldpath.html&quot;&gt;this website&lt;/a&gt; for more information on best practices for using the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you're working with Spark&lt;/strong&gt;, then the &lt;code&gt;PYSPARK_PYTHON&lt;/code&gt; environment variable would be of interest. This essentially tells Spark which Python to use for both its driver and its workers; you can also set the &lt;code&gt;PYSPARK_DRIVER_PYTHON&lt;/code&gt; to be separate from the &lt;code&gt;PYSPARK_PYTHON&lt;/code&gt; environment variable, if needed.&lt;/p&gt;
&lt;h3 id=&quot;hack-your-environment-variables&quot;&gt;Hack Your Environment Variables&lt;/h3&gt;&lt;p&gt;This is where the most fun happens! Follow along for some stuff you might be able to do by hacking your environment variables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hack #1: Enable access to PyPy.&lt;/strong&gt; I occasionally keep up with the development of PyPy, but because PyPy is not yet the default Python interpreter, and is not yet &lt;code&gt;conda install&lt;/code&gt;-able, I have to put it in its own &lt;code&gt;$HOME/pypy/bin&lt;/code&gt; directory. To enable access to the PyPy interpreter, I have to make sure that my &lt;code&gt;/path/to/pypy&lt;/code&gt; is present in the &lt;code&gt;PATH&lt;/code&gt; environment variable, but at a lower priority than my regular CPython interpreter.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hack #2: Enable access to other language interpreters/compilers.&lt;/strong&gt; This is analogous to PyPy. I once was trying out Lua's JIT interpreter to use Torch for deep learning, and needed to add a path to there in my &lt;code&gt;.bashrc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hack #3: Install Python packages to your home directory.&lt;/strong&gt; On shared Linux compute systems that use the &lt;code&gt;modules&lt;/code&gt;  system rather than &lt;code&gt;conda&lt;/code&gt; environments, a &lt;code&gt;modulefile&lt;/code&gt; that you load might be configured with a virtual environment that &lt;em&gt;you don't have permissions to modify&lt;/em&gt;. If you need to install a Python package, you might want to &lt;code&gt;pip install --user my_pkg_name&lt;/code&gt;. This will install it to &lt;code&gt;$HOME/.local/lib/python-[version]/site-packages/&lt;/code&gt;. Ensuring that your &lt;code&gt;PYTHONPATH&lt;/code&gt; includes &lt;code&gt;$HOME/.local/lib/python-[version]/site-packages&lt;/code&gt; at a high enough priority is going to be important in this case.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hack 4: Debugging when things go wrong.&lt;/strong&gt; In case something throws an error, or you have unexpected behaviour -- something I encountered before was my Python interpreter not being found correctly after loading all of my Linux modules -- then a way to debug is to temporarily set your PATH environment variable to some sensible &quot;defaults&quot; and sourcing that, effectively &quot;resetting&quot; your PATH variable, so that you can manually prepend/append while debugging.&lt;/p&gt;
&lt;p&gt;To do this, place the following line inside a file named &lt;code&gt;.path_default&lt;/code&gt;, inside your home directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export PATH=&quot;&quot;  # resets PATH to an empty string.
export PATH=/usr/bin:/bin:/usr/local/bin:$PATH  # this is a sensible default; customize as needed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After something goes wrong, you can reset your PATH environment variable by using the &quot;source&quot; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo $PATH
/some/complicated/path:/more/complicated/paths:/really/complicated/paths
$ source ~/.path_default
$ echo $PATH
/usr/bin:/bin:/usr/local/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note - you can also execute the exact same commands inside your bash session; the interactivity may also be helpful.&lt;/p&gt;
&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;&lt;p&gt;I hope you enjoyed this article, and that it'll give you a, ahem, path forward whenever you encounter these environment variables!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/10/3/new-habits/">
    <title type="text">New Habits</title>
    <id>urn:uuid:7877ee11-bf8d-39a4-b1e5-9c18a698d76f</id>
    <updated>2017-10-03T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/10/3/new-habits/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Ever since &quot;going corporate&quot;, it's meant picking up more new productivity/coding habits. Here's a sampling of what I've learned.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) Living by my calendar&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Basically, the &quot;work calendar&quot; defines everything about the day. I've had to make sure that if I am not going to be pencilled in for a meeting, I have to block out time on the calendar first.&lt;/p&gt;
&lt;p&gt;Also, sending invites to people + rooms -- the latter being the newest habit I've had to pick up.&lt;/p&gt;
&lt;p&gt;Finally, setting informative titles for calendar events - if I want to have coffee or lunch with X, I can't just write &quot;Coffee with X&quot; - it literally shows up as &quot;Coffee with X&quot; on X's calendar, which is super awkward, as if they're having coffee with themselves! Something more informative, like, &quot;Eric &amp;lt;&amp;gt; X coffee&quot; really helps the other person, who might be super busy and thus only glances at their calendar once in a while.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) Flagging emails and applying rules&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Emails fly everywhere. It gets super overwhelming after a while.&lt;/p&gt;
&lt;p&gt;If there's stuff that needs to be followed-up on, it stays in my Inbox until it's done. It also gets flagged, which automatically creates a Todo on my task list. (If this sounds like Outlook - yes, it's Outlook. On macOS. With no &quot;email snoozing&quot; feature...)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3) Hacking through legacy code and shared compute resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Working on a compute cluster with a code base that's built for legacy versions of programming languages is super frustrating! Thankfully I know enough about the differences between Python 2 and Python 3 to hack my way through.&lt;/p&gt;
&lt;p&gt;Shared compute resources means using &lt;code&gt;modules&lt;/code&gt;, but not everybody sets up &lt;code&gt;modules&lt;/code&gt; with the same set of assumptions as others. Some create virtual environments inside a module, others append to &lt;code&gt;$PATH&lt;/code&gt;, and getting the right combinations in a modular way is really tricky. It means I have some really painful one-off &lt;code&gt;$PATH&lt;/code&gt; hacks to make stuff work. Documentation is paramount - without putting in docs, I'll never remember what I did...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(4) Adapting to others' coding styles&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Not everybody is a Python programmer, and not everybody is a Pythonic programmer. The usual Python idioms that I'm used to (whether functional or object-oriented) sometimes get thrown out in favour of some other style (globals, anybody?), and I have to adapt to figure out what's going on. Thankfully my colleagues are open to me modifying their code, as long as I can demonstrate that the new version works fine, and I've been working hard to bring in Pythonic code style.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(5) Performance reviews&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Gotta start getting used to this. I had a taste of it while volunteering as part of Tang Hall's student leadership, but now it's for real.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/9/14/visualize-large-datasets-by-sampling/">
    <title type="text">Visualize Large Datasets by Sampling</title>
    <id>urn:uuid:97b636b4-2b94-388a-ad54-67a2e65f392d</id>
    <updated>2017-09-14T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/9/14/visualize-large-datasets-by-sampling/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Just a little tip, putting it here for myself and others in case it helps.&lt;/p&gt;
&lt;p&gt;Sometimes, you need to visualize a large dataset, but it takes a ton of time to render it or compute the necessary transforms.&lt;/p&gt;
&lt;p&gt;If your samples are statistically sampled independently of one another (i.e. basically not timeseries), and the goals are to do some statistical visualizations, then it's basically valid to visualize a downsampled set of the dataset.&lt;/p&gt;
&lt;p&gt;I recently encountered this point at work. After running a clustering analysis, I wanted to see a pair plot of the distribution of features in each cluster. However, with cluster sizes ranging from 200-2 million, rendering times were unreasonably long (making things non-interactive) for the large sized clusters. I thus decided to downsample the large clusters to a maximum of 2,000 data points. Instantly, render times improved, and I could start interacting with my data again.&lt;/p&gt;
&lt;p&gt;Little things matter!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/9/11/nano-text-editor-hacks/">
    <title type="text">nano text editor hacks</title>
    <id>urn:uuid:5d36c0a2-5bef-39b9-835c-bd5784574506</id>
    <updated>2017-09-11T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/9/11/nano-text-editor-hacks/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Much as I've embraced the &lt;a href=&quot;https://atom.io/&quot;&gt;Atom text editor&lt;/a&gt;, there are times when the GUI isn't accessible to us, and we are forced to use a Terminal-based text editor.&lt;/p&gt;
&lt;p&gt;Now, I'm not one of those crazy types who use emacs or vim - those are the real seasoned pros. (I still don't know how to exit vim, btw.) As such, my terminal editor of choice remains the venerable &lt;code&gt;nano&lt;/code&gt;. Here's some hacks that I recently figured out, to make text editing much easier in &lt;code&gt;nano&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;1-syntax-highlighting&quot;&gt;(1) Syntax highlighting&lt;/h2&gt;&lt;p&gt;This is such a big one! Syntax highlighting seriously helps a ton. If you're on a Mac, make sure you install &lt;code&gt;homebrew&lt;/code&gt;'s version of &lt;code&gt;nano&lt;/code&gt; - you can look at my &lt;a href=&quot;https://github.com/ericmjl/dotfiles/blob/master/install.sh#L41&quot;&gt;dotfiles&lt;/a&gt; or run the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ brew install nano
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, edit your &lt;code&gt;~/.nanorc&lt;/code&gt; file to look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include /usr/local/share/nano/python.nanorc  # gives you Python syntax highlighting
include /usr/local/share/nano/sh.nanorc  # gives you bash shell syntax highlighting
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next time you use &lt;code&gt;nano&lt;/code&gt; (from your user account), syntax highlighting should be enabled!&lt;/p&gt;
&lt;p&gt;You can find a sample &lt;a href=&quot;https://github.com/ericmjl/dotfiles/blob/master/.nanorc-mac&quot;&gt;.nanorc&lt;/a&gt; file on my GitHub &lt;a href=&quot;https://github.com/ericmjl/dotfiles/&quot;&gt;dotfiles&lt;/a&gt; repository&lt;/p&gt;
&lt;h2 id=&quot;2-keyboard-shortcuts&quot;&gt;(2) Keyboard Shortcuts&lt;/h2&gt;&lt;p&gt;Here's a laundry list of keyboard shortcuts I've muscle-memorized:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ctrl-x&lt;/code&gt;: quits. There will be a prompt to save the file if it's been modified.&lt;ul&gt;
&lt;li&gt;I usually end up doing &lt;code&gt;Ctrl-x-y-Enter&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-v&lt;/code&gt; scrolls down a page&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-y&lt;/code&gt; scrolls up a page&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-w&lt;/code&gt; searches the document for a term that you type in (think &quot;where&quot;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-k&lt;/code&gt; cuts the line&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-u&lt;/code&gt; pastes a cut line&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-^&lt;/code&gt; (i.e. &lt;code&gt;Ctrl-Shift-6&lt;/code&gt; on macOS keyboards) starts a &quot;select&quot; cursor.&lt;ul&gt;
&lt;li&gt;You can use arrow keys to expand or shrink the selection, which can then be cut and pasted.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-c&lt;/code&gt; cancels any commands that are 'active'.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ctrl-o&lt;/code&gt; activates the &quot;save file&quot; dialogue - lets you save your state without quitting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;(3) Persistence&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nano&lt;/code&gt;, being not as fancy as &lt;code&gt;vim&lt;/code&gt; or &lt;code&gt;emacs&lt;/code&gt;, means it doesn't have the concept of sessions. Doesn't matter - use &lt;a href=&quot;https://github.com/tmux/tmux/wiki&quot;&gt;&lt;code&gt;tmux&lt;/code&gt;&lt;/a&gt; to persist!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;All-in-all, the biggest one that aids in writing on a terminal editor is syntax highlighting. I wrote this blog post in &lt;code&gt;nano&lt;/code&gt;, and being able to visually see different parts of my text highlighted according to their meaning has made writing much easier.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/8/31/what-would-be-useful-for-aspiring-data-scientists-to-know/">
    <title type="text">What would be useful for aspiring data scientists to know?</title>
    <id>urn:uuid:ac5e7fea-ac8d-3bec-bed0-8c017fad3ed5</id>
    <updated>2017-08-31T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/8/31/what-would-be-useful-for-aspiring-data-scientists-to-know/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I originally titled this post, &quot;What you need to know to become a data scientist&quot;, but I backed off from having such an authoritative post title for I wanted to keep things opinionated without being pompous :).&lt;/p&gt;
&lt;p&gt;Data Science (DS) is a hot field, and I'm going to be starting my new role doing DS at Novartis in September. As an aside, what makes me most happy about this role is that I'm going to do DS in the context of the life sciences (one of the &quot;hard sciences&quot;)!&lt;/p&gt;
&lt;p&gt;Now that I have secured a role, some people have come to ask me questions about how I made the transition into DS and into the industry in general. I hope to provide answers to those questions in this blog post, and that you, the reader, find it useful.&lt;/p&gt;
&lt;p&gt;I will structure this blog post into two sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;What do I need to know and how do I go about it?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What do I need to do?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ready? Here we go :)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;First off, let's talk about what I think you, an aspiring data scientist, needs to know, and how to go about learning it.&lt;/p&gt;
&lt;h3 id=&quot;topic-1:-statistical-learning&quot;&gt;Topic 1: Statistical Learning&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Statistical learning methods&lt;/strong&gt; are going to top the list. From the standpoint of &quot;topics to learn&quot;, there's a laundry list one can write - all of the ML methods in &lt;code&gt;scikit-learn&lt;/code&gt;, neural networks, statistical inference methods and more. It's also very tempting to go through that laundry list of terms, learn how they work underneath, and call it a day there. I think that's all good, but only if that material is learned while in the service of picking up the meta-skill of &lt;strong&gt;statistical thinking&lt;/strong&gt;. This includes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Thinking about data as being sampled from a generative model parameterized by probability distributions (my Bayesian fox tail is revealed!), &lt;/li&gt;
&lt;li&gt;Identifying biases in the data and figuring out how to use sampling methods to help correct those biases (e.g. bootstrap resampling, downsampling), and &lt;/li&gt;
&lt;li&gt;Figuring out when your data are garbage enough that you shouldn't proceed with inference and instead think about experimental design.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That meta-skill of statistical thinking can only come with practice. Some only need a few months, some need a few years. (I needed about a year's worth of self-directed study during graduate school to pick it up.) &lt;strong&gt;&lt;em&gt;Having a project that involves this is going to be key!&lt;/em&gt;&lt;/strong&gt; A good introduction to statistical thinking for data science can be found in a &lt;a href=&quot;https://www.youtube.com/watch?v=TGGGDpb04Yc&quot;&gt;SciPy 2015 talk by Chris Fonnesbeck&lt;/a&gt;, and working through the two-part computational statistics tutorial by him and Allen Downey (&lt;a href=&quot;https://www.youtube.com/watch?v=fMycLa1bsno&quot;&gt;Part 1&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=heFaYLKVZY4&quot;&gt;Part 2&lt;/a&gt;) helped me a ton.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recommendation &amp;amp; Personal Story:&lt;/strong&gt; Nothing beats practice. This means finding ways to apply statistical learning methods to projects that you already work on, or else coming up with new projects to try. I did this in graduate school: my main thesis project was not a machine learning-based project. However, I found a great &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3794897/&quot;&gt;PLoS Computational Biology paper&lt;/a&gt; implementing Random Forests to identify viral hosts from protein sequence, and it was close enough in research topic that I spent two afternoons re-implementing it using &lt;code&gt;scikit-learn&lt;/code&gt;, and presenting it during our lab's Journal Club session. I then realized the same logic could be applied to predicting drug resistance from protein sequence, and re-implemented a few other HIV drug resistance papers before finally learning and applying a fancier deep learning-based method that had been developed at Harvard to the same problem.&lt;/p&gt;
&lt;h3 id=&quot;topic-2:-software-engineering&quot;&gt;Topic 2: Software Engineering&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Software engineering&lt;/strong&gt; (SE), to the best of my observation, is about three main things: (a) learning how to abstract and organize ideas in a way that is logical and humanly accessible, (b) writing good code that is well-tested and documented, and (c) being familiar with the ever-evolving ecosystem of packages. SE is important for a data scientist, because models that are making predictions often are put into production systems and used beyond just the DS themselves.&lt;/p&gt;
&lt;p&gt;Now, I don't think a data scientist has to be a seasoned software engineer, as most companies have SE teams that a data scientist can interface with. However, having some experience building a software product can be &lt;em&gt;very helpful&lt;/em&gt; for lubricating the interaction between DS and SE teams. Having a logical structure to your code, writing basic tests for it, and providing sufficiently detailed documentation, are all things that SE types will very much appreciate, and it'll make life much easier for them when coming to code deployment and helping with maintenance. (Aside: I strongly believe a DS should take primary responsibility for maintenance, and &lt;em&gt;not&lt;/em&gt; the SE team, and only rely on the SE team as a fallback, say, when people are sick or on vacation.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recommendation &amp;amp; Personal Story:&lt;/strong&gt; Again, nothing beats practice here. Working on your own projects, whether work-related or not, will help you get a feel for these things. I learned my software engineering concepts from participating in open source contributions. The first was a contribution to &lt;code&gt;matplotlib&lt;/code&gt; documentation, where I first got to use Git (a version control system) and Travis CI (a continuous integration system). It was there that I also got my first taste of software testing. The next year, I quickly followed it up with a small contribution to &lt;code&gt;bokeh&lt;/code&gt;, and then decided at SciPy 2016 to build &lt;code&gt;nxviz&lt;/code&gt; for my Network Analysis Made Simple tutorials. &lt;code&gt;nxviz&lt;/code&gt; became my first independent software engineering project, and also my &quot;capstone&quot; project for that year of learning. All-in-all, getting practice was instrumental for my learning process.&lt;/p&gt;
&lt;h3 id=&quot;topic-3:-industry-specific-business-cases&quot;&gt;Topic 3: Industry-Specific Business Cases&lt;/h3&gt;&lt;p&gt;This is something I learned from my time at Insight, and is non-negotiable. Data Science does not exist in a vacuum; it is primarily in the service of solving business problems. At Insight, Fellows get exposure to business case problems from a variety of industries, thanks to the Program Directors' efforts in collecting feedback from Insight alumni who are already Data Scientists in the industry.&lt;/p&gt;
&lt;p&gt;I think business cases show up in interviews as a test of a candidate's &lt;strong&gt;imaginative capacity and/or experience&lt;/strong&gt;: can the candidate demonstrate (a) the creativity needed in solving tough business problems, and (b) the passion for solving those problems? Neither of these are easy to fake when confronted with a well-designed business case. In my case, it was tough for me to get excited about data science in an advertisement technology firm, and was promptly rejected right after an on-site business case.&lt;/p&gt;
&lt;p&gt;It's important to note that these business cases are very industry specific. Retail firms will have a distinct need from marketing firms, and both will be very distinct from healthcare and pharmaceutical companies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recommendation &amp;amp; Personal Story:&lt;/strong&gt; For aspiring data scientists, I recommend prioritizing the general industry area that you're most interested in targeting. After that, start going to meet-ups and talking with people about the kinds of problems they're solving - for example, I started going to a &lt;a href=&quot;../../../../../blog/2017/8/31/what-would-be-useful-for-aspiring-data-scientists-to-know/#&quot;&gt;Quantitative Systems Pharmacology&lt;/a&gt; meet-up to learn more about quantitative problems in the pharma research industry; I also presented a talk &amp;amp; poster at a conference organized by Applied BioMath, where I knew lots of pharma scientists would be present. I also started reading through scientific journals (while I still had access to them through the MIT Libraries), and did a lot of background reading on the kinds of problems being solved in drug discovery.&lt;/p&gt;
&lt;h3 id=&quot;topic-4:-cs-fundamentals&quot;&gt;Topic 4: CS Fundamentals&lt;/h3&gt;&lt;p&gt;CS fundamentals really means things like algorithms and data structures. I didn't do much to prepare for this. The industry I was targeting didn't have a strong CS legacy/tradition, unlike most other technology firms doing data science (think the Facebooks, Googles, and Amazons), which do. Thus, I think CS fundamentals are mostly important for cracking interviews, and while problems involving CS fundamentals certainly can show up at work, unless something changes, they probably won't occupy a central focus of data science roles for a long time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recommendation &amp;amp; Personal Story:&lt;/strong&gt; As I don't really like &quot;studying to the test&quot;, I didn't bother with this - but that also meant I was rejected from tech firms that I did apply to (e.g. I didn't pass Google Brain's phone interview). Thus, if you're really interested in those firms, you'll probably have to spend a lot of time getting into the core data structures in computer science (not just Python). Insight provided a great environment for us Fellows to learn these topics; that said, it's easy to over-compensate and neglect the other topics. Prioritize accordingly - based on your field/industry of experience.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Now, let's talk about things you can start doing from now on that will snowball your credibility for entering into a role in data science. To be clear, these recommendations are made with a year-long time horizon in mind - these are not so much &quot;crack-the-interview&quot; tips as they are &quot;prepare yourself for the transition&quot; strategies.&lt;/p&gt;
&lt;h3 id=&quot;strategy-1:-create-novel-and-useful-material-and-share-it-freely&quot;&gt;Strategy 1: Create novel and useful material, and share it freely&lt;/h3&gt;&lt;p&gt;This is very important, as it builds a personal portfolio of projects that showcase your technical skill. A friend of mine, Will Wolf, did a self-directed &lt;a href=&quot;http://willwolf.io/2016/07/29/my-open-source-machine-learning-masters-in-casablanca-morocco/&quot;&gt;Open Source Masters&lt;/a&gt;, where he not only delved deeply into learning data science topics, but also set about &lt;a href=&quot;http://willwolf.io/&quot;&gt;writing blog posts&lt;/a&gt; that explained tough and difficult concepts for others to understand, and showcased data projects that he was hacking on while learning his stuff.&lt;/p&gt;
&lt;p&gt;Another friend of mine, Jon Charest, wrote a blog post doing a &lt;a href=&quot;http://jonchar.net/2016/05/20/exploring-metal-subgenres-with-python.html&quot;&gt;network analysis about metal bands&lt;/a&gt; and their shared genre labels - along the way producing a great Jupyter Notebook and network visualizations that yielded contributions to &lt;code&gt;nxviz&lt;/code&gt;! Starting with that project, he did a few more, and eventually landed a role as a data scientist at Mathworks.&lt;/p&gt;
&lt;p&gt;Apart from blog posts, giving technical talks is another great way to showcase your technical mastery. I had created the Network Analysis Made Simple tutorials, inspired by Allen Downey's X Made Simple series, as a way of solidifying my knowledge on graph theory and complex systems, and a very nice side product was recognition that I had capabilities in computation, resulting in more opportunities - my favourite being becoming a DataCamp instructor on Network Analysis!&lt;/p&gt;
&lt;p&gt;A key here is to create materials that are &lt;strong&gt;accessible&lt;/strong&gt;.  Academic conferences likely won't cut it for accessibility - they're often not recorded, and not published to the web, meaning people can't find it. On the other hand, blog posts are publicly accessible, as are PyCon/SciPy/JupyterCon/PyData videos. Another key is to produce &lt;strong&gt;novel&lt;/strong&gt; material - simple rehashes aren't enough; they have to bring value to someone else's. Your materials only count if people can find you and they expand someone's knowledge.&lt;/p&gt;
&lt;p&gt;A few other data scientists, I think, will concur very strongly with this point; Brandon Rorher has an &lt;a href=&quot;https://brohrer.github.io/imposter_syndrome.html&quot;&gt;excellent blog post&lt;/a&gt; on this.&lt;/p&gt;
&lt;h3 id=&quot;strategy-2:-talk-with-people-inside-and-adjacent-to-industries-that-you-re-interested-in.&quot;&gt;Strategy 2: Talk with people inside and adjacent to industries that you're interested in.&lt;/h3&gt;&lt;p&gt;The importance of learning from other people cannot be understated. If you're releasing novel and accessible material, then you'll find this one to be much easier, as your credibility w.r.t. technical mastery will already be there - you'll have opportunities to bring value to industry insiders, and you can take that opportunity to get inside information on the kinds of problems that are being solved there. That can really help you strategize the kinds of new material that you make, which feeds back into a positive cycle.&lt;/p&gt;
&lt;p&gt;Talking with people in adjacent industries and beyond is also very important. I think none put it better than Francois Chollet in his tweet:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;It&amp;#39;s better to be curious about many things beyond your field -- the more topics you&amp;#39;ve explored, the broader your inspiration in your field&lt;/p&gt;&amp;mdash; François Chollet (@fchollet) &lt;a href=&quot;https://twitter.com/fchollet/status/903103206812655621&quot;&gt;August 31, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;The main thing here is to have a breadth of ideas to draw on for inspiration when solving your own problem at hand. I had a first-hand taste of it when trying to solve the drug resistance problem (see above) - which turned out to be my introduction into the deep learning world proper!&lt;/p&gt;
&lt;h3 id=&quot;strategy-3:-learn-python&quot;&gt;Strategy 3: Learn Python&lt;/h3&gt;&lt;p&gt;Yes, I put this as a strategy rather than as a topic, mainly because programming languages are kind of arbitrary, and as such are less about whether a language is superior to others and more about whether you can get stuff done with that language.&lt;/p&gt;
&lt;p&gt;I suggest Python only because I've tasted for myself the triumphant feeling of being able to do all of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;environment setup (&lt;code&gt;conda&lt;/code&gt;), &lt;/li&gt;
&lt;li&gt;data extraction and cleaning (&lt;code&gt;pandas&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt;modelling (&lt;code&gt;scikit-learn&lt;/code&gt;, &lt;code&gt;PyMC3&lt;/code&gt;, &lt;code&gt;keras&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt;visualization (&lt;code&gt;matplotlib&lt;/code&gt;, &lt;code&gt;bokeh&lt;/code&gt;, &lt;code&gt;searborn&lt;/code&gt;), &lt;/li&gt;
&lt;li&gt;deployment (&lt;code&gt;Flask&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in one language. That's right - one language! (Sprinkling in a bit of HTML/CSS/JS in deployment, and bash in environment setup, of course.)&lt;/p&gt;
&lt;p&gt;There's very few languages with the flexibility of Python, and having a team converse in one language simply reduces that little bit of friction that comes from reading another language. There's a ton of productivity gains to be had! It's not the fastest, it's not the most elegant, but over the years, it's adopted the right ideas and built a large community developers, as such many people have built on it and used it to solve all manners of problems they're facing - heck, I even found a package that converts between traditional and simplified Chinese!&lt;/p&gt;
&lt;p&gt;It takes time to learn the language well enough to write good code with it, and nothing beats learning Python apart from actually building a project with it - I hope this idea of &quot;building stuff&quot; is now something ingrained in you after reading this post!&lt;/p&gt;
&lt;h3 id=&quot;strategy-4:-find-a-community-of-people&quot;&gt;Strategy 4: Find a community of people&lt;/h3&gt;&lt;p&gt;When it comes to building a professional network and making friends, nothing beats going through a shared experience of thick &amp;amp; thin together with other people. Data science, being a really new thing, is a growing community of people, and being plugged into the community is going to be important for learning new things.&lt;/p&gt;
&lt;p&gt;The Insight Summer 2017 class did this - we formed a closely-knit community of aspiring data scientists, cheered each other on, and coached each other on topics that were of interest. I know that this shared experience with other Insighters will give us a professional network that we can tap into in the future!&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;&lt;p&gt;Alrighty, to conclude, here's the topics and strategies outlined above.&lt;/p&gt;
&lt;p&gt;Topics to learn:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Must-have:&lt;/strong&gt; Statistical learning &amp;amp; statistical thinking&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good-to-have:&lt;/strong&gt; Software engineering&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good-to-have:&lt;/strong&gt; Business case knowledge&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dependency, Optional:&lt;/strong&gt; CS Fundamentals&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Strategies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Proven:&lt;/strong&gt; Make novel and useful materials and freely release them - teaching materials &amp;amp; projects!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Very Useful:&lt;/strong&gt; Learn from industry insiders.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Very Useful:&lt;/strong&gt; Learn Python.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don't Forget:&lt;/strong&gt; Build community.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All-in-all, I think it boils back down to the fundamentals of living in a society: it's still about &lt;strong&gt;creating real value for others&lt;/strong&gt;, and &lt;strong&gt;receiving commensurate recognition&lt;/strong&gt; (not always money, by the way) for what you've delivered. Tips and tricks can sometimes get us ahead by a bit, but the fundamentals matter the most.&lt;/p&gt;
&lt;p&gt;For aspiring data scientists, some parting words: build useful stuff, learn new things, demonstrate that you can deliver value using data analytics and work with others using the same tools, and good luck on your job hunt!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/8/24/reading-and-writing-docs-the-overlooked-programming-skill/">
    <title type="text">Reading &amp; Writing Docs: The Overlooked Programming Skill?</title>
    <id>urn:uuid:4182b54b-1dbb-3681-9bcd-01e6851eb7c4</id>
    <updated>2017-08-24T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/8/24/reading-and-writing-docs-the-overlooked-programming-skill/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I recently read a blog article by DataCamp's CTO (Dieter) on how to scale their projects and their engineering team - it's a &lt;a href=&quot;https://medium.com/datacamp/technical-vision-part-1-5f016c163340&quot;&gt;great read&lt;/a&gt;! In the article, Dieter states that the only way to scale an engineering team is to have well-written docs. I can see the benefits to doing it this way - we minimize the number of channels that any coder needs to use to find out information; the docs should be the place where the intent and technical detail of the code are simultaneously documented alongside usage examples.&lt;/p&gt;
&lt;p&gt;Thus, in the final weeks up to starting my new job at Novartis as a Data Scientist, I decided to make sure I have the practice of writing, reading and publishing docs as good as muscle memory. I can already envision cases where, while conducting and building analyses, I end up writing a bunch of generally-useful functions that should be documented as well. What I write may eventually need to be used by someone else, including my future self; keeping track of how exactly a function is intended to be used is going to be very useful.&lt;/p&gt;
&lt;p&gt;I think reading and writing docs is an overlooked skill in programming. It's probably because this isn't a test of &quot;creative capacity&quot; (i.e. can you build something new), which is the &quot;sexy&quot; thing. It's more a test of &quot;maintenance capacity&quot; - and this is given less value and importance in the coding world. But it's incredibly important - many basic problems can be solved by reading the docs... but also, so many problems can be avoided by writing really good docs! The onus is on both parties - package maintainers &lt;em&gt;and&lt;/em&gt; developers - to write &lt;em&gt;and&lt;/em&gt; read good docs.&lt;/p&gt;
&lt;p&gt;But writing good docs is a tough job! I absolutely agree with this. There are different styles through which developers read docs - some prefer examples, while others just want to see function definitions - and it's very difficult to cater to every style. I personally think starting off with the style one's most comfortable with, and then gradually accepting community contributions, is the right way to go.&lt;/p&gt;
&lt;p&gt;One package that I maintain, &lt;a href=&quot;http://github.com/ericmjl/nxviz&quot;&gt;&lt;code&gt;nxviz&lt;/code&gt;&lt;/a&gt;, used to not have any docs written apart from that single file in the README. Thanks to my friend &lt;a href=&quot;https://www.linkedin.com/in/rempic/&quot;&gt;Remi Picone&lt;/a&gt;, I was able to learn how to configure Sphinx to get my docs working through copying &lt;a href=&quot;https://github.com/rempic/Image-Features-Extraction&quot;&gt;his example repository&lt;/a&gt;. Through that, I configured Sphinx to build docs on my nxviz project - and finally got it going! You can find it on &lt;a href=&quot;http://nxviz.readthedocs.io/en/latest/&quot;&gt;RTFD&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Learning this was really fun - looking forward to putting up more docs!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/8/10/next-steps/">
    <title type="text">Next Steps</title>
    <id>urn:uuid:7eda5309-b803-3c48-9d79-c9535e1e28bf</id>
    <updated>2017-08-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/8/10/next-steps/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Signed and done! I will be joining the Novartis Institutes for Biomedical Research (NIBR) in September, as part of the Scientific Data Analysis (SDA) team under Novartis Informatics (NX).&lt;/p&gt;
&lt;p&gt;NIBR is the research arm of Novartis, and the SDA team is essentially a &quot;Data Special Ops&quot; team inside NIBR. The nature of the position involves both internal consulting and the development of new initiatives across teams.&lt;/p&gt;
&lt;p&gt;The nature of the role I'm being hired into is in statistical learning, which is a general direction I've been moving towards during my time in grad school. I picked up and implemented a number of useful and interesting deep learning algorithms back then, and over the past half a year, have finally gotten in underneath the hood of graph &amp;amp; image convolutions, variational autoencoders and gaussian processes. It's really fun stuff, at its core, and to me, it's even more fun translating biological and chemical data problems into that language, and back.&lt;/p&gt;
&lt;p&gt;After a summer learning lots and networking with industry professionals and fellow Fellows at Insight, I'm ready for a bit more structure in my life. Looking forward to starting there!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/8/2/open-source-software/">
    <title type="text">Open Source Software</title>
    <id>urn:uuid:c474ff5a-5342-34a8-abc9-81ea30c5ca0c</id>
    <updated>2017-08-02T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/8/2/open-source-software/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Open source software is awesome, and I've just been thoroughly convinced of why.&lt;/p&gt;
&lt;p&gt;Today, I put in a &lt;a href=&quot;https://github.com/pymc-devs/pymc3/pull/2470&quot;&gt;PR&lt;/a&gt; to PyMC3. This was a bug fix related to the PyMC3 multinomial distribution's random variates generator, which uses &lt;code&gt;numpy&lt;/code&gt;'s multinomial under the hood, which arose from floating point precision errors.&lt;/p&gt;
&lt;p&gt;I first encountered this bug last week, when I started trying out the use of PyMC3 on my GPU tower. GPU stuff is tricky. One of the issues relates to floating point precision. I'm not well-versed enough on this to write intelligently about the underlying causes, but one thing I learned is that GPUs prefer 32-bit floating point precision (&lt;code&gt;float32&lt;/code&gt;), while modern CPUs can handle 64-bit (&lt;code&gt;float64&lt;/code&gt;). (I'm sure this will change in the future.) In the vast majority of &quot;large number&quot; computations, it's no big deal, but when we deal with small numbers (decimals in the thousandths range and smaller), addition errors can crop up.&lt;/p&gt;
&lt;p&gt;This was the exact problem I was facing. I had some numbers crunching on the GPU in &lt;code&gt;float32&lt;/code&gt; space. Then, I had to pass them back to &lt;code&gt;numpy&lt;/code&gt;'s multinomial, which implicitly converts everything to &lt;code&gt;float64&lt;/code&gt;. Because multinomial takes in a list of &lt;code&gt;p&lt;/code&gt;s (probabilities) that must sum to one, I was getting issues with my list of &lt;code&gt;p&lt;/code&gt;s summing to just infinitesimally (in computation land) greater than one. I dug around on-and-off for about a week to look for a solution, but none came. Instead, I had to rely on a small hack that I didn't like, adding a 1 millionth value to the sum and renormalizing probabilities... but that felt hacky and unprincipled.&lt;/p&gt;
&lt;p&gt;The fix was inspired by someone else's problems that was discussed on &lt;code&gt;numpy&lt;/code&gt;'s repository. The trick was to convert the numbers from &lt;code&gt;float32&lt;/code&gt; to &lt;code&gt;float64&lt;/code&gt; first and re-compute the probabilities in &lt;code&gt;float64&lt;/code&gt; precision. I implemented that locally, and everything worked! I quickly ran two of the most relevant tests in the test suite, and they both passed. So I pushed up to GitHub and submitted a PR on this (after checking in with the lead devs on their issue tracker) - and it was just merged tonight!&lt;/p&gt;
&lt;p&gt;If PyMC3's and &lt;code&gt;numpy&lt;/code&gt;'s code bases were not open source, with issues discussed openly, I would not have been able to figure out a possible fix to the issues with the help of other people. Also, I wouldn't have been able to patch the codebase locally first to see if it solved my own problems. I also wouldn't have access to the test suite to check that nothing was broken. All-in-all, working with an open source codebase was instrumental to getting this fix implemented.&lt;/p&gt;
&lt;p&gt;Big shout-out to the PyMC devs I interacted with on this - Colin &amp;amp; Junpeng. Thank you for being so encouraging and helpful!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/22/bayesian-neural-networks/">
    <title type="text">Bayesian Neural Networks</title>
    <id>urn:uuid:91bffec6-e833-3f8e-8d9e-01a12e06bb4e</id>
    <updated>2017-07-22T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/22/bayesian-neural-networks/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;During this week, while us Insight Fellows begin going out to interview with other companies, my &quot;side hustle&quot; has been working on my &lt;a href=&quot;https://github.com/ericmjl/bayesian-analysis-recipes&quot;&gt;Bayesian Analysis Recipes&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;Two particularly interesting problems I've wanted to write my own implementation for are multinomial classification and Bayesian deep learning. I finally got both of them done today, after about 2-3 days of hacking on them.&lt;/p&gt;
&lt;p&gt;Multinomial classification (&lt;a href=&quot;https://github.com/ericmjl/bayesian-analysis-recipes/blob/master/multiclass-logistic-regression-cover-type.ipynb&quot;&gt;notebook here&lt;/a&gt;) is the problem where we try to classify an item as being one of multiple classes. This is the natural extension to binary classification (done by logistic regression). To do this, I took the &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/covertype&quot;&gt;forest cover dataset&lt;/a&gt; and used PyMC3 to implement multinomial logistic regression. Seeing how to do it with PyMC3 was the most important aspect of this; actual accuracy wasn't much of a concern for me.&lt;/p&gt;
&lt;p&gt;However, having seen the classification report (at the bottom of the notebook), and having read that the dataset was originally classified using neural networks, I immediately had the thought of doing a Bayesian neural network for multi-class classification, having seen it implemented for binary classification on the PyMC3 website.&lt;/p&gt;
&lt;p&gt;Bayesian neural networks are not hard to intuit - basically, we place priors on the weights, rather than learning point estimates. In doing so, we are able to propagate uncertainty forward to predictions. Speaking as a non-expert in the field, I think the tricky part is the sampling algorithms needed.&lt;/p&gt;
&lt;p&gt;One thing nice about the field of Bayesian deep learning is the use of variational inference to approximate the true distribution of predictions with a mathematically more tractable one (e.g. a Gaussian). In doing so, we gain a fast way towards approximately learning the uncertainty in predictions - essentially we trade a little bit of accuracy for a lot of speed. For complex models like neural nets, this can be very valuable, as the number of parameters to learn grows very, very quickly with model complexity, so anything fast can make iteration easier.&lt;/p&gt;
&lt;p&gt;Starting with the code &lt;a href=&quot;http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/&quot;&gt;from Thomas Wiecki's website&lt;/a&gt;, I hacked together a few utility functions and boiled down the example to its essentials. Feed-forward neural nets aren't difficult to write - just a bunch of matrix ops and we're done. The &lt;a href=&quot;https://github.com/ericmjl/bayesian-analysis-recipes/blob/master/multiclass-classification-neural-network.ipynb&quot;&gt;notebook is available as well&lt;/a&gt;. One nice little feature is that by going with a deep neural network, we have additional predictive accuracy!&lt;/p&gt;
&lt;p&gt;Moving forward, I'd like to improve on that notebook a bit more, by somehow implementing/developing a visualization for multiclass classification &lt;strong&gt;uncertainty&lt;/strong&gt; which is the thing we gain from going Bayesian. Hopefully I'll be able to get to that next week - it's shaping up to look quite hectic!&lt;/p&gt;
&lt;p&gt;As a side note, I found a bug with the multinomial distribution implementation in PyMC3, and am working with one of the core developers to get it fixed in PyMC3's master branch. (Thanks a ton, Junpeng, if you ever get to read this! ) In the meantime, I simply took his patch, modified mine a little bit, and used the patched up PyMC3 for my own purposes.&lt;/p&gt;
&lt;p&gt;This is why I think open source is amazing - I can literally patch the source code to get it to do what I need correctly! Wherever I work next has to be supportive of things like this, and have to allow re-release of generally/broadly useful code that I touch - it is the right thing to do!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/17/lessons-learned-during-insight/">
    <title type="text">Lessons Learned During Insight</title>
    <id>urn:uuid:94213d9c-1919-363d-a3a8-ef2bf605cb81</id>
    <updated>2017-07-17T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/17/lessons-learned-during-insight/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;&lt;strong&gt;(a) Solving healthcare goes beyond solving the science underlying it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At its core, healthcare delivery is essentially a human problem.  Even what we choose to optimize for is a hard problem. Do we optimize for changing human behaviour, or do we optimize for more precise treatments?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(b) Healthcare is complex&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The biggest thing preventing a &quot;solving of healthcare&quot; is misaligned incentives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(c) I like scientific data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Regardless of the lesson that healthcare needs to be solved with more than science, I still found myself naturally much more engaged with companies that were dealing with scientific data as part of their data science problems. Teams that were dealing with other types of data: insurance claims, financial, marketing, platform product analytics, click streams... these were much less engaging. I know my best fit now, though I won’t rule out other teams.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(d) People can change the equation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I met with some people whose intellect and grasp of knowledge I really admire! Additionally, passion is infectious. It helps to work with colleagues who energize one another, rather than drain each others’ energy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(e) Some Insight alumni are awesome&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;And I want to be like them when I help with mentoring for the next batch. Perhaps if I get a chance to interview others, I’d like to be able to model how I interview after the alumni mentors.&lt;/p&gt;
&lt;p&gt;Biggest shout-out to George Leung, who works for Vectra, tailored his mentoring session by first asking me about my Insight project, which involved Gaussian processes and variational auto-encoders (VAEs). George asked me first about what VAEs were, and then asked me to solve a Bayes problem on the board. I could tell he was building his questions on-the-fly.&lt;/p&gt;
&lt;p&gt;The other shout-out goes to Ramsey Kamar, who went through the “Big 4” questions: tell me about yourself, what’s your previous accomplishments, how did you face a conflict, and what’s your biggest weakness. His feedback to me was direct, positive, and most importantly, always encouraging.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(f) Humanities tools are needed&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On reflection, I think that if we’re going to solve the “human” portion of healthcare, we’re going to need tools from the humanities - the tools that let us qualitatively and quantitatively study human behaviour. While data science can provide a quantitative path towards a solution, the qualitative side of it will remain as important as ever.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/15/insight-week-7/">
    <title type="text">Insight Week 7</title>
    <id>urn:uuid:ac1b8134-3672-3195-8642-f1a29ae6f733</id>
    <updated>2017-07-15T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/15/insight-week-7/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Aaand with that, week 7 of Insight is done!&lt;/p&gt;
&lt;p&gt;I had a short week because of SciPy 2017, and I'm thankful that I got a chance to head out there - had the opportunity to reconnect with many friends from the SciPy community.&lt;/p&gt;
&lt;p&gt;The two days of Week 7 that I experienced were probably the weirdest week 7 any Fellow has experienced to date. Because I had missed a demo on account of SciPy, and because the company didn't want to just watch the pre-recorded demo video, I made a trek up to Cambridge to demo on-site. What initially was a 30 minute session turned out to be a 1.5 hr demo.&lt;/p&gt;
&lt;p&gt;I have two more demo obligations to fulfill next week. Other than that, it's going to be mostly interview preparation with other fellows, and more data and coding challenges, and more studying of topics that we're not familiar with. I am trying to brush up on SQL more, as I can see it being a useful tool to have to query data out of databases.&lt;/p&gt;
&lt;p&gt;Now that we're done with Week 7, we're going to be alumni soon. As such, I've began thinking about how I could give back as an alumni. Some ideas have come to mind, inspired by what others have done.&lt;/p&gt;
&lt;p&gt;Firstly, I think I can help standardize future Fellows' coding environments by providing a set of annotated instructions for installing the Anaconda distribution of Python. Perhaps even an evening workshop on the first Thursday might be useful.&lt;/p&gt;
&lt;p&gt;Secondly, I've come to recognize that the biggest bottleneck for Fellows' projects is the web deployment and design portion. Model training to obtain an MVP is fairly fast - one of &lt;code&gt;scikit-learn&lt;/code&gt;'s models is often good enough. However, most of us didn't know HTML and Bootstrap CSS, and the deadline makes it stressful enough to pick this up on-the-fly. (The stress is probably compounded by the fact that the web app/blog post is not the most intellectually interesting portion of the project.) Perhaps a workshop at the end of Week 2 or beginning of Week 3 might be good.&lt;/p&gt;
&lt;p&gt;Thirdly, I see this trend where a lot more projects are going to start using deep learning. I think putting a workshop together with, say, Jigar, might be a useful thing to have.&lt;/p&gt;
&lt;p&gt;Finally, my interview simulator questions have become famous for being a 'hybrid' between stats, ML and CS. It's very much in the same vein as what I got when I interviewed with Verily.&lt;/p&gt;
&lt;p&gt;Until we get hired, we are allowed (and one might even say, expected) to continue coming into the office to help each other prepare for upcoming interviews. We're all looking forward to getting hired and solving data problems!&lt;/p&gt;
&lt;p&gt;With this post, I think I'll end the regular blog post series here. Hope this post series was an informative insight into Insight! Next one I'll post is going to be a summary of lessons learned from my time as an Insight Health Data Fellow.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/12/scipy-2017/">
    <title type="text">SciPy 2017</title>
    <id>urn:uuid:2c603928-9acb-38b4-916c-cc3edd590b7e</id>
    <updated>2017-07-12T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/12/scipy-2017/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;I just finished from SciPy 2017!  This was a fruitful conference, and I'm glad I managed to make it.&lt;/p&gt;
&lt;p&gt;Monday was the first day. I wanted to get a better feel for the Jupyter widgets ecosystem, and as such I sat in on the corresponding &lt;a href=&quot;https://scipy2017.scipy.org/ehome/220975/493418/&quot;&gt;tutorial&lt;/a&gt;. That happened to be the only tutorial I sat in live.&lt;/p&gt;
&lt;p&gt;Nonetheless, one nice thing about the tutorials is that they are live recorded, and so we can watch the ones we missed on our own time when back home. These are the ones I hope to catch, partly out of interest, partly from recommendations by other conference attendees who sat in them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Numba&lt;/li&gt;
&lt;li&gt;Holoviews&lt;/li&gt;
&lt;li&gt;Dask&lt;/li&gt;
&lt;li&gt;scikit-image&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking at the list, I kind of realize now how much of a Continuum Analytics fanboy I've become...&lt;/p&gt;
&lt;p&gt;On the second day, I delivered my own Network Analysis Made Simple. I collected some feedback right at the end of the tutorial, and it looked like they were overall very positive. Many liked the whiteboard illustrations that I added on. When delivering this at PyCon, I think it would benefit from having a whiteboard of sorts.&lt;/p&gt;
&lt;p&gt;The third day was the start of the conference talks. There's many, many great talks out there! I also had the opportunity to connect with new people over breakfast, lunch, coffee and dinner. I tried hosting &quot;office hours&quot;, like Matt Davis did last year, but I think I announced it a bit too late.&lt;/p&gt;
&lt;p&gt;All-in-all, I think it was great to attend SciPy 2017 this year. I'm happy to have not broken the chain of attendance. Looking forward to serving on next year's organizing committee again, and I hope to have a new tutorial in the works!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/8/insight-week-6/">
    <title type="text">Insight Week 6</title>
    <id>urn:uuid:cee9eb4d-7a48-332d-a06c-ed17e1ff1b28</id>
    <updated>2017-07-08T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/8/insight-week-6/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;We had a short week this week because of the long July 4th weekend (Happy Birthday, America!).&lt;/p&gt;
&lt;p&gt;Wednesday was my second demo day, this time at MGH. There were 8 of us demoing at MGH's Clinical DS team, and I really enjoyed the interaction with them. The team asked of me two technical questions about Flu Forecaster, both of which were analogous to other questions I had heard before. After the demo, we hung out with the team and chatted a bit about their latest projects.&lt;/p&gt;
&lt;p&gt;In the afternoon, I focused on doing the data challenge and leetcode exercises; in the evening, I (at the last minute) signed up for back-to-back behavioral and ML interview practice sessions. It was good to chat with the alumni helping with the sessions, as I learned much more about their thought process. In the future, I'll probably be called on to interview other people, and I will definitely draw on my experiences here.&lt;/p&gt;
&lt;p&gt;On Thursday we had more prep. I helped with mock interviewing by being an observer for Xi and an interviewer for Angela. The role-playing with Angela was an interesting one for me. I tried playing the role of a conversational but technically-competent interviewer. Also asked questions genuinely out of curiosity too. I think that combined with Angela's outgoing personality kept the conversation enjoyable for all three of our spectators.&lt;/p&gt;
&lt;p&gt;In the late afternoon, an NYC session alum came by and gave us a session on data challenges. The exercise he gave was quite neat - basically, given one categorical output column and a slew of other feature columns, train the best model that has the highest accuracy score. Oh, the twist? Do it in 25 minutes.&lt;/p&gt;
&lt;p&gt;The key point from this exercise was to have us get prepared for an on-site data challenge. The on-site data challenge mainly helps the hiring team check that we have the necessary coding chops to work with the team. It also lets them see how we perform under time constraints. The most important thing is to deliver a model with some form of results. Iterating fast is very important. Thus, it helps to push out fast one model that works.&lt;/p&gt;
&lt;p&gt;On Friday, we did another round of the interview simulator. I thought it was better run this time round. The mutual feedback from one another is very helpful. I was tasked with a stats question, which I melded into a hybrid stats + CS question, thus modelling what I had received when I was interviewed at Verily. FWIW, the question I asked was to define bootstrap resampling (sampling with replacement), implement it using the Python standard library, and discuss the scenarios where it becomes a useful thing.&lt;/p&gt;
&lt;p&gt;If tasked with a similar one for the next time, I will probably ask about writing a function to sample from a Bernoulli distribution using only the Python standard library. It's useful to know how to implement these statistical draws when it's not easy or impossible to use other libraries. (I had to do it when trying out the PyPy interpreter a few years back, and didn't want to mess with installing &lt;code&gt;numpy&lt;/code&gt; for PyPy.)&lt;/p&gt;
&lt;p&gt;I liked a few of the other questions asked as well - for example, the knapsack problem posed by Steve: Given a set of produce items, each with their own value and weight (in Kg), and a knapsack that can only carry a maximum weight of produce, find the set of produce that will maximize value at the market.&lt;/p&gt;
&lt;p&gt;That afternoon, we slowed things down a bit. Regardless of how much we benefit from them, the interview simulators nonetheless are tiring. But that's the key point - interviews are day-long, exhausting endeavours that test stamina and ability to switch between contexts (both technical and social). The simulator aims to simulate that.&lt;/p&gt;
&lt;p&gt;Looking forward to next week. For me it'll be a short one, because I'll be at SciPy 2017 to lead a Network Analysis tutorial. Also hoping to represent Insight well!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/7/1/insight-week-5/">
    <title type="text">Insight Week 5</title>
    <id>urn:uuid:a1b7ad70-771c-3183-821a-60f700b77600</id>
    <updated>2017-07-01T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/7/1/insight-week-5/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;First off, Happy Canada Day!&lt;/p&gt;
&lt;p&gt;Week 5 is primarily focused on interview prep as a bunch of us go out for our demos.&lt;/p&gt;
&lt;p&gt;We kicked off Monday with an interview prep field day. The main areas of focus for us were CS fundamentals, machine learning, SQL, and behavioral interviewing. I found SQL to be my weakest point, and I'll definitely be focusing a lot of efforts on there. I had a chance to explain gradient descent and regularization using algebra - something I never thought I would do!&lt;/p&gt;
&lt;p&gt;On Tuesday, Fellows began going outside for demos. My first demo will be at Boston Health Economics this Thursday, followed by (in no particular order) MGH, Biogen, Merck, OM1, and Immuneering. Definitely looking forward to presenting Flu Forecaster to them!&lt;/p&gt;
&lt;p&gt;On the side, we also started thinking through computer science fundamentals problems, and doing data analytics challenges. CS fundamentals are what you think it would be, covering data structures and algorithms. I found myself to be particularly fond of recursion, and implemented a recursive algorithm for something that could be solved in linear time without recursion. It was good to see my biases, and to try my hand at implementing the same thing in fundamentally two different styles.&lt;/p&gt;
&lt;p&gt;In the evening, Nick (one of the fellows) gave us a run through on SQL. It was very useful to have his perspective, which was basically that most of the problems we will encounter involve some degree of nested searches, and that we have to work backwards from what we want. I also had a good perspective from my alumni mentor on how to approach describing my thesis to interviewers.&lt;/p&gt;
&lt;p&gt;On Wednesday, the interview prep continued with more coding challenges, demo trips, and fellow-led workshops. Together with Jeff and Jigar, we led a deep learning fundamentals workshop, in which we went through how deep learning works for feed forward neural networks and convolutions neural networks.&lt;/p&gt;
&lt;p&gt;Thursday came my first demo, which was at Boston Health Economics. Overall, I thought the demo session went well, and that Catherine, our host, kept engaged with the presentations. I very much appreciate her intellect. Additionally, I took the approach of &quot;free styling it&quot; (of course conditioned on having previously rehearsed it enough times), which resulted in a demo presentation that was overall smoother than what I had previously delivered&lt;/p&gt;
&lt;p&gt;Apart from that, we continued our interview prep. This involved more CS fundamentals for me, getting more practice with common algorithms, and finishing the coding exercises that Ivan gave us.&lt;/p&gt;
&lt;p&gt;On Friday, we did an interview simulator, in which we practiced interviewing one another. This gave me a better view into the thought process that an interviewer might be going through, particularly when conducting a technical interview. From prior experience interviewing, I remembered that my most pleasant interviews were with individuals who kept the atmosphere positive, encouraging, and provided hints along the way. Thus, I tried to conduct the mock interviews in the same way.&lt;/p&gt;
&lt;p&gt;In the afternoon, I gave a very short workshop on how to write Pythonic code, which covered &lt;a href=&quot;https://www.python.org/dev/peps/pep-0008/#introduction&quot;&gt;&lt;code&gt;PEP8&lt;/code&gt;&lt;/a&gt; (which is now check-able using &lt;a href=&quot;https://github.com/PyCQA/pycodestyle&quot;&gt;&lt;code&gt;pycodestyle&lt;/code&gt;&lt;/a&gt;). It was fun seeing everybody go, &quot;Whoa! Atom can do that?!&quot; and then promptly going ahead to clean up their code according to the &lt;code&gt;flake8&lt;/code&gt; linter's recommendations.&lt;/p&gt;
&lt;p&gt;Interspersed throughout the week, I made an effort to summarize my thesis work a bit more. I think I have a few ways/hooks to explain it to a 'recruiter without a technical background', a 'computer scientist without biology background', and a 'biologist without a computing background'. Making it concise with a good &quot;hook&quot; was the hardest part, but I think I have something good now.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/30/using-bokeh-in-fluforecaster/">
    <title type="text">Using Bokeh in FluForecaster</title>
    <id>urn:uuid:c11e7beb-02e6-34d1-8a57-5d26a00844bc</id>
    <updated>2017-06-30T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/30/using-bokeh-in-fluforecaster/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Author: Eric J. Ma, Insight Health Data Science Fellow (Boston 2017b)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this blog post, I will show how Bokeh featured in my Insight project, FluForecaster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a Health Data Fellow at Insight, we spend about 3 weeks executing on a data project, which we demo at companies that are hiring. I built &lt;a href=&quot;https://fluforecaster.herokuapp.com/&quot;&gt;FluForecaster&lt;/a&gt;, which was a project aimed at forecasting influenza sequence evolution using deep learning.&lt;/p&gt;
&lt;p&gt;My choice of project was strategically aligned with my goals on a few levels. Firstly, I wanted to make sure my project showcased deep learning, as it's currently one of the hottest skills to have. Secondly, I had components of the code base written in separate Jupyter notebooks prior to Insight, meaning, I could execute on it quickly within the three weeks we had. Thirdly, I had intended to join Insight primarily with the goal of networking with the Insight community, and that basically meant 'being a blessing' to others on their journey too - if I could execute fast and well on my own stuff, then there'd be time to be a team player with other Fellows in the session, and help them get their projects across the finish line.&lt;/p&gt;
&lt;p&gt;Each of us had to demo a &quot;final product&quot;. Initially, I was thinking about a &quot;forecasting dashboard&quot;, but one of our program directors, Ivan, suggested that I include more background information. As such, I decided to make the dashboard an interactive blog post instead. Thus, with FluForecaster being a web-first project, I finally had a project in which I could use Bokeh as part of the front-end.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applying Bokeh&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bokeh was used mainly for displaying three data panels in the browser. Firstly, I wanted to show how flu vaccine efficacy rarely crossed the 60% threshold over the years. Secondly, I wanted to show a breakdown of the number of sequences collected per year (as used in my dataset). Thirdly, I wanted to show a visual display of influenza evolution.&lt;/p&gt;
&lt;p&gt;For yearly vaccine effectiveness, it was essentially a line and scatter chart, with the Y-axis constrained between 0 and 100%. I added a hover tooltip to enable my readers to see the exact value of vaccine effectiveness as measured by the US CDC.&lt;/p&gt;
&lt;p&gt;To show the number of sequences per year in the dataset, the same kind of chart was deployed.&lt;/p&gt;
&lt;p&gt;Bokeh magic became really evident later when I wanted to show sequence evolution in 3 dimensions. Because 3D charts are generally a poor choice for a flat screen, I opted to show pairs of dimensions at a time. A nice side-effect of this is that because my &lt;code&gt;ColumnDataSource&lt;/code&gt; was shared amongst each of the three pairs of coordinates, panning and selection was automatically linked for free.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Usage Pros and Cons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bokeh's API is very powerful, in that it supplies many plotting primitive objects (glyphs, particularly), and that makes it a big plus for users who are experienced with the library, who are creating complex interactive charts.&lt;/p&gt;
&lt;p&gt;Most of my fellow Fellows at Insight ended up using the &lt;code&gt;bokeh.plotting&lt;/code&gt; interface, and I did too. I think the &lt;code&gt;bokeh.plotting&lt;/code&gt; interface provides the best balance between ease-of-use and flexibility. If you take a look at the code &lt;a href=&quot;https://github.com/ericmjl/flu-sequence-predictor/blob/master/utils/webplots.py#L15&quot;&gt;here&lt;/a&gt;, you'll notice that there's often a bit of boilerplate that gets repeated with variation, such as in the configuration of custom hover tools. I think this is the tradeoff we make for configurability... or I might just be not writing code most efficiently. :)&lt;/p&gt;
&lt;p&gt;There were times where I was tempted to just use the &lt;code&gt;bkcharts&lt;/code&gt;' declarative interface instead. It's a lot more easy to use. However, I did have some time on hand, and wanted to get familiar with the &lt;code&gt;bokeh.plotting&lt;/code&gt; interface, because there's a possibility that I might want to make wrappers for other visualizations that can lend themselves to a declarative API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embedding Visualizations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I built my interactive blog post using a combination of Flask, hand-crafted HTML, Bootstrap CSS &amp;amp; JS, and Bokeh - which took care of the bulk of visuals. I drew static figures using Illustrator.&lt;/p&gt;
&lt;p&gt;Embedding the necessary Bokeh components wasn't difficult. Very good documentation is available on the &lt;a href=&quot;http://bokeh.pydata.org/en/latest/docs/user_guide/embed.html&quot;&gt;Bokeh docs&lt;/a&gt;. The key insight that I had learned was that I could have the &lt;code&gt;components&lt;/code&gt; passed into my Flask app functions' &lt;code&gt;return&lt;/code&gt; statements, and embed them using Jinja2 templating syntax. An example can be found &lt;a href=&quot;https://github.com/ericmjl/flu-sequence-predictor/blob/master/templates/index.html#L81&quot;&gt;here&lt;/a&gt;. Basically, &lt;code&gt;components&lt;/code&gt; returns a &lt;code&gt;div&lt;/code&gt; and a &lt;code&gt;js&lt;/code&gt; object, which are essentially just strings. To embed them in the templates, we use the syntax &lt;code&gt;{{ div|safe }}&lt;/code&gt; and &lt;code&gt;{{ js|safe }}&lt;/code&gt;. That &lt;code&gt;|safe&lt;/code&gt; is very important: it tells the Jinja2 templating engine that it's safe to render those pieces of Javascript and HTML.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Through the project, I became a lot more familiar with the Bokeh plotting library. Now I feel a bit torn! I've contributed to both the Bokeh and &lt;code&gt;matplotlib&lt;/code&gt; projects, and I love them both! I've also come to deeply respect the lead developers of both projects, having interacted with them many times. If I were to make a comment on &quot;where to use what&quot; based on my experience, it'd probably still be the conservative view of &quot;&lt;code&gt;matplotlib&lt;/code&gt; for papers, &lt;code&gt;bokeh&lt;/code&gt; for the web&quot;... but I'm sure that will be outdated soon. Who knows how the Python plotting landscape will evolve - it's exciting times ahead, and at least for now, I'm happy for the experience driving a dataviz project with Bokeh!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/24/insight-week-4/">
    <title type="text">Insight Week 4</title>
    <id>urn:uuid:96696a9c-0bdb-3a80-8138-781fb368c17d</id>
    <updated>2017-06-24T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/24/insight-week-4/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Week 4 has been all about demos. Polishing our demos, picking companies that we want to demo at (and possibly interview at later on). Every morning, we practice our demos, 10 minutes per person, with the goal of keeping our demo to under 5 minutes to leave time for Q&amp;amp;A. I've found that the act of rehearsing our demos makes it much easier to pick out where I need improvement. For example, I tended to have trouble with explaining the validation portion smoothly, even though I knew what I was doing there. A tool that seems useful, especially for short demos, is to write out exactly what I want to say, and that definitely helped.&lt;/p&gt;
&lt;p&gt;On the type of work that I'm interested in, here's some things I've become much clearer on.&lt;/p&gt;
&lt;p&gt;Firstly, the factors I'm considering for a company. The ideal combination is: a company that deeply values the hard sciences (in my case life sciences), and is solving very tough technical problems that requires growth in and mastery of deep technical topics, on a team that encourages experimentation, personal growth, and open source contributions on company time. We'd have to be at the innovation boundary of very powerful techniques. This is important for me, because I believe that 5-10 years down the road, I would have mastery over very foundational and broadly applicable tools with the appropriate experience applying them to real-world problems, which I could leverage to solve more cool and interesting problems. It's also a good defence against being pigeon-holed into a particular domains or tasks - autonomy in problem selection and definition is very important to me, so most of my choices aim to maximize that over money.&lt;/p&gt;
&lt;p&gt;Secondly, I've effectively ruled out companies that are dealing with non hard-science data, e.g. insurance claims, marketing &amp;amp; advertising, finance, and business data. Having applied computation to the life sciences over grad school, and being trained in the life sciences for over 10 years, I'm not ready to give up that background knowledge to work on other problems. I also believe that investing in the hard sciences means investing in the next wave of real-world innovation, and I'd like to ride that wave.&lt;/p&gt;
&lt;p&gt;Thirdly, within the next 5 years, I see myself growing as a technical person, rather than a management person. People issues, particularly conflict resolution, make it difficult to focus on being a good craftsman, and I much more enjoy craftsmanship than management.&lt;/p&gt;
&lt;p&gt;Now, on the companies that have come by...&lt;/p&gt;
&lt;p&gt;Most are using open data science tools in their toolkit, and this mostly means Python and R, Spark and a few other big DB tools. Some are still using SAS (.................) and didn't show a trend towards open data science languages, and effectively ruled themselves out of contention. (Using legacy tools signals a lack of forward-thinking and a desire to favour the status quo over pushing boundaries.)&lt;/p&gt;
&lt;p&gt;Some have given us words of wisdom. One guy basically said that healthcare has messed up (he used stronger language) incentives. Another said that to solve healthcare we need to first solve human behaviour. All very interesting points that are well-taken on my side. A non-healthcare company told us that if we're not paying for a service, then we're the product.&lt;/p&gt;
&lt;p&gt;In our session, it was basically the pharma research arms that piqued my interest the most, aside from one hospital's internal startup team. The gap in interest between #4 and #5 (for me, at least) was really big, and the gap of interest from #5 to the rest was even larger.&lt;/p&gt;
&lt;p&gt;Anyways, week 5 begins soon, and we pivot over into interview prep. Looking forward to learning lots, particularly doing deep dives on my weak spots!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/17/insight-week-3/">
    <title type="text">Insight Week 3</title>
    <id>urn:uuid:a1e1c38d-57ab-3aef-b95a-07116118da6d</id>
    <updated>2017-06-17T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/17/insight-week-3/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;This week was a week of polishing our final products and getting them in shape for our demos. Pushing a product to final production really involves a lot of nitty-gritty tweaking. In this blog post, I'll detail some of what I had to work on.&lt;/p&gt;
&lt;p&gt;My &lt;a href=&quot;https://fluforecaster.herokuapp.com&quot;&gt;final product&lt;/a&gt; a hybrid web dashboard + blog post. Behind the dashboard is a fairly complex set of computations, which currently are run through a Jupyter notebook. The front-end, therefore, only renders the predicted flu sequences returned from the Jupyter notebooks. As part of my forecasts, I want to show the uncertainty surrounding the predictions, and how they're associated with individual forecasted sequences. This requires computing a convex hull surrounding a point cloud, and plotting it. I spent about 3-4 hours on Tuesday figuring out the code to make this part of the visualization, which I consider integral to communicating the project.&lt;/p&gt;
&lt;p&gt;Another important thing is the user experience (UX) when interacting with my hybrid blog post + dashboard. Unlike this blog or one written in Medium (the blog of choice for Insight), I have interactive elements in the post, which meant I had to hand-craft the HTML for the page. In plotting the figures on the page, there are a set of functions in the backend that are run before the page is rendered. These compute the necessary JS for interactive web plots. They have to run fast enough, otherwise Heroku will timeout. Introducing code to plot the bounding boxes above slowed the loading time of the page beyond the 30 second limit Heroku imposed. As such, I had to carefully profile my code (mostly manually, with timing statements printed to console) to isolate the slow part, rewrite the implementation for speed, and re-deploy to Heroku. This took another good 3-4 hours, all to shave off dozens of seconds. The things we do with our lives!&lt;/p&gt;
&lt;p&gt;Throughout the week, a lot of other Fellows were getting their web demos set up. A lot of questions regarding Bokeh and Flask were flying around. Because of the discussion, I think I have a much better grasp over the programming model involved in making Bokeh work with Flask. Basically there's a bunch of plotting computation that is needed to get the JavaScript computer by Bokeh, and then through Jinja2 templating and HTML divs, we can put the final plot in the HTML canvas. A few more rounds of practice and I should be able to commit it to memory.&lt;/p&gt;
&lt;p&gt;The final part is in getting the presentation overall looking polished and understandable. This involves many tasks, from tweaking the text to making static figures and more. I have spent time with column layouts and configuring modals to get my page content looking overall fresh and yet also informative. Requires a lot of thought!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/10/insight-week-2/">
    <title type="text">Insight Week 2</title>
    <id>urn:uuid:4cb2d5e3-a9eb-3e41-a8ea-d4a7e56cfe74</id>
    <updated>2017-06-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/10/insight-week-2/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;This week has been intense, mostly because I knew in advance that I'd be spending two days wearing a fancy hat, funky robe, and yellow sash. Because I was missing two days of Insight, I had to get my Minimum Viable Product (MVP) out by Wednesday - thankfully, I did!&lt;/p&gt;
&lt;p&gt;If you've followed my blog post series on Insight (this is the 2nd post), my project is forecasting influenza sequences. This week, I hacked out my MVP and deployed it to &lt;a href=&quot;https://fluforecaster.herokuapp.com/&quot;&gt;Heroku&lt;/a&gt; as a hybrid HTML report + dashboard. I also picked up and incorporated a few new things along the way.&lt;/p&gt;
&lt;p&gt;The first is the use of tooltips on my Bokeh plots. Bokeh is really powerful, and in some of the exploratory analyses, I desired having tooltips as a UI element to help a reader (who might need some introduction) understand the nature of the problem and the data involved.&lt;/p&gt;
&lt;p&gt;The second is further mastery of Bootstrap CSS &amp;amp; JS. Now, Insight's Program Directors have told us clearly that we're not gunning to become front-end designers (and the likes). Keeping that in mind, I still think it's important to know at least one front-end framework well enough to produce pleasant-looking interactive tools or reports - knowing front-end elements potentiates us to communicate with front-end designers on final data products.&lt;/p&gt;
&lt;p&gt;For the MVP, I tried further experiments with the Grid layout and Modal JS. The key idea behind Grid layouts was easier to grasp - prioritize rows, then columns.&lt;/p&gt;
&lt;p&gt;With the Modal, stepping back for a moment, my goal was to display the science behind the project. However, it gets really technical. My audience is probably going to fall into one of two personas: the &quot;business person&quot; who just wants to see the final result and doesn't really care about the techniques, and the &quot;technical person&quot; who wants to dig deeper. I chose to use the Modal effect to satisfy both. The scientific methods are described at a high level on the main page, and the Modal element is used to show further information, graphics, and the likes.&lt;/p&gt;
&lt;p&gt;The third was deployment to Heroku itself! &lt;a href=&quot;https://www.davidbaumgold.com/&quot;&gt;David Baumgold&lt;/a&gt; first showed me how to use Heroku at PyCon 2016, but I could never wrap my head around it at first. I think I didn't understand how &quot;deployment&quot; worked. A year later, stuff that DB taught me came to fruition, as I hacked on deploying a minimal Flask app to Heroku with my younger brother. That gave me enough of the Heroku-specific concepts to hack together the necessary &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;Procfile&lt;/code&gt; files to deploy Flu Forecaster to the web.&lt;/p&gt;
&lt;p&gt;For next week, these are my plans:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solve the problem of &quot;average sequences per quarter&quot; being ~10 amino acids different from actual sequences. Two approaches I'm thinking of:&lt;ul&gt;
&lt;li&gt;Use GPflow to train a Sparse Variational GP regressor on my dataset. This should allow me to scale up the forecasts beyond 67 quarters and into 700+ weeks, which is a greater time resolution and thus will give me greater sequence resolution in forecasts.&lt;/li&gt;
&lt;li&gt;Try forecasting variance in addition to mean coordinates. This will give me a full probability distribution to sample from, which may allow me to stick with PyMC3 and quarterly forecasts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Still not sure which of the above two approaches are the better one, so I'll be sure to give each a shot.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/10/walk-the-stage-2017-edition/">
    <title type="text">&quot;Walk the Stage&quot; 2017 Edition</title>
    <id>urn:uuid:7a996565-b51a-33f8-9bcd-2f08ea626ff5</id>
    <updated>2017-06-10T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/10/walk-the-stage-2017-edition/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Finally put on a funny hat and an oversized robe, and topped it off with a yellow hood that only six of us received last Friday. Just six in the entire Institute this year - only six of us weirdos chose the SciDoc (ScD) degree! (I chose it because I like yellow over blue, and get to have a bit of fun confusing recruiters out there.) The day was too hot, and so I couldn't be bothered to dress up - who's going to see what I'm wearing underneath the robes anyways?!&lt;/p&gt;
&lt;p&gt;Anyways, overall a good feeling to be done. A little bittersweet because I'm leaving a time where I had a ton of fun learning new things, especially in my final two years of grad school, though I also think it's nice to have a change of environment and to have a new set of problems to solve.&lt;/p&gt;
&lt;p&gt;My hope is to continue being deeply engaged with the hard sciences, even outside of the academic ivory tower, just because it's a fun thing to do. Here's to hoping I can find a good match with a company out there.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/6/2/insight-week-1/">
    <title type="text">Insight Week 1</title>
    <id>urn:uuid:f2edfde4-6a3c-3edb-af7b-a7b417f6d672</id>
    <updated>2017-06-02T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/6/2/insight-week-1/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Insight's Week 1 is done! Here's some of my thoughts so far.&lt;/p&gt;
&lt;p&gt;Firstly, the Fellows at Insight is very fast at learning things. Everybody is either a PhD or MD, some have done post-doctoral work, and even fewer have become professors, but everybody is interested in doing data stuff, and are very fast at picking up new things. I think at the same time, we're also good at thinking strategically upon being given feedback; once an idea sounds infeasible, new ideas come out of the pivot or even switch.&lt;/p&gt;
&lt;p&gt;Secondly, I see now the importance of developing a great data product. I think of a data product in terms of the &lt;strong&gt;input data&lt;/strong&gt;, the &lt;strong&gt;transformation&lt;/strong&gt; applied to the data, and the &lt;strong&gt;insight&lt;/strong&gt; returned from the data. Think of it as a Python function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def data_product(data):
    insight = transformation(data)
    return insight
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most of the &quot;data products&quot; being developed are consumer-facing type projects that a user can interact with, but a small number of them, mine included, are &quot;dashboard-style&quot; products that can continually ingest continually updated data and return continually updated insights. Both are good ideas.&lt;/p&gt;
&lt;p&gt;Thirdly, I've become clear on the importance of first clearly defining the problem we want to solve, and then working backwards to define what we build, particularly for the &lt;strong&gt;m&lt;/strong&gt;inimum &lt;strong&gt;v&lt;/strong&gt;iable &lt;strong&gt;p&lt;/strong&gt;roduct (MVP). This way of thinking keeps us agile, and prevents us from being stuck in a rut.&lt;/p&gt;
&lt;p&gt;Fourthly, other fellows know lots of good stuff that I've been able to learn about. For example, in deep learning, there's been a few steps I wasn't sure about w.r.t. convolutional neural networks in autoencoders. One other fellow, a post-doc from UC Berkeley, gave me the master-class run-through on what happens at the vector/matrix level with convolutional neural networks.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Thus far, really nice. I've noticed we don't generally end up competing with one another, and the atmosphere is very collaborative. We're working with one another, talking with one another, building trust and the likes. I'm looking forward to the coming weeks!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://www.ericmjl.com/blog/2017/5/22/pycon-2017-highlights/">
    <title type="text">PyCon 2017 Highlights</title>
    <id>urn:uuid:e81dada7-7a2e-3763-957e-6c5476caf25f</id>
    <updated>2017-05-22T00:00:00Z</updated>
    <link href="http://www.ericmjl.com/blog/2017/5/22/pycon-2017-highlights/" />
    <author>
      <name>Eric J. Ma</name>
    </author>
    <content type="html">&lt;p&gt;Last post was about thoughts on past PyCons, having attended PyCon 2017. This post is on PyCon 2017's highlights for me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) Serving as part of the organizing committee.&lt;/strong&gt; I had the privilege of serving on the FinAid committee this year, and spent a large fraction of time in the staff room preparing to disburse FinAid cheques. I have very vivid memories of how slow the line was when I was receiving my cheques back in the day, and so I wanted to make sure FinAid recipients could receive their reimbursements as fast as possible, without wasting time in line (when they could instead be listening on talks).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) Teaching two tutorials.&lt;/strong&gt; This year, I submitted two tutorial proposals, and both were accepted. In the three years that I've been teaching it, &lt;a href=&quot;https://www.youtube.com/watch?v=E4VKzFmByhE&quot;&gt;Network Analysis Made Simple&lt;/a&gt; has always been popular, and I think it's because it gives participants a different way of thinking about data, thus making it an intellectually stimulating topic. I also developed a new material on &lt;a href=&quot;https://www.youtube.com/watch?v=yACtdj1_IxE&quot;&gt;Best Testing Practices for Data Science&lt;/a&gt;. This one, in retrospect, was much fresher, and thus in need of more battle-testing and polish compared to Network Analysis. I have some ideas, including modifications to the workshop format, narrowing the target audience and more, to make it more useful for future iterations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3) First talk at PyCon!&lt;/strong&gt; I also gave a talk at PyCon on doing &lt;a href=&quot;https://www.youtube.com/watch?v=p1IB4zWq9C8&quot;&gt;Bayesian Statistical Analysis with PyMC3&lt;/a&gt;! This was my first PyCon talk ever. It was so nice to have a tweet-commendation by PyMC3's creator Chris Fonnesbeck too:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;. &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt; is giving the &lt;a href=&quot;https://twitter.com/hashtag/PyMC3?src=hash&quot;&gt;#PyMC3&lt;/a&gt; talk you really want to hear if you want to learn how to put it to practical use. Room 251. &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt;&lt;/p&gt;&amp;mdash; Chris Fonnesbeck (@fonnesbeck) &lt;a href=&quot;https://twitter.com/fonnesbeck/status/866404594951139328&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;It was also nice to have Thomas Wiecki's tweet-commendation too:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Excellent &lt;a href=&quot;https://twitter.com/hashtag/PyMC3?src=hash&quot;&gt;#PyMC3&lt;/a&gt; talks at &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/fonnesbeck&quot;&gt;@fonnesbeck&lt;/a&gt;: &lt;a href=&quot;https://t.co/iFbxjSz9C1&quot;&gt;https://t.co/iFbxjSz9C1&lt;/a&gt; &lt;a href=&quot;https://t.co/VhAJLpVQBR&quot;&gt;https://t.co/VhAJLpVQBR&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt;: &lt;a href=&quot;https://t.co/MnkyWRivXs&quot;&gt;https://t.co/MnkyWRivXs&lt;/a&gt;&lt;/p&gt;&amp;mdash; Thomas Wiecki (@twiecki) &lt;a href=&quot;https://twitter.com/twiecki/status/866639588995063808&quot;&gt;May 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;Beyond that, the attendees seemed to like the talk too on the Twitterverse!&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Great introduction to Bayesian data analysis with PyMC3 by &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt; at &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt; &lt;a href=&quot;https://t.co/BjbR0tZ6AO&quot;&gt;https://t.co/BjbR0tZ6AO&lt;/a&gt;&lt;/p&gt;&amp;mdash; Matteo Visconti dOC (@MatteoVdOC) &lt;a href=&quot;https://twitter.com/MatteoVdOC/status/866413241907400704&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Awesome talk on Bayesian analysis by &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt;! Check out the material here: &lt;a href=&quot;https://t.co/HAPVYjKUhM&quot;&gt;https://t.co/HAPVYjKUhM&lt;/a&gt;&lt;/p&gt;&amp;mdash; Sarah Guido (@sarah_guido) &lt;a href=&quot;https://twitter.com/sarah_guido/status/866413261037555713&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;An excellent concrete introduction to Bayesian stats. I&amp;#39;m really looking forward to working through the notebooks as well. &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt; &lt;a href=&quot;https://t.co/ec230Ui3iC&quot;&gt;https://t.co/ec230Ui3iC&lt;/a&gt;&lt;/p&gt;&amp;mdash; Leland McInnes (@leland_mcinnes) &lt;a href=&quot;https://twitter.com/leland_mcinnes/status/866437998253981696&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Problems, code and explanation - nice! &lt;a href=&quot;https://t.co/ulJEXfMAo0&quot;&gt;https://t.co/ulJEXfMAo0&lt;/a&gt;&lt;/p&gt;&amp;mdash; AV Speech Processing (@AV_SP) &lt;a href=&quot;https://twitter.com/AV_SP/status/866422943361794049&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Great summary slide &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt;! &lt;a href=&quot;https://t.co/JbFV4qrzCl&quot;&gt;pic.twitter.com/JbFV4qrzCl&lt;/a&gt;&lt;/p&gt;&amp;mdash; William Farmer (@willzfarmer) &lt;a href=&quot;https://twitter.com/willzfarmer/status/866415332264562688&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Last technical talk of &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt; and my brain is full. Excellent introduction to &lt;a href=&quot;https://twitter.com/hashtag/PyMc3?src=hash&quot;&gt;#PyMc3&lt;/a&gt; and Bayesian variable inference by &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt;&lt;/p&gt;&amp;mdash; Justin Gosses (@JustinGosses) &lt;a href=&quot;https://twitter.com/JustinGosses/status/866413619315056641&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Great talk from &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt; on PyMC3 making everything clear with concrete examples. &lt;a href=&quot;https://twitter.com/hashtag/pycon2017?src=hash&quot;&gt;#pycon2017&lt;/a&gt;&lt;/p&gt;&amp;mdash; Leland McInnes (@leland_mcinnes) &lt;a href=&quot;https://twitter.com/leland_mcinnes/status/866413119676891137&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;.&lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt; giving &lt;a href=&quot;https://twitter.com/hashtag/bayesian?src=hash&quot;&gt;#bayesian&lt;/a&gt; intuition at &lt;a href=&quot;https://twitter.com/hashtag/PyCon2017?src=hash&quot;&gt;#PyCon2017&lt;/a&gt; ; as always, a great, inspiring speaker &lt;a href=&quot;https://t.co/4qz9QeTArc&quot;&gt;https://t.co/4qz9QeTArc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Hugo Bowne-Anderson (@hugobowne) &lt;a href=&quot;https://twitter.com/hugobowne/status/866407227518734337&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Foregoing formula, &lt;a href=&quot;https://twitter.com/ericmjl&quot;&gt;@ericmjl&lt;/a&gt; wants you to walk away w/intuition about Bayesian stats: &amp;quot;update beliefs having seen the evidence&amp;quot; &lt;a href=&quot;https://twitter.com/hashtag/pycon2017?src=hash&quot;&gt;#pycon2017&lt;/a&gt;&lt;/p&gt;&amp;mdash; Melissa @ #pycon2017 (@iff_or) &lt;a href=&quot;https://twitter.com/iff_or/status/866407192110350336&quot;&gt;May 21, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;It's very heartening to see how many people want to move into Bayes-land! The talk also happened to be the last in the session and last of the day, so I think many people were tired by that point and wanted to go to the final keynote. Thus, the only question came from my friend Hugo, with whom I also worked on a course at DataCamp, who asked about &quot;how we might communicate these ideas to, say, a manager.&quot; My thoughts on that were to report not a single number (e.g. the mean), but also the range, and communicate how the lower and upper bound of the range would affect bottomline decisions, or open up new opportunities (though I probably could have expressed this sentiment better).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(4) Feeding Guido van Rossum.&lt;/strong&gt; Python's BDFL, &lt;a href=&quot;https://en.wikipedia.org/wiki/Guido_van_Rossum&quot;&gt;Guido van Rossum&lt;/a&gt;, wandered into the staff office asking to see whether the speaker ready room was open, because he was hungry and was looking for some snacks. We initially suggested the main conference hall, but later I ran out and called him back, because we had some English biscuits in the staff room, and we engaged in a short chat. That's when I had my star-awed moment! Was tempted to get a photo, but I figured he'd probably be fed up with people asking for photo ops, so I decided against it, hoping to be considerate for him. When he finished the biscuit, he said goodbye, and left the staff office. Amazing how everybody else just went about their own business while he was in the room; speaks to the lack of ego that PyCon celebrities have, and that sets a great example for the rest of the community!&lt;/p&gt;
&lt;p&gt;Once I'm back in Boston, I'm definitely going to catch up on the rest of PyCon. I heard that there were a lot of good talks that I missed while staffing the conference as FinAid co-chair, will have to make sure that YouTube playlist is set up!&lt;/p&gt;
</content>
  </entry>
</feed>
