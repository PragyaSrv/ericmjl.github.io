

<!doctype html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <!-- Bootstrap v4beta Imports -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <style media="screen">
        body {
            padding-top: 70px;
            padding-bottom: 70px;
        }
    </style>

    
    

    <!-- Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-12498603-2', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- ClustrMaps Tracking -->
    <!-- <script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=nhKoDpoTjWz4pC6CwI-fSy4hPoJ1uXwTLCfMCT3OK_8"></script> -->

    <!-- FontAwesome embed -->
    <!-- <script src="https://use.fontawesome.com/cb9dbe8e41.js"></script> -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" integrity="sha384-O8whS3fhG2OnA5Kas0Y9l3cfpmYjapjI0E4theH4iuMD+pLhbf6JI0jIMfYcK3yZ" crossorigin="anonymous">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/static/css/custom.css">

    <!-- Mathjax -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

</head>

<title>Blog - Eric J. Ma's Personal Site</title>
<body class="body">
    <nav class="navbar navbar-expand-sm navbar-dark fixed-top bg-dark">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#local-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="local-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="/"><i class="fa fa-home" aria-hidden="true"></i> Home</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="https://ericmjl.github.io/resume"><i class="fa far fa-file-alt" aria-hidden="true"></i> Resume</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/blog"><i class="fa fa-rss" aria-hidden="true"></i> Blog</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/open-source"><i class="fa fa-code" aria-hidden="true"></i> Open Source</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/projects"><i class="fa fa-briefcase" aria-hidden="true"></i> Projects</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/talks"><i class="fa fa-microphone" aria-hidden="true"></i> Talks</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/teaching"><i class="fa fa-university" aria-hidden="true"></i> Teaching</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="/bio"><i class="fa fa-user" aria-hidden="true"></i> Bio</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <div class="container">
        





<div class="card bg-dark">
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div class="card-body">
    <h1><a href="../../../blog/2019/10/31/reimplementing-and-testing-deep-learning-models/">Reimplementing and Testing Deep Learning Models</a></h1>
    <small class="text-muted">
      <p>
        written by
        
        <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
        
        on 2019-10-31
        
      </p>
      <!-- Append tags after author -->
      <p>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/data science/">
          data science
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/deep learning/">
          deep learning
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/testing/">
          testing
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/pair programming/">
          pair programming
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/code review/">
          code review
        </a>
        
      </p>
      

    </small>

    <p class="card-text"><p><em>Note: this blog post is cross-posted on my personal <a href="https://ericmjl.github.io/essays-on-data-science/machine-learning/reimplementing-models/">essay collection on the practice of data science</a>.</em></p>
<p>At work, most deep learners I have encountered
have a tendency to take deep learning models
and treat them as black boxes that we should be able to wrangle.
While I see this as a pragmatic first step
to testing and proving out the value of a newly-developed deep learning model,
I think that stopping there
and not investing the time into understanding the nitty-gritty of the model
leaves us in a poor position
to know that model's
(1) applicability domain (i.e. where the model should be used),
(2) computational and statistical performance limitations, and
(3) possible engineering barriers to getting the model performant
in a "production" setting.</p>
<p>As such, with deep learning models,
I'm actually a fan of investing the time to re-implement the model
in a tensor framework that we all know and love,
NumPy (and by extension, JAX).</p>
<h2 id="benefits-of-re-implementing-deep-learning-models">Benefits of re-implementing deep learning models</h2><p>Doing a model re-implementation from a deep learning framework
into NumPy code actually has some benefits for the time being invested.</p>
<h3 id="developing-familiarity-with-deep-learning-frameworks">Developing familiarity with deep learning frameworks</h3><p>Firstly, doing so forces us to know the translation/mapping
from deep learning tensor libraries into NumPy.
One of the issues I have had with deep learning libraries
(PyTorch and Tensorflow being the main culprits here)
is that their API copies something like 90% of NumPy API
without making easily accessible
the design considerations discussed when deciding to deviate.
(By contrast, CuPy has an explicit API policy
that is well-documented and front-and-center on the docs,
while JAX strives to replicate the NumPy API.)</p>
<p>My gripes with tensor library APIs aside, though,
translating a model by hand from one API to another
forces growth in familiarity with both APIs,
much as translating between two languages
forces growth in familiarity with both languages.</p>
<h3 id="developing-a-mechanistic-understanding-of-the-model">Developing a mechanistic understanding of the model</h3><p>It is one thing to describe a deep neural network
as being "like the brain cell connections".
It is another thing to know that the math operations underneath the hood
are nothing more than dot products (or tensor operations, more generally).
Re-implementing a deep learning model
requires combing over every line of code,
which forces us to identify each math operation used.
No longer can we hide behind an unhelpfully vague abstraction.</p>
<h3 id="developing-an-ability-to-test-and-sanity-check-the-model">Developing an ability to test and sanity-check the model</h3><p>If we follow the workflow (that I will describe below)
for reimplementing the model,
(or as the reader should now see, translating the model between APIs)
we will develop confidence in the correctness of the model.
This is because the workflow I am going to propose
involves proper basic software engineering workflow:
writing documentation for the model,
testing it,
and modularizing it into its logical components.
Doing each of these requires a mechanistic understanding
of how the model works,
and hence forms a useful way of building intuition behind the model
as well as correctness of the model.</p>
<h3 id="reimplementing-models-is-_not_-a-waste-of-time">Reimplementing models is <em>not</em> a waste of time</h3><p>By contrast, it is a highly beneficial practice
for gaining a deeper understanding into the inner workings
of a deep neural network.
The only price we pay is in person-hours,
yet under the assumption that the model is of strong commercial interest,
that price can only be considered an investment, and not a waste.</p>
<h2 id="a-proposed-workflow-for-reimplementing-deep-learning-models">A proposed workflow for reimplementing deep learning models</h2><p>I will now propose a workflow for re-implementing deep learning models.</p>
<h3 id="identify-a-coding-partner">Identify a coding partner</h3><p>Pair programming is a productive way of teaching and learning.
Hence, I would start by identifying a coding partner
who has the requisite skillset and shared incentive
to go deep on the model.</p>
<p>Doing so helps a few ways.</p>
<p>Firstly, we have real-time peer review on our code,
making it easier for us to catch mistakes that show up.</p>
<p>Secondly, working together at the same time means that
both myself and my colleague will learn something about the neural network
that we are re-implementing.</p>
<h3 id="pick-out-the-forward-step-of-the-model">Pick out the "forward" step of the model</h3><p>The "forward" pass of the model is where the structure of the model is defined:
basically the mathematical operations
that transform the input data into the output observations.</p>
<p>A few keywords to look out for
are the <code>forward()</code> and  <code>__call__()</code> class methods.</p>
<div class="hll"><pre><span></span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># Implementation of model happens here.</span>
        <span class="n">something</span> <span class="o">=</span> <span class="o">...</span>
        <span class="k">return</span> <span class="n">something</span>
</pre></div>
<p>For models that involve an autoencoder,
somewhat more seasoned programmers
might create a class method called <code>encoder()</code> and <code>decoder()</code>,
which themselves reference another model
that would have a <code>forward()</code> or <code>__call__()</code> defined.</p>
<div class="hll"><pre><span></span><span class="k">class</span> <span class="nc">AutoEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">something</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">something</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
<p>Re-implementing the <code>forward()</code> part of the model
is usually a good way of building a map
of the equations that are being used
to transform the input data into the output data.</p>
<h3 id="inspect-the-shapes-of-the-weights">Inspect the shapes of the weights</h3><p>While the equations give the model <em>structure</em>,
the weights and biases, or the <em>parameters</em>,
are the part of the model that are optimized.
(In Bayesian statistics, we would usually presume a model structure,
i.e. the set of equations used alongside the priors,
and fit the model parameters.)</p>
<p>Because much of deep learning hinges on linear algebra,
and because most of the transformations that happen
involve transforming the <em>input space</em> into the <em>output space</em>,
getting the shapes of the parameters is very important.</p>
<p>In a re-implementation exercise with my intern,
where we re-implemented
a specially designed recurrent neural network layer in JAX,
we did a manual sanity check through our implementation
to identify what the shapes would need to be
for the inputs and outputs.</p>
<h3 id="write-tests-for-the-neural-network-components">Write tests for the neural network components</h3><p>Once we have the neural network model and its components implemented,
writing tests for those components is a wonderful way of making sure
that
(1) the implementation is correct, to the best of our knowledge, and that
(2) we can catch when the implementation might have been broken inadvertently.</p>
<p>The shape test (as described above) is one way of doing this.</p>
<div class="hll"><pre><span></span><span class="k">def</span> <span class="nf">test_layer_shapes</span><span class="p">():</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">input_dims</span><span class="p">,</span> <span class="n">output_dims</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_dims</span><span class="p">))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">nn_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">output_dims</span>
</pre></div>
<p>If there are special elementwise transforms performed on the data,
such as a ReLU or exponential transform,
we can test that the numerical properties of the output are correct:</p>
<div class="hll"><pre><span></span><span class="k">def</span> <span class="nf">test_layer_shapes</span><span class="p">():</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">input_dims</span><span class="p">,</span> <span class="n">output_dims</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_dims</span><span class="p">))</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">nn_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">output</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
<h3 id="write-tests-for-the-entire-training-loop">Write tests for the entire training loop</h3><p>Once the model has been re-implemented in its entirety,
prepare a small set of training data,
and pass it through the model,
and attempt to train it for a few epochs.</p>
<p>If the model, as implemented, is doing what we think it should be,
then after a dozen epochs or so,
the training loss should go down.
We can then test that the training loss at the end
is less than the training loss at the beginning.
If the loss does go down, it's necessary but not sufficient for knowing
that the model is implemented correctly.
However, if the loss <em>does not</em> go down, then we will definitely know
that a problem exists somewhere in the code, and can begin to debug.</p>
<p>An example with pseudocode below might look like the following:</p>
<div class="hll"><pre><span></span><span class="kn">from</span> <span class="nn">data</span> <span class="kn">import</span> <span class="n">dummy_graph_data</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">gnn_model</span>
<span class="kn">from</span> <span class="nn">params</span> <span class="kn">import</span> <span class="n">make_gnn_params</span>
<span class="kn">from</span> <span class="nn">losses</span> <span class="kn">import</span> <span class="n">mse_loss</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="kn">from</span> <span class="nn">jax.experimental.optimizers</span> <span class="kn">import</span> <span class="n">adam</span>

<span class="k">def</span> <span class="nf">test_gnn_training</span><span class="p">():</span>
    <span class="c1"># Prepare training data</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dummy_graph_data</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">make_gnn_params</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">dloss</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">mse_loss</span><span class="p">)</span>
    <span class="n">init</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">get_params</span> <span class="o">=</span> <span class="n">adam</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span>
    <span class="n">start_loss</span>  <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">state</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">dloss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="n">end_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">end_loss</span> <span class="o">&lt;</span> <span class="n">start_loss</span>
</pre></div>
<p>A side benefit of this is that
if you commit to only judiciously changing the tests,
you will end up with a stable
and copy/paste-able
training loop that you know you can trust
on new learning tasks,
and hence only need to worry about swapping out the data.</p>
<h3 id="build-little-tools-for-yourself-that-automate-repetitive-boring-things">Build little tools for yourself that automate repetitive (boring) things</h3><p>You may notice in the above integration test,
we wrote a lot of other functions
that make testing much easier,
such as dummy data generators,
and parameter initializers.</p>
<p>These are tools that make composing parts of the entire training process
modular and easy to compose.
I strongly recommend writing these things,
and also backing them with more tests
(since we will end up relying on them anyways).</p>
<h3 id="now-run-your-deep-learning-experiments">Now run your deep learning experiments</h3><p>Once we have the model re-implemented and tested,
the groundwork is present for us to conduct extensive experiments
with the confidence that we know
how to catch bugs in the model
in a fairly automated fashion.</p>
<h2 id="concluding-words">Concluding words</h2><p>Re-implementing deep learning models can be a very fun and rewarding exercise,
because it serves as an excellent tool
to check our understanding of the models that we work with.</p>
<p>Without the right safeguards in place, though,
it can also very quickly metamorphose into a nightmare rabbithole of debugging.
Placing basic safeguards in place when re-implementing models
helps us avoid as many of these rabbitholes as possible.</p>

    </p>
    <small class="text-muted">
      <p class="card-text">
        <i>Did you enjoy this blog post? <a href="../../../blog/2019/10/31/reimplementing-and-testing-deep-learning-models/#disqus">Let's discuss more</a>!
        </i>
      </p>
    </small>

  </div>
</div>


<div>
  <hr>
</div>



<div class="card bg-dark">
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div class="card-body">
    <h1><a href="../../../blog/2019/10/30/code-review-in-data-science/">Code review in data science</a></h1>
    <small class="text-muted">
      <p>
        written by
        
        <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
        
        on 2019-10-30
        
      </p>
      <!-- Append tags after author -->
      <p>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/essays/">
          essays
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/data science/">
          data science
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/workflow/">
          workflow
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/good practices/">
          good practices
        </a>
        
      </p>
      

    </small>

    <p class="card-text"><p><em>This blog post is cross-posted in my <a href="https://ericmjl.github.io/essays-on-data-science/workflow/code-review/">essays collection</a>.</em></p>
<p>The practice of code review is extremely beneficial to the practice of software engineering.
I believe it has its place in data science as well.</p>
<h2 id="what-code-review-is">What code review is</h2><p>Code review is the process by which a contributor's newly committed code
is reviewed by one or more teammate(s).
During the review process, the teammate(s) are tasked with ensuring that they</p>
<ul>
<li>understand the code and are able to follow the logic,</li>
<li>find potential flaws in the newly contributed code,</li>
<li>identify poorly documented code and confusing use of variable names,</li>
<li>raise constructive questions and provide constructive feedback</li>
</ul>
<p>on the codebase.</p>
<p>If you've done the practice of scientific research before,
it is essentially identical to peer review,
except with code being the thing being reviewed instead.</p>
<h2 id="what-code-review-_isn-t_">What code review <em>isn't</em></h2><p>Code review is not the time
for a senior person to slam the contributions of a junior person,
nor vice versa.</p>
<h2 id="why-data-scientists-should-do-code-review">Why data scientists should do code review</h2><p>The first reason is to ensure that project knowledge
is shared amongst teammates.
By doing this, we ensure that
in case the original code creator needs to be offline for whatever reason,
others on the team cover for that person and pick up the analysis.
When N people review the code, N+1 people know what went on.
(It does not necessarily have to be N == number of people on the team.)</p>
<p>In the context of notebooks, this is even more important.
An analysis is complex,
and involves multiple modelling decisions and assumptions.
Raising these questions,
and pointing out where those assumptions should be documented
(particularly in the notebook)
is a good way of ensuring
that N+1 people know those implicit assumptions that go into the model.</p>
<p>The second reason is that
even so-called "senior" data scientists are humans,
and will make mistakes.
With my interns and less-experienced colleagues,
I will invite them to constructively raise queries about my code
where it looks confusing to them.
Sometimes, their lack of experience gives me an opportunity to explain
and share design considerations during the code review process,
but at other times, they are correct, and I have made a mistake in my code
that should be rectified.</p>
<h2 id="what-code-review-can-be">What code review can be</h2><p>Code review can become a very productive time of learning for all parties.
What it takes is the willingness to listen to the critique provided,
and the willingness to raise issues on the codebase in a constructive fashion.</p>
<h2 id="how-code-review-happens">How code review happens</h2><p>Code review happens usually in the context of a pull request
to merge contributed code into the master branch.
The major version control system hosting platforms (GitHub, BitBucket, GitLab)
all provide an interface to show the "diff"
(i.e. newly contributed or deleted code)
and comment directly on the code, in context.</p>
<p>As such, code review can happen entirely asynchronously, across time zones,
and without needing much in-person interaction.</p>
<p>Of course, being able to sync up either via a video call,
or by meeting up in person,
has numerous advantages by allowing non-verbal communication to take place.
This helps with building trust between teammates,
and hence doing even "virtual" in-person reviews
can be a way of being inclusive towards remote colleagues.</p>
<h2 id="parting-words">Parting words</h2><p>If your firm is set up to use a version control system,
then you probably have the facilities to do code review available.
I hope this essay encourages you to give it a try.</p>

    </p>
    <small class="text-muted">
      <p class="card-text">
        <i>Did you enjoy this blog post? <a href="../../../blog/2019/10/30/code-review-in-data-science/#disqus">Let's discuss more</a>!
        </i>
      </p>
    </small>

  </div>
</div>


<div>
  <hr>
</div>



<div class="card bg-dark">
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div class="card-body">
    <h1><a href="../../../blog/2019/10/29/ai-will-not-solve-medicine/">“AI will not solve medicine”</a></h1>
    <small class="text-muted">
      <p>
        written by
        
        <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
        
        on 2019-10-29
        
      </p>
      <!-- Append tags after author -->
      <p>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/data science/">
          data science
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/drug development/">
          drug development
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/artificial intelligence/">
          artificial intelligence
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/medicine/">
          medicine
        </a>
        
      </p>
      

    </small>

    <p class="card-text"><p>Those who think “AI will solve medicine” are delusional.
I say this as a practitioner of machine learning in drug discovery and development.</p>
<p>First things first, “AI” is an overused term.
We should stop using it, especially in medicinal research.</p>
<p>Now, my thoughts are more sanguine.
The real value proposition of machine learning models in drug development
is to navigate chemical, sequence, pathway, and knowledge space
faster and smarter than we might otherwise do so
without machine learning methods.
It’s a modeling tool, and nothing more than that.
It’s a tool for helping the human collective make better decisions than without it,
but it’s also a double-edged sword.
We can use the tool and then constrain our thinking because we have that tool,
because we want to continue using that tool.
Or we can use the tool to our advantage
and liberate our mind to think of other things.</p>
<p>This thought was sparked off by an email that I was on at work.
A molecule was approved for <em>continued investigation</em> (not even “go for safety trials”!),
and 63 people were on that email.
Imagine the number of people
who are involved in getting a molecule past all research-phase checkpoints
<em>and</em> all 3 clinical trial checkpoints.
<em>Hint: Many people are involved.</em></p>
<p>As I combed through the names on that email,
the number of machine learners was vastly outnumbered by the number of colleagues
who toiled daily at the bench,
wrangling with even more uncertainty than that we have at our computers.
We machine learners work in service of them,
delivering insights and prioritized directions,
just as they toil to generate the data that our data-hungry models need.
It’s a symbiotic relationship.</p>
<p>What do all of those 63 people work on?</p>
<p>Some make the molecules.
Others design the assays to test the molecules in.
Yet others design the assays to find the target to then develop the assay for.
It’s many layers of human creativity in the loop.
I can’t automate the entirety of their work with my software tools, but I can augment them.
I mean, yeah, I can find a new potential target,
but ultimately it's a molecular biologist
who develops the assay, especially if that assay has never existed before.</p>
<p>There are others who professionally manage the progress of the project.
There’s sufficient complexity at the bench
and in the silicon chips
that we can’t each keep track of the big picture.
Someone has to do that, and keep everybody focused.</p>
<p>And then there’s the handful of us who deal with numbers and mainly just numbers.
Yes, it’s a handful.
I counted them on my fingers.
We do have an outsized impact compared to our numbers,
but that’s because we can get computers to do our repetitive work for us.
At the bench, robots are harder to work with.
Having been at the bench before and failing badly at it,
I can very much empathize with how tedious the work is.
It’s expensive to collect that data,
so the onus is on us computation types to get help navigate “data space” more smartly.</p>

    </p>
    <small class="text-muted">
      <p class="card-text">
        <i>Did you enjoy this blog post? <a href="../../../blog/2019/10/29/ai-will-not-solve-medicine/#disqus">Let's discuss more</a>!
        </i>
      </p>
    </small>

  </div>
</div>


<div>
  <hr>
</div>



<div class="card bg-dark">
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div class="card-body">
    <h1><a href="../../../blog/2019/10/18/caching-long-running-function-results/">Caching Long-Running Function Results</a></h1>
    <small class="text-muted">
      <p>
        written by
        
        <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
        
        on 2019-10-18
        
      </p>
      <!-- Append tags after author -->
      <p>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/python/">
          python
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/tips/">
          tips
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/optimization/">
          optimization
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/packages/">
          packages
        </a>
        
      </p>
      

    </small>

    <p class="card-text"><p>I found this nifty tool for caching the results of long-running functions: <a href="https://pypi.org/project/cachier/"><code>cachier</code></a>. This is useful when we’re building, say, Python applications for which quick interactions are necessary, or for caching the results of a long database query.</p>
<p>How do we use it? Basically it’s nothing more than a decorator!</p>
<p>Let’s imagine I have a long-running function as below.</p>
<div class="hll"><pre><span></span><span class="k">def</span> <span class="nf">long_running_function</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">):</span>
    <span class="c1"># stuff happens</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
<p>Turns out, if you have a need to cache the result in a lightweight fashion, you can simply add <code>cachier</code>:</p>
<div class="hll"><pre><span></span><span class="kn">from</span> <span class="nn">cachier</span> <span class="kn">import</span> <span class="n">cachier</span>

<span class="nd">@cachier</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">long_running_function</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">):</span>
    <span class="c1"># stuff happens</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
<p>The result is stored in your home directory, so the cache is accessible to you.</p>
<p>One nice thing <code>cachier</code> also offers is the ability to set a time duration after which the cache goes stale. This can be useful in situations where you know that you need to refresh the cache, such as a database query that may go stale because of new data added into it. This is done by specifying the <code>stale_after</code> keyword argument:</p>
<div class="hll"><pre><span></span><span class="kn">from</span> <span class="nn">cachier</span> <span class="kn">import</span> <span class="n">cachier</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>

<span class="c1"># Re-cache result after 1 week.</span>
<span class="nd">@cachier</span><span class="p">(</span><span class="n">stale_after</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">weeks</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">long_running_function</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">):</span>
    <span class="c1"># stuff happens</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
<p>If you need to reset the cache manually, you can always do:</p>
<div class="hll"><pre><span></span><span class="n">long_running_function</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
</pre></div>
<p>There are other advanced features that <code>cachier</code> provides, and so I’d encourage you to go and take a look at it!</p>

    </p>
    <small class="text-muted">
      <p class="card-text">
        <i>Did you enjoy this blog post? <a href="../../../blog/2019/10/18/caching-long-running-function-results/#disqus">Let's discuss more</a>!
        </i>
      </p>
    </small>

  </div>
</div>


<div>
  <hr>
</div>



<div class="card bg-dark">
  <link rel="stylesheet" href="../../../static/pygments.css">
  <div class="card-body">
    <h1><a href="../../../blog/2019/10/5/jupyter-server-with-https-on-personal-server/">Jupyter Server with HTTPS on Personal Server</a></h1>
    <small class="text-muted">
      <p>
        written by
        
        <a href="https://twitter.com/ericmjl">Eric J. Ma</a>
        
        on 2019-10-05
        
      </p>
      <!-- Append tags after author -->
      <p>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/jupyter/">
          jupyter
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/dataops/">
          dataops
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/devops/">
          devops
        </a>
        <i class="fas fa-tag"></i>
        <a href="../../../blog/tag/data science/">
          data science
        </a>
        
      </p>
      

    </small>

    <p class="card-text"><p>Recording this for myself, since I did it once and probably don't have the brain bandwidth to remember this through repetition.</p>
<p>I have known how to run a "public" Jupyter server (password-protected, naturally), but one thing I've struggled with was getting HTTPS working.</p>
<p>Turns out, the <code>letsencrypt</code> instructions aren't that bad on Jupyter's docs. I just was ignorant in the past, and didn't know enough about Linux to get this working right.</p>
<p>The key here is creating a <code>letsencrypt</code> certificate, and making sure file permissions are set correctly.</p>
<p>First off, go to the <a href="https://certbot.eff.org">Certbot page</a>. Select the type of website you're running and operating system. For Jupyter, I chose "None of the Above" and "Ubuntu 18.04 LTS (bionic)" (even though I'm technically on Ubuntu 19). (Here's a <a href="https://certbot.eff.org/lets-encrypt/ubuntubionic-other">shortcut link</a> to the instructions if you're in the same situation.)</p>
<p>On my system (Ubuntu-based), I used the following commands to install <code>certbot</code>:</p>
<div class="hll"><pre><span></span><span class="c1"># Add repository</span>
sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update

<span class="c1"># Install certbot</span>
sudo apt-get install certbot

<span class="c1"># Run certbot</span>
sudo certbot certonly --standalone
</pre></div>
<p>Follow the instructions. <code>certbot</code> will install into a protected directory. In my case, it was <code>/etc/letsencrypt/live/&lt;mywebsite&gt;/</code>.</p>
<p>Here, a problem will show up. That directory above is not accessible by a Jupyter server run under a user other than <code>root</code>. But a desired property of running Jupyter servers is that we don't have to use <code>sudo</code> to run it. How can we solve this? Basically, by making sure that the certificate is readable by a non-<code>root</code> user.</p>
<p>What I did, then, was to copy the files that were created by <code>certbot</code> into a location under my home directory. For security by obscurity, I'm naturally not revealing its identity. Then, I changed ownership of those files to my username:</p>
<div class="hll"><pre><span></span><span class="nb">pwd</span>  <span class="c1"># you should be in the directory where the certbot-created files are located</span>
su -
chown &lt;myusername&gt; *.pem  <span class="c1"># changes ownership of those files</span>
</pre></div>
<p>Finally, I went into my Jupyter config (<code>~/.jupyter/jupyter_notebook_config.py</code>, this is well-known), and edited the two lines that specified the "certfile" and the "keyfile":</p>
<div class="hll"><pre><span></span><span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">certfile</span> <span class="o">=</span> <span class="sa">u</span><span class="s1">&#39;/absolute/path/to/your/certificate/mycert.pem&#39;</span>
<span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">keyfile</span> <span class="o">=</span> <span class="sa">u</span><span class="s1">&#39;/absolute/path/to/your/certificate/mykey.key&#39;</span>
</pre></div>
<p>If this helps you, leave me a note in the comments below. :)</p>

    </p>
    <small class="text-muted">
      <p class="card-text">
        <i>Did you enjoy this blog post? <a href="../../../blog/2019/10/5/jupyter-server-with-https-on-personal-server/#disqus">Let's discuss more</a>!
        </i>
      </p>
    </small>

  </div>
</div>


<div>
  <hr>
</div>


  <div class="pagination">
    
      <a href="../../../blog/">&laquo; Previous</a>
    
    | 2 |
    
      <a href="../../../blog/page/3/">Next &raquo;</a>
    
  </div>


    </div>

    <nav class="navbar navbar-expand-sm navbar-dark fixed-bottom bg-dark">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#external-links" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="external-links">
            <ul class="navbar-nav mr-auto">
                
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/ericmjl"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://twitter.com/ericmjl"><i class="fab fa-twitter" aria-hidden="true"></i> Twitter</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://octodon.social/ericmjl"><i class="fab fa-mastodon" aria-hidden="true"></i> Octodon</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://github.com/ericmjl"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://stackoverflow.com/users/1274908/ericmjl"><i class="fab fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="http://shortwhale.com/ericmjl"><i class="far fa-envelope" aria-hidden="true"></i> Contact Me</a>
                </li>
                
            </ul>
        </div>
    </nav>
    <!-- Boostrap JS imports -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
</body>
